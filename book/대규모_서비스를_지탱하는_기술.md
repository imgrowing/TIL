# 대규모 서비스를 지탱하는 기술

## 대규모 데이터 처리의 어려운 점 - 메모리와 디스크

#### 대규모 데이터를 다룰 때 힘든점은, **메모리 내에서 계산할 수 없다.** 는 점
- 메모리에 올리지 않으면, 기본적으로 디스크를 계속해서 읽어가며 처리 해야한다.
- 데이터 건수가 많아질수록 계산량도 늘어남.
- 디스크 I/O는 매우 느리다.

#### 메모리와 디스크의 속도차이
- 메모리와 디스크는 10의 5승 ~ 10의6승 배 이상 빠르다.
    
#### 디스크가 느린 이유 ?
- 디스크는 동축 상에 '원반'이 쌓여 있다. 원반이 회전하고 있으며, 여기서 데이터를 읽어냄.
- 메모리와 달리 디스크는 **물리적인 동작** 을 수반하고 있음.
- 이 원반 뿐 아니라, 데이터를 읽어내는 '헤드' 도 존재한다.
- 헤드가 붙어 데이터를 읽어 내야 한다.
- 헤드의 이동, 원반의 회전단위 => 각각 4밀리초
- 데이터가 여기저기 분산되어 있을수록, 디스크에서 읽어 들이는 속도는 느려진다.
    
#### OS 레벨 에서의 연구
- OS에서 이를 어느정도 커버하는 작용을 한다.
- OS는 연속된 데이터를 같은 위치에 쌓는데 이는 4KB 단위로 수행한다.
- 비슷한 데이터를 비슷한 위치에 두어 1번 회전으로 읽어들이는 데이터 수를 증가 시켜 이를 완화한다.

#### 전송 속도, 버스의 속도 차이
- 탐색 속도 측면에서 메모리가 디스크에 비해 빠르지만, 이것만의 차이가 아니다.
- 메모리와 디스크 모두 CPU 와 버스로 연결되어 있는데, 이 버스의 전송 속도도 차이가 남.
- 메모리와 CPU는 7.5GB/s, 디스크는 58MB/s 
- SSD로 인해 탐색 속도는 빠르지만, 전송 속도에서 차이가 난다.

#### Linux 단일 호스트의 부하
- 단일 서버의 성능을 충분히 끌어낼 수 있는것을 시작으로 복수 서버의 부하분산이 의미를 가진다.
- **추측하지 말고, 계측하라.**
- 병목 규명작업의 기본 흐름
    - Load Average 확인
    - CPU, I/O 병목 원인 조사

`Load Average 확인`
- 부하 규명의 시작이 되는 지표
- top, uptime 등 명령으로 확인 한다.
- 시스템 전체의 부하상황을 나타내는 지표
- Load Average 는 낮은데, 시스템 전송량이 낮은 경우도 있다.
- 소프트웨어 설정, 오류, 네트워크, 원격 호스트 등을 살펴보라.

`CPU I/O 병목 원인 조사`
- sar, vmstat로 CPU 사용률 과 I/O 대기율 추이 확인
- CPU에 부하가 걸리는 상황 두가지
    - 디스크나 메모리 용량 등 그 밖의 부분에서는 병목이 되지않는 이상적인 상태
    - 프로그램이 폭주하여 CPU에 필요 이상의 부하가 걸리는 경우
- I/O 부하가 높은 경우
    - 프로그램에서 입출력이 많음
    - 스왑이 발생해서 디스크 액세스가 발생하고 있는 상황

> 스왑이 발생하지 않고, 디스크 I/O가 많은 경우 캐시에 필요한 메모리가 부족한 경우도 있다.

- OS 튜닝이란 부하의 원인을 알고 이것을 제거하는 것이다.
- 튜닝의 본질은 하드웨어/소프트웨어가 가지고 있는 본래 성능을 충분히 내도록 문제가 되는 부분을 제거하는것

## 규모조정의 요소

#### 규모조정, 확장성
- 웹 서비스에서는 고가의 하드웨어를 사서 성능을 올리는 **스케일 업 (scale up)** 보다
- 저가이면서 일반적인 성능의 하드웨어를 많이 나열해 전체 성능을 올리는 **스케일 아웃 (scale out)** 전략이 주류이다.

> 하드웨어 성능은 가격과 비례하지 않는다.

#### 규모 조정의 요소 - CPU 부하와 I/O 부하
- 스케일 아웃은 CPU 부하의 확장성을 확보하기는 쉽다.
- 이는 AP 서버에 해당한다 (애플리케이션 서버)
- DB 서버 측면에서는 I/O 부하가 걸린다.

#### 웹 애플리케이션과 부하의 관계
- 기본적으로 AP 서버에는 I/O 부하가 걸리지 않고, DB측에 I/O부하가 걸린다.
- AP 서버는 CPU 부하만 걸리기 때문에 분산이 간단하다.
- 대수를 늘리고, 로드밸런서를 이용해 적절히 분산하기만 하면 되기 때문에 간단하다.
- I/O 부하는 문제가 있다.
- 대수를 늘렸을때, 데이터의 동기화 문제, 쓰기는 간단히 분산할 수가 없다.

#### DB 확장성 확보의 어려움
- DB의 확장성 확보는 상당히 어렵다. 이는 디스크가 느리다는 문제도 한몫을 하고 있다.

#### 두 종류의 부하와 웹 애플리케이션
- 부하는 CPU 부하와 I/O 부하 두가지로 분류 된다.
- 대규모 계산을 하는 프로그램, 이는 I/O는 발생하지 않지만, 계산 속도에 의해 응답 시간이 좌지우지된다.
- 이는 CPU에 부하를 주는 프로그램이다.
- 디스크에 저장된 대량의 데이터를 검색하는 프로그램, 이는 디스크의 읽기속도에 의존한다.
- I/O에 부하를 주는 프로그램이다.

#### 멀티테스킹 OS와 부하
- 여러 OS가 멀티테스킹을 지원하지만, 이는 실제로 매우 짧은 시간간격으로 여러 테스크를 전환해가며, 멀티 테스킹을 실현한다.
- 테스크가 많아질수록,  특정 테스크가 처리중이라면 다른 테스크는 대기를 하게 되는데, '처리를 실행하려고 해도 대기한다' 라는 대기상태가 프로그램 실행 지연으로 나타난다.
- top의 출력 내용에 Load Average (평균 부하) 라는 수치가 포함되어 있다.
- Load Average 가 높을수록 테스크 실행에 대기가 발생하고 있다는 표시이다.

#### Average 가 보고하는 부하의 정체
- 하드웨어는 일정 주기로 CPU에게 인터럽트 신호를 보낸다.
- 주기적으로 보내는 신호라는 점에서 타이머 인터럽트라고 한다.
- 실행 중인 프로세스가 CPU를 얼마나 사용했는지 계산하는 등 시간과 관련된 처리를 한다.
- 커널은 타이머 인터럽트가 발생했을때 테스크 개수를 세어두고, 그 값을 단위 시간으로 계산한것이 Load Average로 보고 된다.

## 대규모 데이터를 다루기 위한 기초지식

#### 대규모 데이터를 다루는 세 가지 급소 - 프로그램 작성 요령
- 요령1. 어떻게 하면 메모리에서 처리를 할 수 있을까 ? 라는 점
    - 메모리에서 처리를 마쳐야하는 이유는 디스크 seek 횟수가 확장성과 성능에 크게 영향을 준다.
- 요령2. 데이터량 증가에 강한 알고리즘을 사용하는것.
    - 레포드 1,000만건이 존재할 때 단순 선형 탐색을 사용하는것 보다 Log Order 알고리즘을 사용하여 탐색 횟수를 줄인다.
- 요령3. 데이터 압축 혹은 검색기술 과 같은 테크닉을 활용한다.
    - 압축하여 데이터량을 줄인다면, 읽어내는 seek 횟수도 적어지게 되므로 I/O 횟수가 줄어든다.
    
> 검색이 중요한 이유는, 확장성 면에서 DB에만 맡겨서 해결할 수 없을 때, 특정 용도에 특화된 검색 엔진등을 만들어 활용하여
> 속도를 확보 한다.

#### 대규모 데이터를 다루기 전 3대 전제 지식 - 프로그램 개발의 한층 아래 기초
- 1. OS 캐시
- 2. 분산을 고려하여 RDBMS 운용시 어떻게 해야만 하는가
- 3. 대규모 환경에서 알고리즘과 데이터 구조를 사용한다는 것은 어떤 것이가

## OS의 캐시 구조

#### OS의 캐시 구조를 알고 애플리케이션 작성하기 - 페이지 캐시
- OS에는 디스크 내의 데이터에 빠르게 액세스할 수 있는 페이지 캐시라 불리는 캐시구조를 가지고 있다.

#### Linux(x86)의 페이징 구조
- OS는 **가상 메모리구조**를 가지고 있으며, 가상 메모리 구조는 논리적인 선형 어드레스를 물리적인 물리 어드레스로 변환하는것.

#### 스왑
- 가상 메모리를 응용한 기능 중 하나로 물리 메모리가 부족할 때 2차 기억장치 (디스크)를 메모리로 간주하여 메모리 부족을 해소하는 원리

#### 가상 메모리 구조
- 가상 메모리가 존재하는 가장 큰 이유는 **물리적인 하드웨어를 OS 레벨에서 추상화** 하기 위해서이다.
- 각 프로세스에서 메모리의 어드레스를 직접 사용하면 여러 문제가 발생한다.
- 프로세스에서 메모리가 필요하다면, OS가 관리중인 메모리에서 비어있는 곳을 사용한다.
- 메모리를 확보할 때에도 디스크를 다룰때와 같이 4KB씩 블록으로 확보해서 프로세스에게 넘기는 이를 **페이지** 라고 한다.

#### Linux의 페이지 캐시 원리
- OS는 확보한 페이지를 메모리상에 계속 확보해두는 기능을 가지고 있따.
- 처리를 마친뒤 불필요하게 되었어도, 이를 해제하지 않고 남겨둠으로 써 다른 프로세스가 재활용할 수 있게 된다.
- 즉, 커널이 한번 할당한 메모리를 해제하지 않고 남겨두는것. 이것이 페이지 캐시의 원리이다.
- 이는 예외인 경우를 제외한 모든 I/O에 작용한다.
- OS를 켜두면 켜둘수록 점점 페이지 캐시가 최적화 되기 때문에 점점 더 빨라진다.

#### VFS
- 디스크 캐시는 페이지 캐시에 의해 제공되지만, 실제 이를 조작하는 디바이스 드라이버와 OS 사이에는 파일시스템이 껴 있다.
- Linux는 ext3, ext2, ext4, xfs 등 몇가지 파일 시스템이 존재하는데 그 하위에 디바이스 드라이버가 있다.
- 이 디바이스 드라이버가 실제 하드디스크를 조작한다.
- 파일 시스템 위에 VFS (Virtual File System) 이라는 추상화 레이어가 있다. 파일 시스템의 인터페이스를 통합하는 것이 역할이다.
- VFS는 페이지 캐시 구조를 지니고 있다.

#### Linux는 페이지 단위로 디스크를 캐싱한다
- OS는 읽어낸 블록 단위만으로 캐싱할 수 있는 범위가 정해진다.
- 디스크 캐싱하는 단위가 페이지 이다.
- 페이지: 가상 메모리의 최소단위

#### LRU
- 메모리 여유분이 1.5GB 존재하고, 파일을 4GB 모두 읽게 될 경우 어떻게 될까 ?
- 구조상 LRU 알고리즘으로 인해 갖아 오래된 것을 파기하고, 가장 새로운것을 남겨 둔다.
- 따라서 DB도 계속 구동시키면 캐시가 점점 최적화 되어, 뒤로 갈수록 부하, I/O가 내려가는 특성을 보인다.

#### 어떻게 캐싱될까? 
- Linux는 파일을 i 노드 번호라고 하는 번호로 식별하며, 해당 파일의 i노드 번호와 해당 파일의 어느 위치부터 시작할지를 나타내는 오프셋.
- 이 두가지 값을 키로 캐싱한다.
- 이 두가지를 키로 하기 때문에 파일 전체가 아닌 파일의 일부를 캐싱할 수 있다.
- 파일이 아무리 크더라도 이 키로부터 해당 페이지를 찾을 때 데이터 구조는 최적화 되어 있으며, **Radix Tree** 라고 한다.

#### 메모리가 비어 있으면 캐싱한다
- Linux는 메모리가 비어있다면 모두 캐싱한다.
- 이는 제한이 없기 때문에 비어있는 캐시 공간에 계속해서 캐싱한다.
- 프로세스에서 메모리를 요청했을 경우, 오래된 캐시를 버리고 프로세스에 메모리를 확보해 준다.

#### 메모리를 늘려서 I/O 부하 줄이기
- 메모리를 늘리면 실제 I/O 부하를 줄일 수 있다.
- 메모리를 늘리면 캐시에 사용 가능한 용량이 늘어나고, 보다 많은 데이터를 캐싱하기 때문에 디스크 I/O 횟수가 줄어든다.

## I/O 부하를 줄이는 방법

#### 캐시를 전제로 한 I/O 줄이는 방법
- 첫 번째 포인트는 데이터 규모에 비해 물리 메모리가 크면 모두 캐싱이 가능하다. 다루고자 하는 데이터의 크기에 주목 할것
- 두 번째는 경제적인 비용과 밸런스를 고려하자. AP 서버는 메모리가 그렇게 많이 필요하지 않으나 DB서버는 많은 메모리를 필요로 한다.

#### 복수 서버로 확장시키기 - 캐시로 해결될 수 없는 규모일 경우
- 데이터를 모두 캐싱할 수 없는 규모일 경우 ?
- 복수서버로 확장 시켜야 한다.
- CPU 분산시에는 단순히 늘린다.
- I/O 분산에는 국소성을 고려해야 한다.

#### 단순히 대수를 늘려서는 확장성을 확보할 수 없다
- 캐시 용량을 늘려야 하는경우 (I/O 분산) 단순히 대수를 늘려서는 해결되지 않는다.
- 애초에 캐시 용량이 부족해서 늘렸지만, 부족한 부분도 그대로 동일하게 늘려가게 된다..
- 캐싱되지 않는 부분은 동일 하다..

## 국소성을 살리는 분산

#### 국소성을 고려한 분산이란 ?
- 캐시 용량을늘리기 위해서는 국소성을 고려한 분산 시켜야 한다.
- 국소성을 고려한 분산이란, 데이터에 대한 엑세스 패턴을 고려해서 분산시키는 것을 국소성을 고려한 분산이라고 한다.

#### 파티셔닝 - 국소성을 고려한 분산
- 국소성을 고려한 분선을 위해 파티셔닝 이라는 기법을 자주 사용한다.
- DB서버를 여러 대로 분할하는 방법
- 분할 방법은 여러가지가 있지만, 간단한 것은 테이블 단위 분할이다.
- 테이블 데이터 분할 방법은 테이블 하나를 여러 작은 테이블로 분할 한다.
- 이런식으로 분할을 하게 되면, 캐싱을 하지 못하는 부분이 사라지게 된다.

#### 요청 패턴을 '섬'으로 분할 - 국소성을 고려한 분산
- 용도별로 시스템을 섬으로 나누는 방법이 있다.
- User-Agent 값을 참조하여, 일반적은 사용자 요청 , 봇의 요청 등을 각각 다른 서버가 처리하도록 만드는 방법
- 일반적인 사용자의 요청은 최상위 페이지나, 인기 페이지에 액세스가 집중되기 때문에 캐싱하기 쉽다.

#### 페이지 캐시를 고려한 운용의 기본 규칙
- OS 기동 직후에 서버를 투입해서는 안된다.
- 캐시가 쌓여 있지않아, 디스크 액세스만 발생하게 되어, 대규모 시스템의 경우 서버가 뻗게 된다.
- 성능평가나, 부하 테스트시에도 캐시가 최적화 된 이후 실시한다.

## 인덱스를 올바르게 운용하기

#### 분산을 고려한 MySQL 운용, 세 가지 포인트
1. OS 캐시 활용
2. 인덱스
3. 확정을 전제로 시스템 설계

#### OS 캐시 활용
- 대량의 데이터를 저장하려는 테이블은 레코드가 가능한 작아지도록 컴팩트하게 설계하자
- 서비스 설계 초기단계 부터 깊게생각할 필요는 없지만, 어느정도 규모가 있는 서비스가 되면 칼럼변경, 스키마 변경에도
그에 상응하는 주의가 필요하다.
- 데이터량 < 물리메모리를 유지하자.

#### 정규화
- 필수항목과 부가 항목을 구분하여 정규화를 하면, 수천만 레코드만큼 용량이 줄어들 수 있다.
- 하지만 경우에 따라 쿼리가 복잡해져 속도가 떨어지는 경우도 있다.
- 모든 설계는 trade-off다.

#### 인덱스의 중요성 - B트리
- 데이터 구조에서 탐색시 기본적으로 트리 구조를 널리 사용한다.
- MySQL 은 기본적으로 B+ 트리 구조를 사용한다.
- 이는 B 트리에서 파생된 데이터 구조이다. (각 노드가 여러 개의 자식을 가질수 있는 다분 트리, 삽입/삭제를 반복해도 치우침이 생기지 않는 평형 트리)

#### 이진트리와 B 트리 비교
- B 트리는 자식 노드의 개수를 지정할 수 있다. 이를 조정함으로 써 4KB 등으로 사이즈를 정할 수 있다.
- 즉 이것이 장점이다.
- OS 는 디스크에서 데이터를 읽을 때 블록 단위로 읽어낸다.
- 이분 트리는 특정 노드를 모아 1블록에 저장하는 작업이 어렵다.
- B 트리는 블록 단위로 저장할 수 있음.
- B+ 트리는 DB에 데이터를 저장하는 좀 더 최적화 된 데이터 구조이다.

#### 인덱스의 효과
- 인덱스 = 색인
- B+ 트리 = 외부 기억장치 탐색시 Seek 횟수를 최소화 하는 트리 구조

#### 인덱스의 작용 - MySQL 의 특성
- 기본적으로 Where, order by, group by 에 지정된 칼럼에 사용된다.
- 복수의 칼럼에 인덱스를 태우고자 할 경우 복합 인덱스를 사용해야 한다.
- MySQL은 한 번의 쿼리에서 하나의 인덱스만 사용한다는 특성을 가지고 있다.

#### 인덱스 작용 확인 - explain 명령
- explain 명령을 사용해 인덱스 작용여부를 확인 가능하다.
- extra 열에서 filesort, temporary 같은 항목이 나올 경우 좋은 쿼리가 아니다.

## MySQL의 분산 - 확장을 전제로 한 시스템 설계

#### MySQL의 레플리케이션 기능
- MySQL에는 레플리케이션 기능이 있다.
- 마스터 - 슬레이브를 지정해 두어, 마스터에서 write 한 내용을 슬레이브가 polling 하여 동일한 내용으로 갱신하는 기능이다.
- 동일한 내용의 서버를 여러대 마련할 수 있다.
- 애플리케이션 구현단에서 select 쿼리만 슬레이브로 보내고, 슬레이브 앞단에 로드밸런서 혹은 MySQL Proxy를 사용해 요청을 분산한다.

#### 마스터/슬레이브 특징 - 참조 계열은 확장하고 갱신 계열은 확장하지 않는다.
- 마스터는 확장할 수 없다.
- 갱신 계열 쿼리가 늘어나게되면 동시성 문제가 발생하게된다.
- 또한 웹 애플리케이션 에서는 쓰는 행위보다 읽는 행위가 90%이상을 차지하기 대문에 마스터가 병목되어 장애가 발생하는 상황은
그리 많지 않다.

#### 갱신/쓰기 계열 확장시 - 테이블 분할, key-value 스토어
- 매우 드물지만 마스터에 엄청난 쓰기 작업이 발생하는 애플리케이션을 개발할 때가 있다.
- 이럴 경우 테이블을 작게 분할해서 쓰기 작업을 분산시키거나, RDBMS를 사용하지 않고, KVS (key-value 스토리지)를 사용하는 방법이 있다.
- key-value 스토리지는 오버헤드가 적고 압도적으로 빠르며 확장하기 쉽다.

> 애플리케이션 측면에서 쓰기 작업 횟수를 줄이는 것은 당연히 고려되어야 한다.

## MySQL의 스케일아웃과 파티셔닝

#### MySQL의 스케일아웃 전략
- 기본적인 스케일 아웃 전략은 데이터가 메모리에 올라가는 크기라면, 메모리에 올리고, 아닐경우 메모리 증설. 인덱스를 제대로 걸자.

#### 파티셔닝에 관한 보충
- 파티셔닝이란 테이블 A와 테이블 B를 서로 다른 서버에 놓아 분산하는 방법
- 파티셔닝은 국소성을 활용한 분산이 가능하기 때문에 캐시가 유효하고 때문에 파티셔닝은 효과적이다.

#### 파티셔닝을 전재로 한 설계
- 파티셔닝을 전제로한 설계가 중요하다.
- JOIN 쿼리를 날리기 위해서는 관련 있는 테이블 A, B를 분할 할 수 없다. (이는 다른 머신으로 나눈다는 의미)
- MySQL은 서로 다른 서버에 있는 테이블을 JOIN하는 기능이 기본적으로 없다. (5.1 에서는 REDERATED 테이블 이용시 가능)
- JOIN 쿼리는 대상이 되는 테이블을 아픙로도 서버 분할하지 않을 것이라 보장할 수 있을때만 사용한다.

#### JOIN 배제 - where ... in 
- INNER JOIN 을 사용하지 않고, 쿼리를 두번에 나눠서 where id in (...) 쿼리를 사용하면 동일한 데이터를 얻을 수 있다.

#### 파티셔닝의 상반관계
- 파티셔닝으로 분산을 할 수 있지만 상반관계가 존재한다.
- 장점은 부하가 내려가고 국소성이 늘어나 캐시효과가 높아진다.
- 단점은 운용이 복잡해진다.
- 고장률이 높아진다.

#### 다중화에 필요한 서버 대수는 몇대 ?
- 다중화에 필요한 서버수는 보통 4대라고 한다.
- 한대는 마스터 3대는 슬레이브로 묶어서 4대를 한 단위로 묶어서 관리한다.
- 그 이유는 마스터가 죽으면 슬레이브 중 한대를 마스터로 승격시키면 되지만
- 슬레이브가 죽을경우 남은 2대중 1대를 내리고 데이터 복제를하여 복구해야하기 때문이다.

#### 애플리케이션의 용도와 서버 대수
- 위의 경우 처럼 분할할 경우 4대였던것이 8대가 되고, 3대로 분할하면 12대가 되어 점점 늘어난다..
- 이럴 경우 반드시 4대가 필요한지 여부를 체크해야한다.
- 일부 기능 정지가 가능한 서비스라면 꼭 4대를 한세트로 유지하지 않아도 된다. (비용 절감)

## 이론과 실전 양쪽과의 싸움

#### 요구되는 기술 요건 규명하기
- RDBMS JOIN을 사용하지 않는것. 과 같은 방법을 배드 노하우일 것이다.
- 나중에 분할될 것을 고려하여 JOIN을 하지말라. 는 '실전적인 노하우' 인 것이다.

#### 대규모 웹 애플리케이션에 있어서 이론과 실전
- 대규모 웹 애플리케이션을 개발, 운용시 이론과 실전 모두를 하지 않으면 안된다.
- 이론과 실전 사이에 균형을 잘 맞춰 실행하는것이 중요하다.

#### 컴퓨터의 문제에 이르는 길을 어떻게 발견할까?
- 이론적으로 배울 뿐만 아니라 응용을 위한 이치를 어느 정도 익혀두는 것도 중요하다.

## 알고리즘과 평가

#### 데이터 규모와 계산량 차이
- 대상 데이터가 클수록 알고리즘이나 데이터 구조 선택이 속도에 영향을 미친다.
- 알고리즘 성능을 측정할 대 최대 탐색 횟수를 계산횟수의 기준이 되는 수로 "계산량" 이라고 한다.

#### 알고리즘이란 ?
- 어떤 값 또는 값의 집합을 입력으로 하고 어떤 값 또는 값의 집합을 출력으로 하는 명확하게 정의된 계산절차이다.

#### 좁은 의미의 알고리즘, 넓은 의미의 알고리즘
- DB에서 레코드를 얻어 적절히 출력하는것 처럼 보통 아무렇지 않게 작성하는 프로그램에 대해서도 "알고리즘이 어떻게 되어있나?"
- 라고 하는 이부분은 도메인 로직 일것이다. 이는 넓은 의미의 알고리즘 이라고 한다.
- 좁은 의미에서의 알고리즘은 정렬 혹은 탐색, 해시와 같은 계산문제의 해법에 대해 논의되고 있는 것이다.

#### 알고리즘을 배우는 의의
- 컴퓨터 자원은 유한하기 때문에, 알고리즘에 대해 배우는것은 중요하다.
- 알고리즘은 디자인 패턴과 마찬가지로 엔지니어에게 공통 언어이다.
- "그 부분은 해시를 사용하면 되잖아" 와 같이 커뮤니케이션을 완료하기 위해 해시가무엇인지 이해해둘 필요가 있다.
- 대규모 데이터를 앞 둔 경우에도 알고리즘이 애플리케이션 성능에 큰 영향을 주기 때문에, 그런 감각을 익히기 위해 알고리즘 학습은 매우 중요하다.

#### 알고리즘의 평가 - 빅오 표기법
- 선형 탐색은 O(n), 이분 탐색은 O(log n) 이라고 한다. 이런 표기법을 빅오 표기법 이라고 한다.
- 입력의 크기가 n 일 때 대략적으로 어느정도 계산이 소요된다는 표기법 이다.
- 특정 상황을 다루는 것이 아닌, 평군 혹은 최대를 평가 한다는것이 핵심이다.

#### 각종 알고리즘의 빅오 표기
- O(1), O(log n) < O(n) < O(n log n) < O(n2) < ... O(2n)
- 우측으로 갈수록 계산량은 많아진다.
- 계산량
    - 시간 복잡도 (실행시간, 단계 횟수)
    - 공간 복잡도 (메모리 사용량)

#### 알고리즘과 데이터 구조
- 알고리즘과 데이터 구조는 뗄수 없는 관계이다.
- 알고리즘에서 자주 사용하는 조작에 맞춰 데이터 구조를 선택할 필요가 있기 때문이다.

#### 계산량과 상수항 - 측정이 중요하다
- 계산량의 빅오 표기법에서는 상수항을 무시한다.
- 상수항이란 해당 알고리즘을 구현하는 중 입력 크기에 의존하지 않지만, 실행하지 않으면 안되는 처리의 일종
- 빅 오 표기법은 알고리즘을 비교할 땐 편리하지만 구현을 포함하여 생각할 때 그게 전부가 아니라는 의미이다.
- 상수항을 줄이기 위해 노력을 기울여야 한다.

#### 구현시 유의해야하는 최적화 이야기
- 처음부터 최적화를 수행하는 것은 대체로 잘못된 방침이다.
- 계산량 O(n2) 인 알고리즘을 대체할 수 있는 O(n log n)이 있다면 후자를 사용하는것이 전자를 최적화하는 것 보다 나을것이다.
- "측정이 중요하다" 는 의미 이다.

#### 알고리즘의 실제 활용 - 측정이 중요하다
- 예측이나 축정이 중요하다.
- 때에 따라서는 명쾌하게 단순한 구현을 시도해보는 것도 좋다.
- 데이터 건수가 적을 경우 최적화가 의미가 없다.

## 하테나 다이어리의 키워드 링크

#### 키워드 링크란 ?
- wiki 처럼 워드에 링크하는 기능이다.
- 기존에는 특정 키워드를 정규식을 사용해서 구현 하였다.
- 하지만 키워드가 많아질수록 시간이 오래 걸리는 문제가 발생함
- 1. 정규표현을 컴파일 처리
- 2. 정규표현에서 패턴 매칭하는 처리
> 위 두가지 모두 캐싱을 이용해서 어느정도 회피가 가능하지만 근본적인 해결방법은 아니었다.

#### 정규표현식 -> Trie - 매칭 구현 변경
- Trie 는 트리구조의 일종인 데이터 구조이다.
- 탐색 대상 데이터의 공통 접두사를 모아서 트리구조를 이루는것이 그특징이다.
- ab, abcde, bc, bab, d 는 ab와 abcde 는 ab라는 공통 접두사를 갖고 있으며 공통 접두사를 정리함으로써 불필요한 것을 배제하는 것이 특징 ㄴ

#### Trie 구조와 패턴 매칭
- Trie 구조를 사전과 비교하며 패턴 매칭을 하면 정규표현식 보다 계산량을 줄일 수 있다.
- Trie 에 입력 문서를 입력 한 뒤, 엣지를 순회 하며 종단이 발견되면 해당 단어가 포함되어 있음을 간주하는 것이다.

#### AC법 - Trie 에 의한 매칭을 좀 더 빠르게
- Aho-Corasick 이라는 방법 이다.
- 사전 내에서 패턴매칭을 수행하는 오토마톤을 구축하고 입력 텍스트에 대해 선형 계산시간을 실현한다.
- 계산량이 사전크기에 의존하지 않는 빠른 방법이다.
- Trie에서 패턴 매칭으로 매칭이 진행되다가, 도중에 실패한 경우 되도아 오는 길의 엣지를 Trie에 추가한 데이터 구조를 사용하는 방법

> 처음 부터 최적의 구현을 사용하는것이 반드시 옳다고는 할 수 없다.

## 하테나 북마크의 기사 분류

#### 기사 분류란 ?
- 과학.학문 혹은 컴퓨터.IT 와 같은 카테고리에 기사 분류

#### 베이지안 필터에 의한 카테고리 판정
- 베이지안 필터를 사용한다. (스팸필터 등에도 응용되고 있음)
- 베이지안 필터는 텍스트 문서 등을 입력으로 받아, 나이브 베이즈 라는 알고리즘을 적용하여 확률적으로 해당 문서가 어느
카테고리에 해당하는지 판정하는 프로그램이다.
- 데이터의 통계 정보로 부터 판정을 수행한다.

#### 기계학습과 대규모 데이터
- 베이지안 필터에는 대량의 정해 데이터를 필요로 하지는 않지만, 기계학습의 테스크에 따라 데이터가 많을수록 정밀도가 향상된다.

#### 대규모 데이터와 웹 서비스
- 구글 검색을 사용하면 잘못된 검색 쿼리에 대해 '이것을 찾으셨나요 ?' 하고 쿼리 추천기능을 보았을 것이다.
- 이는 사용자가 검색한 쿼리로그를 정해 데이터로 사용하여, 잘못입력한경우 이렇게 다시 검색한다 라고 학습된 것이다.

#### 베이지안 필터의 원리
- 베이지안 필터의 핵심은 나이브 베이즈라는 알고리즘 이다.
- 베이즈의 정리라는 공식을 기반으로 하고있는 알고리즘
- 나이브 베이즈에서 카테고리 추정은 문서 D가 주어졌을때 카테고리인 C의 조건부 확률을 구하는 문제이다.
- P(C|D)
- 위 문제를 변형하면 P(C|D) = P(D|C) P(C) / P(D)
- 우변의 각 확률을 구하는 문제로 생각할 수 있음
- 구체적인 확률값이 아닌 각 카테고리로 비교하여, 어떤 확률이 젤 높은지를 나타낸 순위가 중요하다.
- 결과적으로 생각할 값은 두가지로 좁혀진다.
- P(D|C), P(C)
> 카테고리 추정시 이 두가지 값을 학습 데이터의 통계정버로부터 산출하면 된다.

#### 수비 자세와 공격 자세
- 동일한 알고리즘 이라도 대량의 데이터를 빠르게 정렬, 검색, 압축하는 일은 발생하는 문제를 얼마나 잘 맞아들이는가 라는 '수비'
- 기계학습이나 패턴인식 등은 적극적으로 데이터를 응용하고 그 결과에 따라 부가가치를 창출하는 의미로 '공격' 적인 자세로 표현한다.

## 검색 시스템의 아키텍쳐

#### 검색 시스템이 완성되기까지
- 검색을 할 수 있을 때 까지의 과정
1. 크롤링
    - 검색할 대상 문서를 가져온다.
2. 저장
    - 어떻게 저장할 것인가 ? 단일 DB에 넣을 경우 복원이 불가능 하므로 분산 해서 저장해야 한다.
3. 인덱싱
    - 고속으로 검색하기 위한 구조, 색인이다.
4. 검색
5. 스코어링
6. 결과표시

#### 전문 검색의 종류
- grep 형
- Suffix 형
- 역 인덱스 형

#### grep 형
- 검색 대상 문서를 처음부터 전부 읽어가는 단순한 아키텍쳐
- 검색 대상 텍스트 길이를 m, 검색어의 길이를 n 이라 했을때, O(mn) 이다.
- KMP 법, BM 법 등 어느정도 계산량을 개선한 방법 등이 있다.

#### Suffix 형
- 검색 대상 전문을 검색 가능한 형태로 가지고 있다.
- 데이터 구조는 Trie, Suffix Array, Suffix Tree 등이 있다.
- 문서를 검색가능한 형태로 전부 메모리에 올릴수 있기 때문에 빠르게 검색 할 수 있다.

> 이론적으로는 가능하나, 정보량이 크고 구현이 어렵다.

#### 역 인덱스 형
- 현재 주류인 방식
- term 과 문서를 연관짓는다.
- 역 인덱스를 문서와는 별개로 만들어야 하며, 전처리 과정이 필요하기 때문에 실시간 검색이 불가능하다. (준 리얼타임)
- 인덱스를 압축함으로써 컴팩트하게 가져가고 대규모하기도 쉽다.

> 밸런스가 좋은 아키텍쳐 이며 상당수가 역 인덱스 방식을 사용한다. 

## 검색엔진의 내부구조

#### 역 인덱스의 구조 - Dictionary + Postings
- 역 인덱스의 내부구조는 Dictionary 와 Postings 두 파트로 나뉜다.
- term 들의 집합이 Dictionary, 각 term을 포함하는 문서는 몇번인지 나열한 것이 Postings이다.

#### Dictionary 를 만드는 방법
- 사전을 이용해 단어를 구분하는 방법, n-gram 을 활용한 방법, 형태소 분석을 사용하는 방법 등이 있다.

#### 사전 + AC법을 이용하는 방법
- 사전이 곧 검색 시스템의 단어 공간이 된다.
- Wikipedia의 표제어만을 사용해서 검색할 수 있도록 하는 방법이 있다.

#### 형태소 분석을 이용하는 방법
- 형태로 분석기를 이용해 term으로 사용한다.

#### n-gram을 이용하는 방법
- n-gram으로 잘라낸 단위를 term으로서 다루는 방법이 있다.
- n-gram을 사용할 경우 쿼리도 동일한 규칙으로 분할해서 사용한다.

#### 재현률과 적합률
- 재현률: 어느 정도의 양, 결과를 반환하는가
- 적합률: 얼마나 명백히 타당한 결과를 반환하는가

#### Postings 작성법
- 단순하게 문서의 ID만을 보유하는 방법이 있다.
- 또는 term이 해당 문서 내에 어느 위치에 출현하는지 그 출현위치를 저장하는 경우도 있다. 이를 "Full Inverted Index" 라고 한다.
- 출현위치를 알고 있다면, 스니핏을 뽑아낼 때 어디에 포함되었는지 바로 알 수 잇으며, 스코어링에도 도움이 된다.

## 엔터프라이즈 vs 웹서비스

#### 웹 서비스의 특징
- 트래픽 - 대용량 트래픽이 발생할 가능성이 농후
- 성장속도 - 엔터프라이즈계열 대비 매우 압도적
- 신뢰성 - 엔터프라이즈의 경우 매우 높은 신뢰도가 필요하지만 반면 그렇게 높은 레벨의 신뢰도가 필요하지 않음
- 트랜잭션 - 엔터프라이즈의 경우 데이터간 정합성을 정확하게 유지해야 한다. 하지만 웹 서비스는 일시적인 정합성이 일치하지 않아도 허용하도록 처리하는 경우도 있다.

#### 웹 서비스의 인프라 - 중요시 되는 세 가지 포인트
1. 저비용 고효율이 중시된다.
    - trade-off
    - 100%의 신뢰성을 목표로 하지 않는다.
    - 오히려 비용을 낮춰 효율을 높히는 방향으로 추진한다.
2. 확장성이나 응답성 등 설계를 중요시한다.
    - 100% 신뢰성 보다 장래를 위한 확장중시
3. 유연하게 대응가능한 인프라여야 한다.
    - 개발속도를 중시한 인프라로 구성해가는것도 중요
    - 무중단 배포, 자동화 시스템이 중요

## 클라우드 vs 자체구축 인프라

#### 클라우드 컴퓨팅
- 유명한 클라우드 컴퓨팅 서비스는 Amanzon EC2 가 있다.
- 최대의 장점은 **확장성**
- 단점은 각 클라우드 서비스마다 독자적인 사양에 대응해야 한다.
- 서비스 규모가 커질수록 아직 자체구축 인프라를 구축하는게 유리하다.

#### 자체구축 인프라의 장점
1. 하드웨어 구성을 유연하게 할 수 있다.
2. 서비스로부터 요청에 유연하게 대응할 수 있다.
3. 병목현상을 제어할 수 있다.

#### 자체구축 인프라와 수직통합 모델
- 기술 모델은 수직통합 모델, 수평분산 모델 이라는 개념이 있음
- 수직 통합 모델
    - 물리적인 계층 부터 서비스 설계까지 모든 것을 한 회사에서 구축
- 수평 분산 모델
    - 각 계층마다 다른 기업이 시스템을 제공하는 것

## 계층과 확장성

#### 확장성에 대한 요구 - 서버 1대에서 처리가능한 트래픽 한계
- 보통 4core CPU, 8GB 메모리 서버를 사용하면 피크 시 성능이 수천요청/분 정도가 나온다.
- 이 경우 보통 월 100만 PV (Page View) 정도를 처리할 수 있다.

#### 계층별 확장성
- API 서버는 기본적으로 깊은 부분까지 생각하지 않아도 비교적 간단하게 확장이 가능하다.
- API 서버는 상태를 가지고있지 않기 때문에, 요청별로 다른 서버로 날려도 처리상 문제가 발생되지 않으며 로드밸런스에 추가하면 점점 확장 된다.
- 반면 DB나 파일서버는 호가장이 매우 어렵다.
- READ는 쉬우나, WRITE 를 분산하는 것은 매우 어렵다.

## 부하 파악, 튜닝

#### 부하를 측정하기 위한 항목 - Load Average, 메모리, CPU
- 부하 측정시 Load Average 부터 살펴본다.
- Load Average
    - Linux 내에는 프로세스가 다수 동작한다.
    - Load Average 란 프로세스를 처리할 CPU가 할당되지 않아 대기상태에 있는 프로세스 수의 평균치이다.
   
> 대체로 CPU 코어수 이하에서 절반 정도로 맞춰지도록 제어 한다. 하지만 절대적인 수치는 아니며 용도에 따라 달라진다.

#### 용도에 맞는 튜닝
- 사용자용 AP 서버와 봇용 AP 서버의 경우 튜닝의 방향이 달라져야한다.
- 사용자용 서버는 양호한 응답 시간을 위해 이를 중점적을 튜닝한다. Load Average 를 낮게 유지한다.
- 봇은 응답시간이 그다지 중요하지 않으므로 요청 처리수를 최대화 하는 방법을 택하기 때문에 Load Average 가 높게 나온다. 

#### 서비스 규모와 튜닝
- 튜닝 작업을 반복하다보면 서버 대수가 늘어났을때 비정상적인 거동을 하고잇는 서버를 찾는 방법이 과제가 된다.

#### 확장성 확보
- 로드밸런서나 파티셔닝을 해야 한다.
- LVS (Linux Virtual Server) 라는 커널에 포함된 로드밸런서를 사용한다.

## 다중성 확보

#### 다중성 확보 - API 서버
- API서버에서는 확장성을 생각하는 방식과 동일하게 여러 서버를 놓는게 기본이다.
- 요점은 **1대나 2대가 정지 되더라도 충분히 처리 가능하도록 처리 능력을 확보해 두는것**
- 서버 정지에 대한 대응으로 로드 밸런서를 활용한 페일오버(fail-over) - 페일백(fail-back) 전략을 사용한다.
    - 정지된 서버를 자동적으로 분리 (페일 오버)
    - 복구된다면 원상복귀 (페일 백)
- 로드밸런서는 주기적으로 헬스체크를 진행한다.

#### 다중성 확보 - DB 서버
- DB도 마찬가지로 여러 서버를 놓고, 1대나 2대가 정지 되더라도 충분히 처리 가능하도록 처리 능력을 확보해 두어야한다.
- 또한 마스터의 다중화도 중요하다. 이는 **멀티 마스터** 라는 방법을 사용한다.
    - 서로가 서로의 슬레이브가 되는 상태로 해두어, 한쪽에서 write한다면, 다른쪽에서는 싱크를 맞추는 방식이다.
    - MySQL은 약간이나마 지연이 존재하지만 이는 감안하고 계속해서 작동하는데에 중점을 둔다.
    - 엔터프라이즈에서는 슬레이브까지 데이터 싱크를 맞춘 뒤 클라이언트에 응답을 반환하는 방법으로 극복하는데, 이는 성능상 큰 손실이 발생한다.

#### 멀티 마스터
- VRRP(Virtual Router Redundancy Protocol) 이라는 프로토콜로 상호간에 감시하여 한쪽이 분리되면, Active 로 승격한다.
- 멀티 마스터 구성에서는 서버는 기본적으로 2대가 있으며, Active/Standby 구성을 한다.
- 한쪽은 항상 Active로 Write 작업만, 한쪽은 Standby 형태로 항상 싱크만 맞추며 대기를 하다가, Active 서버가 다운되면 Standby 가 Active로 승격한다.
- **원래 VRRP는 라우터용으로 개발된 프로토콜**이다.
- Active 서버A = 1, Standby 서버 B는 = 2 라고하자.
- 이 때 클라이언트에서 접근가능한 가상 IP인 3을 Active에게 부여한다.
- 운영중 Active가 장애가나서 Standby 서버가 Active가 되었다면 가상 IP인 3을 Active가 된 서버에게 부여하여 **마스터의 전환을 API 서버 입장에서 은폐하고 있다.**

#### 다중성 확보 - 스토리지 서버
- 분산 파일 시스템을 사용함으로써 대량의 파일을 보존가능한 확장성과 일부 서버가 다운되더라도 전체 장애로 이어지지 않는 다중성 확보가 가능하다.
- 스토리지 노드 1대당 용량을 너무 높히게 되면, 그 안에 저장된 파일수가 너무 많아져서 I/O 병목 현상이 일어나 100% 용량을 다 상요할 수 없는 경우도 발생한다.
- 분산 파일 시스템은 특정 노드가 다운되었을때 다른 노드로 데이터를 이동, 액세스가 편중될 때 이를 평준화 하는 등 여러 기술이 있다.

## 시스템 안정화

#### 시스템 안정화를 위한 상반 관계
- 안전성과 자원효율 간에는 상반관계가 있으며, 안정성과 속도도 상반관계가 있다.
- 메모리 상한선을 너무 높게 잡을 경우, 메모리 누수가 발생하여 메모리 소비량이 증가 했을경우, 스왑이 발생하여 성능이 저하되고 서비스 장애로 이어진다.
- CPU를 한계에 다다를정도로 사용할 경우, 1대에서 장애날 경우 전체적인 처리능력이 부족하여 장애가 발생하는 경우도 있다.

> 메모리와 CPU를 7할 정도 까지만 사용하게끔 어느정도 여유를 가질 수 있게 설계하는 것이 중요하다.

#### 시스템 불안정 요인
1. 기능추가
2. 메모리 누수
3. 지뢰
    - 특정 URL이 읽히면 마치 지뢰처럼 긴 시간동안 응답이 오지 않아 장애의 원인이 되는 현상
4. 사용자의 액세스 패턴
    - 급작스러운 트래픽 증가로 인한 문제: 캐시를 활용
5. 데이터량 증가
    - 비정상적으로 데이터량이 늘어날 경우 문제가 발생: 설계를 바꾸는 방식으로 해결
6. 외부연계 추가
    - 광고 관련 API 나 Amazon 등 다양한 API 와 연계중 해당 외부서비스가 장애가 났을경우 서비스가 연달아 장애나는 현상
    - 장애가 났을경우 그 부분만 동작을 멈춘다거나 하는 등 설계가 필요함
7. 메모리, HDD, NIC 장애
    - 로드밸런서를 활용해 적절히 헬스체크를 해서 하드웨어 장애로 이상이 있는경우 해당 요청을 보내지 않도록 조치한다.

## 시스템 안정화 대책

#### 실제 안정화 대책 - 적절한 버퍼 유지와 불안정 요인 제거
- 적절한 버퍼 유지를 위하 한계의 7할 운용을 수행한다.
- SQL 부하대책
    - 1시간마다 배치 SQL 을 사용자용 DB가 아닌, 배치용 DB에 날리는 방법을 사용해 부하를 줄인다.

#### 이상 동작시 자율 제어
- 자동 DoS 판단
    - 리로드를 반복하는 행위가 있다. 해당 대처방안으로 자동 DoS 판정을 수행하도록 해서 당분간 403 응답으로 차단한다. 
- 자동 재시작
    - 어느정도 리소스를 지나치게 사용했다고 판단 한 경우 웹서버를 재시작 하여 리소스 안정화를 수행한다. 
- 자동 쿼리 제거
    - 소요시간이 긴 SQL을 KILL 한다.
    
## 가상화 기술

#### 가상화 기술의 도입
- 가상화 기술의 목적
    - 확장성
        - 오버헤드 최소화
    - 비용대비 성능
        - 리소스 사용률 향상
        - 운용의 유연함
    - 고가용성
        - 환경의 격리

#### 가상화 기술의 효용
1. IPMI를 대체하는 하이퍼바이저
    - 벤더 서버에는 IPMI(Intelligent Platform Management Interface) 라는 리모트 관리기능이 존재함
    - 이를 대체해서 하이퍼 바이저 를 사용할 수 있음 (이른바 호스트 OS)
2. 하드웨어 간 차이를 흡수 (환경 추상화)
3. 준 가상화 (ParaVirtualization)
4. 리소스 소비 제어 (과부하 경고, 부하 조정)

#### 가상화 서버 구축정책
- 가상화 기술 도입 기본목적 => 하드웨어 이용효율의 향상
    - CPU 리소스가 남는다면 웹서버로, I/O 리소스가 남는다면 DB, 메모리가 남는다면 캐시 서버로 투입한다.
> 리소스 소비성향이 비슷하고 부하가 높은 용도의 게스트 OS 끼리는 서로 점유 경쟁이 일어나므로 같이 두는것을 피한다.

* 가상화 기술을 도입할 때 중앙 스토리지 형태의 파일시스템을 구성하는것은 피한다.
    - 고가의 스토리지 서버를 사용하지 않으면 안정성 확보가 힘들기 때문
    
#### 가상화로 얻은 장점
- 물리적인 리소스 제약에서 벗어나 동적으로 변경이 가능하고 게스트 OS의 마이그레이션이나 복제가 용이해 졌다.
    - 서버 증설이 용이하고 확장성을 확보할 수 있다.
- 소프트웨어 레벨에서 호스트 리소스를 제어할 수 있고, 비정상 동작 시 문제를 국소화 시키고 호스트를 쉽게 제어할 수 있다.
    - 효율이 향상되고, 시스템을 전체적으로 안정화 가능함
    
#### 가상화 도입시 주의할 점
- 전형적인 단점으로는 성능상 오버헤드가 존재한다.
    - CPU 2~3%
    - 메모리 성능 1할
    - 네트워크 성능 절반
    - I/O 성능이 5%
> 가상화 기술이 만능은 아니며, 용도에 따라 가상화를 사용하지 않는 곳도 존재

## 하드웨어와 효율 향상 - 저비용을 실현하는 요소기술

#### 프로세서의 성능향상
- 무어의 법칙
    - 집적회로 상의 트랜지스터 수는 18개월 마다 2배로 증가한다.
    
#### 저가 하드웨어의 유용한 이용법 - 가상화를 전제로 한 하드웨어 사용
- 최소한의 관리기능
- 많은 core CPU
- 대량의 메모리
- flexible한 I/O 성능
    - Diskless
    - 하드웨어 RAID-10
    - SSD RAID-0
- 관리용 하드콘솔 불필요

#### SSD
- DB 서버를 기준으로 메모리 32GB 서버와, 8GB + SSD 서버를 비교 했을때 다음과 같다.
- 32GB서버
    - 데이터가 전부 메모리에 올라가 있으므로 write I/O 만 발생함
- 8GB + SSD 서버
    - 메모리에 거의 올라가지 않아 대량의 read I/O 발생
> 성능면으로 봤을때는 LoadAverage 는 비슷하고, 쿼리 성능도 비슷하다. (성능면에서 비용으로 같은 효과를 냄)

## 네트워크 분기점

#### 서비스 성장과 네트워크 분기점
- 1Gbps -> 30만pps 이상
    - PC 라우터의 한계
- 500호스트 이상
    - 1 서브넷의 한계
- 글로벌화
    - 1 데이터 센터의 한계
    
#### 500 호스트의 한계 - 1서브넷, ARP 테이블에서의 한계
- 스위치의 ARP 테이블 (Address Resolution Protocol Table)과 관련해서 한계가 있다.
    - ARP 테이블은 간단히 설명하면 Ethernet 통신을 할 때 IP주소와 MAC 주소간의 매핑 정보를 가지고 있는것
- ARP 테이블의 내용이 800건 이상까지 늘어나자 특정 호스트로 ping이 가지 않는 등 통신을 할 수 없게 되었다.
- 서버내에 호스트를 많이 두면 브로드캐스팅 패킷이 증가하며, 이는 CPU에 부하를 주게 된다.
- 호스트는 500개가 그 분기점인듯 하다.

#### 네트워크 구조의 계층화
- 베스트 프랙티스는 3단 구조로 구성하는 것이 좋다.
- 액세스 계층
    - 서버로의 엔드포인트를 제공
- 디스트리뷰션 계층
    - 트래픽을 각 서브넷에 전송
- Core 혹은 OSPF(Open Shortest Path First) 계층
    - 트래픽의 큰 흐름을 담당
> 가장 작은 서브넷이 100 ~ 200대, 디스트리뷰션 1000대, 코어 전체는 10,000대를 다룰수 있는 계층 구조를 설계하는 것이 일반적

#### 글로벌화 와 CDN
- 태평양을 넘는 액세스는 상당한 오버헤드
- CDN을 사용하면 2~30초가 걸리던 다운로드를 5~6초 대로 줄일 수 있다.
- CDN 이란 Content Delivery Network 이며 세계 각 지에 서버를 두고, 거기에 미디어를 캐싱하여 사용자가 가져갈 때 가장 가까운 서버로 부터 다운로드 하는것

## 한층 높은 단계로

#### 10Gbps 이상의 세계
- 10Gbps 이상의 세계에서는 AS 번호 (Autonomous System number) 를 보유하고, IX (Internet Exchange) 에 트래픽을 교환하거나
BGP (Boarder Gateway Protocol) 이라는 인터넷 라우팅을 제어하는 프로토콜을 사용한다.
> 잘못 제어하게 될 경우 다른 사이트에도 영향을 미친다..

## 작업 큐 (Job Queue) 시스템

#### 웹 서비스와 요청
- 웹 서비스에서는 기본적으로 요청이 동기적으로 실행된다.
- 데이터가 쌓일수록 데이터 추가/갱신 처리가 점점 무거워 지기 때문에 사용자 경험에 악영향을 미친다.
- 작업 큐를 사용해 나중에 처리해도 문제가없는 테스크 들을 비동기로 실행할 수 있따.

#### 작업 큐 시스템 입문
- 가장 간단한 방법은 비동기 처리를 독립된 스크립트로 작성해 해당 스크립트를 애플리케이션 내부에서 호출한다.
    - 이 방법은 시작 및 초기화 오버헤드가 커서 성능이 좋지 않다.
- 어느정도 양이 있는 비동기 처리를 안정적으로 수행하려면 작업큐 - 워커 를 한세트로 사용하는것이 일반적이다.
    - 워커를 항상 실행 해 둠으로ㅓ써 초기화 오버헤드를 제거한다.
    
#### 로그 분석
- WorkerManager를 두어 워커가 작업 처리했을 때 타임 스탬프를 기록한다.
- 처리시간과 지연시간을 측정함으로써 투입된 작업 종류와 양에 대해 워커 능력을 측정하고, 튜닝 및 보강을 생각한다.

## 스토리지 선택 - RDBMS 와 Key-Value 스토어

#### 웹 애플리케이션과 스토리지
- 스토리지란 애플리케이션 데이터를 영속 혹은 일시적으로 저장하기 위한 기능 이란 의미
- 원본 데이터 부터 원본 데이터를 가공함으로써 나오는 데이터 등 다양한 특성이 있다.

#### 적절한 스토리지 선택의 어려움
- 스토리지 설계와 구현은 다양한 종류가 있으며 오픈소수도 다수 존재한다.
- 데이터 특성에 맞는 스토리지를 선택하는것이 비용과 성능 안정성의 규현을 높은 차원으로 만든다.

#### 스토리지 선택의 전제 조건
- 애플리케이션의 액세스 패턴을 이해하는것이 중요
1. 평균크기
2. 최대크기
3. 신규추가빈도
4. 갱신빈도
5. 삭제빈도
6. 참조빈도

#### 스토리지의 종류
1. RDBMS - MySQL, PostgresSQL 등
2. 분산 key-value 스토어 - memcached 등
3. 분산 파일시스템 - MogileFS, GlusterFS 등
4. NFS 계열 파일시스템, DRBD, HDFS 등

#### RDBMS
- RDBMS란 표 형태로 데이터를 저장하고 SQL 을 질의하여 데이터를 조작할 수 있다.
- 오픈소스는 대표적으로 MySQL, PostgresSQL등 이 있다.

#### MySQL
- MySQL의 아키텍쳐는 SQL 을 해석해서 실행하는 기능 블록, 데이터를 보관하는 기능 블록이 분리되어 있다는게 특징
- 후자는 보통 스토리지 엔진이라고 불린다.
- 주요 스토리지 엔진은 MyISAM, InnoDB가 있다.

#### MyISAM
- MySQL 5.1 버전의 표준 스토리지 엔진이다.
- 심플한 구조를 한 엔진으로, 1개의 테이블이 실제 파일 시스템 상의 3개의 파일 (정의, 인덱스, 데이터)로 표현된다.
- insert 처리가 빠르다.
- 하지만 DB 프로시스가 비정상 종료된다면 테이블 파손 가능성이 높고, 트랜잭션 기능이 없으며, update, delete, insert 가 테이블 락으로 되어 있어
성능상 불리하다.

#### InnoDB
- MyISAM 과 대조적인 스토리지 엔진이다.
- 스토리지 엔진 전체에서 사전 정의한 소수의 파일에 데이터를 저장하고, 트랜잭션 지원, 복구기능, 데이터 갱신이 로우 레벨 락으로 되어 있다.

|액세스 패턴|적합한 스토리지 엔진|
|---|---|
|추가처리만한다|MyISAM|
|갱신빈도가높다|InnoDB|
|트랜잭션이 필요하다|InnoDB|
|SELECT COUNT(*)|MyISAM|

#### 분산 key-value 스토어
- key-value 스토어는 key-value 쌍을 저장하기 위한 심플한 스토리지 이다.
- 분산 스토어는 네트워크를 지원함으로 써 다수의 서버로 확장시키는 기능을 지닌 것이다.
- 가장 유명한 것은 memcached 이며 메모리상 동작하기에 성능이 매우 좋다.
- 단점은 재기동시 데이터가 사라진다는 점이다.

#### memcached
- 심플한 구현의 key-value 스토어로 **분산 알고리즘을 클라이언트 라이브러로 구현**하고 있다.
- 분산 알고리즘은 key의해시값을 서버 대수로 나눈 나머지를 사용하는 단순한 방법
- Consistent Hashing 과 같은 방법도 사용한다.
 
#### 분산 파일 시스템
- 분산 파일시스템도 스토리지의 유력한 후보가 된다.
- 파일시스템은 특성상 보통 어느정도 이상인 크기의 데이터를 저장하는데 적합하다.
- NFS 처럼 고려된 구현이 아닌경우 를 제외하면 작은 데이터가 대량으로 존재하는 경우는 적합하지 않다.

#### MogileFS
- 비교적 작은대량의 파일을 다룰 목적으로 Perl로 구현된 분산 파일시스템
- 아키텍쳐는 메타데이터를 다루는 RDBMS, 스토리지 서버, 전송 서버로 구성딘다.
- 대량의 KB ~ 수십 KB 정도의 파일과 이미지를 효율적으로 저장하기 위한 시스템이다.
- 대부분 추가된 뒤 갱신하지 않고 참조만 하는 용도에 적합함
- WebDAV 프로토콜을 사용하기 때문에 애플리케이션 측 구현이 필요하다.

#### NFS 계열 분산 파일시스템
- 특정 서버의 파일시스템을 다른 서버에서 마운트 한 뒤 해당 서버의 로컬 파일시스템 처럼 사용가능한 기술
- 대부분 커널 레벨에서 구현되어 있어 서버측 장애시 클라이언트 동작도 정지된다는것이 단점이다.

#### WebDAV 서버
- NFS가 커널레벨에 구현되어 발생하는 문제를 극복하기 위한 방법
- HTTP를 기반으로 한 프로토콜이며, 애플리케이션 레벨에서 구현되는 경우가 많아 안정된 시스템 구축이 가능하다.

#### DRBD
- DRBD (Distributed Replicated Block Device)는 네트워크 계층에서의 RAID라고 할 수 있다.
- 블록 디바이스 레벨에서 분산, 다중화 가능한 기술이다.
- 2대의 스토리지 서버의 블록 디바이스 간 동기를 실현한다.
- 이는 RAID-1을 네트워크 상에서 실현한 것이다.
- RAID 와 마찬가지로 HDD 상에서 블록 디바이스와 동일하게 다를 수 있음

#### HDFS
- HDFS (Hadoop Distributed File System) Hadoop 용도로 설계된 분산 파일 시스템
- 64MB 씩 분할하여 저장하고 수백 MB ~ 수십 GB 거대한 데이터를 저장하는것을 목적
- MapReduce 를 구현하고 있다.

## 캐시 시스템

#### 웹 애플리케이션의 부하와 프록시/캐시 시스템
- 웹 애플리케이션의 부하가 증가해서 시스템 용량이 부족해졌을 때에 API 서버나 DB 서버를 증설함으로써 대응할 수 있지만
- HTTP 레벨의 캐시를 이용해 대응도 가능하다.
- 보통 프워드 프록시와 리버스 프록시라 불리는 2 종류가 있다.
- 프워드 프록시 - 클라이언트가 외부 서버에 액세스 할 때 사이에 두는 프록시
- 리버스 프록시 - 역으로 외부의 클라이언트가 내부 서버에 액세스 할 때 두는 프록시

> 프록시 서버를 두어 응답을 캐싱해 두어 캐싱해둔 응답을 사용해 부하에 대한 대응을 한다.

#### 리버스 프록시 캐시 서버
- 리버스 프록시 캐시 서버의 구현으로 Squid 가 가장 유명하다.
- 1990년대에 개발되었으며 이를 대체하기 위한 구현은 nginx, pound, Varnish 등이 개발 되었다.

#### 기본적인 구성
- 리버스 프록시와 API 서버 2대로 이루어진 구성을 전제한다.
- 캐시 서버를 도입할 경우 리버스 프록시와 API 서버 사이에 배치한다.
- 요청의 일부를 캐싱하여 전체 성능을 향상시킨다.

#### 여러 대의 서버로 분산하라
- 2대를 사용하여 다중성을 띄게 한다.
- Active-Standby 구조로 구성하거나, 각각을 독립적인 캐시서버로 동작시키는 등 설정이 가능하지만
- 2대의 서버를 연계해서 동작 하는것이 가장 효율이 좋다.
- ICP (Inter-Cache Protocol) 를 사용하는 것이 기본이다.
- ICP는 Internet-Draft로 정의된 프로토콜중 하나이며 캐시를 제어하기 위한 프로토콜이다.

#### 2단 구성 캐시 서버
- 이미지 파일 등 캐시서버 부하가 높아지면 용량이 턱없이 부족해진다.
- 이런 경우 캐시 서버를 2단으로 구성하여 높은 확장성을 가지는 캐시 서버를 구성한다.
- CARP (Cache Array Routing Protocol) 프로토콜에 따라 URL을 키로 각 캐시 서버로 전송한다.
    - 특정 URL 에 대해 특정 캐시 서버만 사용하게 된다.

> 캐시 서버대수가 늘어나도 효율적인 캐싱 및 부드럽게 확장이 가능하지만, 특정 리소스에 대한 요청이 과하게 몰릴경우 특정 노드에만 요청이 쏠리는 문제가 있음

#### COSS 크기 결정방법
- 히트율을 높이기 위해 충분한 캐시 용량을 준비해둬야한다.
- 캐시는 용량이 클수록 좋은것이 아닌 과부족이 없는 상태가 최적의 상태
- 캐시 용량이 너무 크면 아래 단점이 존재한다.
1. 초기 시작시 COSS 파일 생성 시간이 걸림
2. 서버 재기동 등으로 메모리가 초기화 된후 안정화 까지 시간이 걸린다.
3. 디스크 용량을 압박한다.

#### 투입 시 주의점
- 캐시 서버의 효율을 올릴수록 캐시 서버 장애시 영향이 커진다.
- 2대로 부하를 분산하고 있을때 1대가 고장나더라도 남은 1대가 버틸만한 서버를 준비하는 것이 정석이다.
- 장애 복구한 서버나 새로운 서버를 추가 할때 성능이 떨어지는 경우가 있다.
> 이 경우는 기동 직후에는 적절한 캐시 데이터가 준비되어 있지 않기 때문이다.

## 계산 클러스터 - Hadoop

#### 대량 로그 데이터의 병렬 처리
- 대규모 웹 서비스를 운영하다 보면 로그 데이터도 대량으로 쌓인다.
- 이런 로그 처리를 빠르게 수행하기 위해 병렬처리가 가능한 계산 클러스터가 필요하다.

#### MapReduce 의 계산모델
- Hadoop 이라는 MapReduce의 오픈소스 구현이 유명하다.
- MapReduce는 2004년에 구글이 발표한 계산모델이며, 거대한 데이터를 빠르게 병렬처리하는 것을 목적
- 다수의 계산 노드로 구성된 클러스터와 대량 데이터를 분산해서 저장하기 위한 분산 파일 시스템으로 구성된다.
- 계산 모델
    - key/value 쌍 리스트를 입력 데이터로 최종적으로 value 리스트를 출력한다.
    - 계산은 Map 과 Reduce 단계로 구성된다.
- Map 단계
    - 마스터 노드에서 데이터를 잘게 분할하여 각 노드로 분산한다.
    - 분할된 데이터를 각 노드에서 계싼 후 결과를 key/value 로 구성된 중간 데이터로 출력한다.
- Reduce 단계
    - Map 단계의 출력 데이터를 key 별로 정리해서 key와 key에 대응하는 값의 리스토로 재구성 한다.
    - 각 key를 각 노드로 분산하는데 이 과정을 Shuffle Phase 라고 한다.
    - 그 후 각 노드에 있는 리스트를 입력 데이터로 해서 각 리스트를 최정적으로 출력 데이터로 가공하는 처리를 수행한다.

> 얼핏 보면 단순한 처리 밖에 할 수 없는것 처럼 보이지만, 로그분석 / 인덱싱 등 응용 범위는 광범위 하다. 