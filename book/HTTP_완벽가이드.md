# HTTP 완벽 가이드

## HTTP: 웹의 기초

### 1장 HTTP 개관

#### 1.1 HTTP: 인터넷의 멀티미디어 배달부
- HTTP는 신뢰성 있는 데이터 전송 프로토콜을 사용 한다.
- HTTP 통신중 파괴되거나, 중복되거나, 왜곡되는 것을 걱정하지 않아도 된다.

#### 1.2 HTTP: 웹 클라이언트와 서버
- 웹 콘텐츠는 웹서버에 존재한다.
- 웹 서버는 HTTP 프로토콜로 통신하기 떄문에 HTTP 서버라고 불린다.
- 웹 서버는 HTTP 클라이언트가 요청한 데이터를 HTTP 응답으로 제공한다.
- HTTP 클라이언트와 HTTP 서버는 월드 와이드 웹의 기본 요소이다.

#### 1.3 리소스
- 웹 서버는 웹 리소스를 관리하고 제공한다.
- 리소스는 반드시 정적 파일이어야 할 필요는 없다.

> 어떤 종류의 콘텐츠 소스도 리소스가 될 수 있다.

##### 1.3.1 미디어 타입
- 수천 가지 데이터 타입을 다루기 때문에, HTTP는 웹에서 전송되는 객체 각각에 신중하게 MIME 타입이라는 데이터 포맷 라벨을 붙인다.
    - Multipurpose Internet Mail Extensions
- 원래 각기 다른 전자메일 시스템 사이에서 메시지가 오갈때 겪는 문제점을 해결하기 위해 설계 되었다.
- 웹 서버는 모든 HTTP 객체 데이터에 MIME타입을 붙인다.

##### 1.3.2 URI
- 서버 리소스 이름은 통합 자원 식별자 (Uniform Resource Identifier), 혹은 URI로 불린다.
- 인터넷의 우편물 주소 같은 것응로, 정보 리소스를 고유하게 식별하고 위치를 지정할 수 있다.
    - http://www.june.me/items/1

##### 1.3.3 URL
- 통합 자원 지시자 (Uniform Resource Locator) URL은 리소스 식별자의 가장 흔한 형태이다.
- 특정 서버의 한 리소스에 대한 구체적인 위치를 서술한다.
- URL은 리소스가 정확히 어디에 있고 어떻게 접근할 수 있는지 분명히 알려준다.

`URL 표준 포맷`
- 첫번 째 부분은 스킴(scheme)라고 부른다. 리소스에 접근하는 프로토콜을 명시한다 (http://)
- 두번째 부분은 서버의 인터넷 주소를 제공한다 (www.naver.com)
- 마지막은 웹 서버의 리소스를 가리킨다. (/items/1)

> 오늘날 대부분의 URI는 URL이다.

##### 1.3.4 URN
- URI의 두 번째 종류는 유니폼 리소스 이름 (Uniform Resource Name) URN 이다.
- 콘텐츠를 이루는 한 리소스에 대해, 그 리소스의 위치에 영향 받지 않는 유일 무이한 이름 역할을 한다.

> 리소스가 이름을 변하지 않게 유지하는 한, 여러 종류의 네트워크 접속 프로토콜로 접근해도 문제없다.

#### 1.4 트랜잭션
- HTTP 트랜잭션은 요청 명령과 응답결과로 구성되어 있다.
- 이 상호작용은 HTTP 메시지라고 불리는 정형화된 데이터 덩어리를 이용해 이루어진다.

##### 1.4.1 메서드
- HTTP는 HTTP 메서드라고 불리는 여러 가지 종류의 요청 명령을 지원한다.
- 모든 HTTP 요청 메시지는 한 개의 메서드를 갖는다.

| HTTP 메서드 | 설명 |
|---|---|
| GET | 서버에서 클라이언트로 지정한 리소스를 보내라. |
| PUT | 클라이언트에서 서버로 보낸 데이터를 지정한 이름의 리소스로 저장하라. |
| DELETE | 지정한 리소스를 서버에서 삭제하라. |
| POST | 클라이언트 데이터를 서버 게이트웨이 애플리케이션으로 보내라. |
| HEAD | 지정한 리소스에 대한 응답에서, HTTP 헤더 부분만 보내라. |

##### 1.4.2 응답 코드
- 모든 HTTP 응답 메시지는 상태 코드와 함께 반환된다.
- 상태 코드는 클아이언트에게 요청이 성공했는지 추가 조치가 필요한지 알려주는 세자리 숫자이다.

| HTTP 상태코드 | 설명 |
|---|---|
| 200 | 문서가 올바르게 반환됨. |
| 302 | 다른 곳에 가서 리소스를 가져가라. |
| 404 | 리소스를 찾을 수 없다. |

##### 1.4.3 웹페이지는 여러 객체로 이루어질 수 있다
- 애플리케이션은 보통 하나의 작업을 수행하기 위해 여러 HTTP 트랜잭션을 수행 한다.
- 웹 브라우저는 시각적으로 풍부한 웹페이지를 가져올 때 대량의 HTTP 트랜잭션을 수행한다.

> 웹 페이지는 하나의 리소스가 아닌 리소스의 모음이다.


#### 1.5 메시지
- HTTP 메시지는 단순한 줄 단위의 문자열이다.
- 웹 클라이언트에서 웹 서버로 보낸 HTTP 메시지를 **요청 메시지**
- 웹 서버에서 웹 클라이언트로 보낸 HTTP 메시지를 **응답 메시지** 라고 한다.

`HTTP 메시지 구성`
- 시작줄
    - 요청이라면 무엇을 해야하는지, 응답이라면 무슨일이 일어났는지 나타낸다.

- 헤더
    - 시작줄 다음에는 0개 이상의 헤더 필드가 이어진다.
    - 쉬운 구문분석을 위해 쌍점(:) 으로 구분되어 있는 하나의 이름과 하나의 값으로 구성된다.
    - 헤더는 빈 줄로 끝난다.

- 본문
    - 빈 줄 다음 메시지 본문이 필요에 따라 올 수 있따.
    - 임의의 이진 데이터를 포함할 수 있다. (텍스트 포함)

```
[ 요청 메시지 ]
GET /test/hi ( 시작줄 )
--------------
Accept: text/* ( 헤더 )
Accept-Language: en, fr 

[ 응답 메시지 ]
HTTP/1.0 200 OK ( 시작줄 )
--------------
Content-type: text/plain ( 헤더 )
Content-Length: 19
--------------
Hi !!! ( 본문 )
```

#### 1.6 TCP 커넥션
- TCP ( Transmission Control Protocol, 전송 제어 프로토콜 ) 커넥션

##### 1.6.1 TCP/IP
- HTTP는 애플리케이션 계층 프로토콜 이다.
- 네트워크 통신 세부사항에 신경쓰지 않으며 **TCP/IP 프로토콜에게 맡긴다.**

`TCP`
- 오류없는 데이터 전송
- 순서에 맞는 전달 (데이터는 보낸순서로 도착한다.)
- 조각나지 않는 데이터 스트림 (언제든지 어떤 크기로든 보낼 수 있다.)

##### 1.6.2 접속, IP주소, 그리고 포트번호
- HTTP 클라이언트가 서버에 메시지를 전송 하기 전 인터넷 프로토콜 주소와 포트번호를 사용해 서버 사이에 TCP/IP 연결을 맺어야 한다.
- TCP 에서는 IP 주소와, 그 서버에서 실행중인 프로그램이 사용중인 포트번호가 필요하다.

`HTML 리소스를 사용자에게 보여주는 과정`
- 웹브라우저는 서버의 URL에서 호스트 명을 추출한다.
- 웹브라우저는 서버의 호스트 명을 IP로 변환한다.
- 웹브라우저는 URL에서 포트번호를 추출한다.
- 웹브라우저는 웹서버와 TCP 커넥션을 맺는다.
- 웹브라우저는 서버에 HTTP 요청을 보낸다.
- 서버는 웹브라우저에게 HTTP 응답을 돌려준다.
- 커넥션이 닫히면, 웹브라우저는 문서를 보여준다.


##### 1.6.3 텔넷(Telnet)을 이용한 실제 예제
- 텔넷은 HTTP 클라이언트는 잘 흉내 내지만 서버로서는 변변치 않다.

#### 1.7 프로토콜 버전
- 오늘날 쓰이고 있는 HTTP 프로노콜은 버전이 여러가지 이다.

###### HTTP/0.9
- 오직 GET 메서드만 지원하고, MIME타입, HTTP 헤더, 버전 번호는 지원하지 않는다.
- 간단한 HTML객체를 받아오기 위해 만들어진 것이다.
- 금방 HTTP/1.0 으로 대체되었다.

###### HTTP/1.0
- 처음으로 널리 쓰이기 시작한 HTTP 버전이다.
- 버전번호, HTTP 헤더, 추가 메서드, 멀티미디어 객체 처리를 추가했다.
- 시각적으로 매력적인 웹페이지와 상호작용하는 폼을 실현했고, 월드와이드웹을 대세로 만들었다.

###### HTTP/1.0+
- keep-alive 커넥션, 가상 호스팅 지원, 프락시 연결 지원을 포함해 많은 기능이 공식적이진 않지만 표준으로 추가되었다.

###### HTTP/1.1
- HTTP 설계의 구조적 결함 교정, 두드러진 성능 최적화, 잘못된 기능 제거에 집중했다.
- 현재의 HTTP 버전이다.

###### HTTP/2.0
- HTTP/2.0은 HTTP/1.1 성능 문제를 개선하기 위해 구그르이 SPDY 프로토콜을 기반으로 설계가 진행중인 프로토콜 이다.


#### 1.8 웹의 구성요소
- 프락시
    - 클라이언트와 서버사이에 위치한 HTTP 중재자
- 캐시
    - 많이 찾는 웹페이지를 클라이언트 가까이에 보관하는 HTTP 창고
- 게이트웨이
    - 다른 애플리케이션과 연결된 특별한 웹 서버
- 터널
    - 단순히 HTTP 통신을 전달하기만 하는 특별한 프락시
- 에이전트
    - 자동화된 HTTP 요청을 만드는 준 지능적 (semi-intelligenct) 웹 클라이언트

##### 1.8.1 프락시
- **웹 보안, 애플리케이션 통합, 성능 최적화를 위한 중요한 구성 요소**이다.
- 프락시는 클라이언트와 서버 사이에 위치하여 클라이언트의 모든 HTTP요청을 받아 서버에 전달한다.
- 주로 보안을 위해 사용된다. 모든 웹 트래픽 흐름 속에서 신뢰할 만한 중개자 역할을 한다.
    - 요청과 응답을 필터링 한다.

##### 1.8.2 캐시
- 웹캐시와 캐시 프락시는 자주 찾는 것의 사본을 저장해두는 특별한 종류의 HTTP 프락시 서버다.
- HTTP는 캐시를 효율적으로 동작하게 하고 캐시된 콘텐츠를 최신버전으로 유지하면서 동시에 프라이버시도 보호하기 위한 많은 기능을 정의한다.

##### 1.8.3 게이트웨이
- 다른 서버들의 중개자로 동작하는 특별한 서버다.
- 주로 HTTP 트래픽을 다른 프로토콜로 변환하기 위해 사용된다.
- 언제나 스스로가 리소스를 갖고 있는 진짜 서버인 것처럼 요청을 다룬다.

##### 1.8.4 터널
- 두 커넥션 사이에서 날(raw) 데이터를 열어보지 않고 그대로 전달해주는 HTTP 애플리케이션이다.
- 주로 비 HTTP 데이터를 하나 이상의 HTTP 연결을 통해 그대로 전송해주기 위해 사용된다.

> SSL 트래픽을 HTTP 커넥션으로 전송함으로써 웹 트래픽만 허용하는 사내 방화벽을 통과시키는 것이 있다.

##### 1.8.5 에이전트
- 사용자를 위해 HTTP 요청을 만들어주는 클라이언트 프로그램이다.
    - 웹 요청을 만드는 애플리케이션은 뭐든 HTTP 에이전트 이다.

### 2장 URL과 리소스
- URL (Uniform Resource Locator)은 인터넷의 리소스를 가리키는 표준이름이다.
- 전자정보 일부를 가리키고 그것이 어디에 있고 어떻게 접근할 수 있는지 알려준다.

#### 2.1 인터넷의 리소스 탐색하기
- URL은 브라우저가 정보를 찾는데 필요한 리소스의 위치를 가리킨다.
- URL은 통합 자원 식별자 혹은 URI 라고 불리는 더 일반화된 부류의 부분 집합이다.
- URI는 두가지 주요 부분집합인, URL, URN으로 구성된 종합적인 개념이다.

```
http://www.naver.com/posts/1
```

- URL의 첫 부분인 http는 URL의 스킴이다. 웹 클라이언트가 리소스에 어떻게 접근하는지 알려준다.
- 두번째 부분은 서버의 위치다. 웹 클라이언트가 리소스가 어디에 호스팅되어 있는지 알려준다.
- 세번째 부분인 /posts/1 은 리소스의 경로이다.

> 대부분의 URL은 '스킴://서버위치/경로' 구조로 되어 있다.

##### 2.1.1 URL이 있기 전 암흑의 시대 
- 웹과 URL이 있기전 네트워크 상 산재해있는 데이터에 접근하기 위해 애플리케잇녀마다 달리 가지고 있는 분류방식을 사용 했다.

> URL은 브라우저가 더 영리하게 리소스에 접근하고 그것을 다루게 함으로써 온라인 세상을 단순화 시킨다.

#### 2.2 URL 문법
- URL 문법은 스킴에 따라서 달라진다.
- 대부분의 URL은 일반 URL문법을 따르며, 서로 다른 URL 스킴도 형태와 문법 면에서 매우 유사하다.

대부분의 URL 스킴의 문법은 일반적으로 9개 부분으로 나뉜다.
> <스킴>://<사용자이름>:<비밀번호>@<호스트>:<포트>/<경로>;<파라미터>?<질의>#<프래그먼트>

##### 2.2.1 스킴: 프로토콜
- 스킴은 르소스에 어떻게 접근하는지 알려주는 매우 중요한 정보다.
- 스킴 컴포넌트는 알파벳으로 시작해야 하고 URL의 나머지 부분들과 첫번째':' 문자로 구분한다. 또한 대소문자를 가리지 않는다.

##### 2.2.2 호스트와 포트
- 리소스를 찾으려면, 리소스를 호스팅하고 있는 장비와 그 장비내에 접근할수 있는 서버가 어디있는지 알아야한다.
- URL의 호스트와 포트 컴포넌트는 그 두가지 정보를 제공해준다.
- 내부적으로 TCP 프로토콜을 사용하는 HTTP는 기본포트로 80을 사용한다.

##### 2.2.3 사용자 이름과 비밀번호
- 많은 서버가 자신이 가지고있는 데이터에 접근을 허용하기 전에 사용자 이름과 비밀번호를 요구한다.
- FTP서버가 좋은 예 이다.

```
ftp://anonymous@ftp.prep.ai.mit.edut/pub/gnu
```

##### 2.2.4 경로
- URL의 경로 컴포넌트는 리소스가 서버의 어디에 있는지 알려준다.
- 해당 경로는 계층적 파일 시스템 경로와 유사한 구조를 가진다.

> https://www.naver.com/posts/1

##### 2.2.5 파라미터
- URL의 파라미터 컴포넌트는 애플리케이션이 서버에 정확한 요청을 하기 위해 필요한 입력 파라미터를 받는데 사용한다.
- 이름/값 쌍의 리스트로 URL 나머지 부분들로 부터 ';' 문자로 구분하여 URL에 기술한다.

##### 2.2.6 질의 문자열
- 데이터베이스 같은 서비스들은 요청받을 리소스 형식의 범위를 좁히기 위해 질문이나 질의를 받을 수 있다.
- 다음과 같이 물음표 우측에 있는 값들을 질의 컴포넌트라고 부른다.
- 게이트웨이를 가리키는 URL경로 컴포넌트와 함께 전달하고 있다.
- 편의상 많은 게이트웨이가 '&'로 나뉜 '이름=값' 쌍 형식의 질의 문자열을 원한다.
```
http://www.joes-hardware.com/inveintory-check.cgi?item=12731
``` 

##### 2.2.7 프래그먼트
- HTML 같은 리소스 형식들은 본래의 수준보다 더 작게 나뉠 수 있다.
- 리소스의 특정 부분을 가리킬 수 있도록 URL은 리소스 내의 조각을 가리킬 수 있는 프래그먼트 컴포넌트를 제공한다.
- 예를 들면 HTML문서에 있는 특정 이미지나 일부분을 가리킬 수 있다.

#### 2.3 단축 URL
- 웹 클라이언트는 몇몇 단축 URL을 인식하고 사용한다.
- 상대 URL은 리소스내에 존재하는 리소스를 간결하게 기술하는데 사용할 수 있다.

##### 2.3.1 상대 URL
- URL은 절대 URL, 상대 URL로 나뉜다.
- 절대 URL은 리소스에 접근하는데 필요한 모든 정보를 가지고 있따.
- 상대 URL은 모든 정보를 담고 있지는 않다.
    - 상대 URL로 리소스에 접근하는데 필요한 모든 정보를 얻기위해서, 기저(Base) URL을 사용해야 한다.
    
```
// 기저 URL: [ ] 내의 부분 
[http://www.naver.com]/tools.html

// 상대 URL
./hammer.html
```

##### 2.3.2 URL 확장
- 어떤 브라우저 들은 URL을 입력한 다음이나 입력하고 있는 동안 자동으로 URL을 확장한다.
- 이러한 확장 기능은 두가지로 나뉜다.

`호스트 명 확장`
- 단순한 휴리스틱만을 사용해서 입력한 호스트 명을 전체 호스트명으로 확장할 수 있다.
- yahoo 라고 입력할 경우 www.yahoo.com 을 만든다.

> 프락시와 같은 다른 HTTP 애플리케이션에 문제를 발생시킬 수도 있다.

`히스토리 확장`
- 과거에 사용자가 방문했던 URL의 기록을 저장해 놓는 것이다.
- URL을 입력하면 그 입력된 URL의 앞 글자들을 포함하는 완결된 형태의 URL 들을 선택하게 해준다.

> 프락시를 사용할 경우 다르게 동작 할 수 있다.


#### 2.4 안전하지 않은 문자
- URL 설계자는 사람들이 URL에 이진 데이터나 일반적으로 안전한 알파벳 외 문자도 포함하려고 할 떄가 있다는 것을 알게 되었다.
- 그래서 이스케이프 라는 기능을 추가하여, 안전하지 않은 문자를 안전한 문자로 인코딩 할 수 있게 하였다.

##### 2.4.1 URL 문자 집합
- US-ASCII는 문자를 서식화 하고 하드웨어상에서 신호를 주고받기 위해, 7비트를 사용하여 영문 자판에 있는 키 대부분과 몇몇 출력되지 않는 제어문자를 표현한다.
- URL 설계자 들은 이스케이프 문자열을 쓸 수 있게 설계 하였다.
- 이스케이프 문자열은 US-ASCII 에서 사용이 금지된 문자들로, 특정 문자나 데이터를 인코딩할 수 있게 함으로써 이동성과 완성도를 높혔다.

##### 2.4.2 인코딩 체계
- 인코딩은 안전하지 않는 문자를 퍼센티지 기호로 시작해, ASCII 코드로 표현되는 두 개의 16진수 숫자로 이루어진 '이스케이프' 문자로 바꾼다.

##### 2.4.3 문자 제한
- 몇몇 문자는 URL 내에서 특별한 의미로 예약되어 있다.

| 문자 | 설명 |
|---|---|
| & | 인코딩된 문자에 사용할 이스케이프 토큰으로 선점 |
| / | 경로 컴포넌트에 있는 경로 세그먼트를 나누눈 용도로 선점 |
| . | 경로 컴포넌트에서 선점 |
| .. | 경로 컴포넌트에서 선점 |
| # | 프래그먼트의 구획 문자로 선점 |
| ? | 질의 문자열의 구획 문자로 선점 |
| ; | 파라미터의 구획 문자로 선점 |
| : | 스킴, 사용자 이름/비밀번호, 호스트/포트의 구획 문자로 선점 |
| $, + | 선점 |
| @&= | 특정 스킴에서 특별한 의미가 있기 때문에 선점 |
| {}\~[]₩ | 게이트웨이와 같은 여러 전송 에이전트에서 불안전하게 다루기 때문에 제한됨  |
| <>" | 안전하지 않음 URL 범위 밖에서 역할이 있는 문자열이기 때문에 반드시 인코딩 해야함 |
| 0x00-0x1F, 0x7F | 제한됨, 이 16진수 범위에 속하는 문자들은 인쇄되지 않는 US-ASCII 문자 |
| > 0x7F | 제한됨, 이 16진수 범위에 속하는 문자들은 7비트 US-ASCII 문자가 아님 |

#### 2.5 스킴의 바다

| 스킴 | 설명 |
|---|---|
| http | 사용자 이름이나 비밀번호가 없다는 것을 제외하고, 일반 URL 포맷을 지키는 하이퍼텍스트 전송 프로토콜이다. 기본포트는 80 |
| https | http 스킴과 거의 같다. HTTP 커넥션 양 끝단에서 암호화하기위한 SSL 을 사용한다. 기본포트는 443 |
| mailto | 이메일 주소를 가리킨다. 다른 스킴과 다르게 동작하기 때문에 표준 URL과 다른 포맷을 가진다. RFC 822에 기술되어 있다. |
| ftp | 파일 전송 프로토콜은 FTP 서버에 있는 파일을 내려받거나 올리고, 디렉터리의 콘텐츠 목록을 가져오는데 사용할 수 있다. |
| rtsp, rtspu | 실시간 스트리밍 프로토콜을 통해 읽을 수 있는 오디오 및 비디오와 같은 미디어 리소스 식별자이다. |
| file | 주어진 호스트 기기에서 바로 접근 할 수 있는 파일들을 나타낸다. 만약 호스트가 생략되어 있다면 로컬호스트가 기본 값이다. |
| news | news 스킴은 RFC 1036 정의된 바와 같이 특정 문서나 뉴스 그룹에 접근하는데 사용한다. 리소스의 위치 정보를 포함하지 않는다. |
| telnet | 대화형 서비스에 접근하는데 사용한다. |


### 3장 HTTP 메시지

#### 3.1 메시지의 흐름
- HTTP 메시지는 HTTP 애플리케이션 간에 주고받은 데이터의 블록들이다.
- 이 메시지는 클라이언트, 서버, 프락시 사이를 흐른다.
- '인바운드', '아웃바운드', '업스트림', '다운스트림'은 메시지의 방향을 의미한다.

##### 3.1.1 메시지는 원 서버 방향을 인바운드로 하여 송신된다
- HTTP 메시지가 원 서버로 향하는 것은 인바운드, 모든 처리가 끝난뒤 사용자에게 돌아오는것을 아웃바운드 라고 한다.

##### 3.1.2 다운스트림으로 흐르는 메시지
- HTTP 메시지는 요청과 응답 관계없이 모두 다운스트림으로 흐른다.
- 메시지 발송자는 수신자의 업스트림이다.

#### 3.2 메시지의 각 부분
- HTTP 메시지는 단순한, 데이터의 구조화된 블록이다.
- 메시지는 시작줄, 헤더 블록, 본문 세가지 부분으로 이루어 진다.
- 싲작줄은 어떤 메시지 인지 서술하며, 헤더 블록은 속성, 본문은 데이터를 담고 있다.

##### 3.2.1 메시지 문법
`요청 메시지의 형식`
```
<메서드> <요청 URL> <버전>
<헤더>
<엔티티 본문>
```

`응답 메시지의 형식`
```
<버전> <상태 코드> <사유 구절>
<헤더>
<엔티티 본문>
```

###### 메서드
- 클라이언트 측에서 서바가 리소스에 대해 수행해주길 바라는 동작

###### 요청 URL
- 요청 대상이 되는 리소스를 지칭하는 완전한 URL 혹은 URL의 경로 구성요소다

###### 버전
- HTTP의 버전

###### 상태 코드
- 요청 중 무엇이 일어났는지 설명하는 세자리의 숫자이다.

###### 사유 구절
- 숫자로 된 상태 코드의 의미를 사람이 이해할 수 있게 설명해주는 짧은 문구이다.

###### 헤더들
- 이름, 콜론(:), 선택적인 공백, 값, CRLF가 순서대로 나타나는 0개 이상의 헤더들이다.
- 헤더의 목록은 빈줄 (CRLF)로 끝나 헤더 목록의 끝과 엔티티 본문의 시작을 표시한다.

###### 엔티티 본문
- 엔티티 본문은 임의의 데이터 블록은 포함한다.
- 모든 세미지가 본문을 갖는것은 아니다.

##### 3.2.2 시작줄
- 요청 메시지의 시작줄은 무엇을 해야 하는지 말해준다.
- 응답 메시지의 시작줄은 무슨 일이 일어났는지 말해준다.

###### 요청줄
- 요청 메시지의 시작줄, 혹은 요청줄에는 서버에서 어떤 동작이 일어나야 하는지 설명해주는 메서드와 그 동작에 대한 대상을
- 지칭하는 요청 URL이 있다. HTTP 버전도 포함한다. (HTTP 1.0 이전에는 필수가 아니었음)

###### 응답줄
- 응답 메시지의 시작줄 혹은 응답줄에는 응답 메시지에 쓰인 HTTP 버전, 상태코드, 사유구절이 들어 있다.

###### 메서드
- 서버에게 무서을 해야하는지 말해준다.

| 메서드 | 설명 | 메시지 본문이 있는가 ? |
|---|---|---|
| GET | 서버에서 어떤 문서를 가져온다. | 없음 |
| HEAD | 서버에서 어떤 문서에 대해 헤더만 가져온다. | 없음 |
| POST | 서버가 처리해야 할 데이터를 보낸다. | 있음 |
| PUT | 서버에 요청 메시지의 본문을 저장한다. | 있음 |
| TRACE | 메시지가 프락시를 거쳐 서버에 도달하는 과정을 추적한다. | 없음 |
| OPTIONS | 서버가 어떤 메서드를 수행할 수 있는지 확인한다. | 없음 |
| DELETE | 서버에서 문서를 제거한다. | 없음 |

###### 상태코드
- 클라이언트에게 무엇이 일어났는지 말해준다.

| 전체 범위 | 정의된 범위 | 분류 |
|---|---|---|
| 100-199 | 100-101 | 정보 |
| 200-299 | 200-206 | 성공 |
| 300-399 | 300-305 | 리다이렉션 |
| 400-499 | 400-415 | 클라이언트 에러 |
| 500-599 | 500-505 | 서버에러 |

###### 사유구절
- 응답 시작줄의 마지막 구성요소다.
- 상태 코드에 대한 글로된 설명을 제공한다.
- 상태코드와 일대일로 대응되며, 요청중 어떤일이 일어났는지 알려주기 위해 넘겨줄 수 있는상태 코드의 사람이 이해하기 쉬운 버전이다.

###### 버전 번호
- HTTP/x.y 형식으로 요청과 응답 메시지 양쪽 모두에 기술된다.
- HTTP로 대화하는 애플리케이션들에게 대화 상대의 능력과 메시지의 형식에 대한 단서를 제공해주기 위한 것이다.

#### 3.2.3 헤더
- HTTP 헤더 필드는 요청과 응답 메시지에 추가 정보를 더한다.
- 기본적으로 이름/값 쌍의 목록이다.

##### 헤더 분류

`일반 헤더`
- 요청과 응답 양쪽에 모두 나타날 수 있음

`요청 헤더`
- 요청에 대한 부가 정보를 제공

`응답 헤더`
- 응답에 대한 부가 정보를 제공

`Entity 헤더`
- 본문 크기와 콘텐츠, 혹은 리소스 그 자체를 서술

`확장 헤더`
- 명세에 정의되지 않은 새로운 헤더


##### 헤더를 여러 줄로 나누기
- 긴 헤더 줄은 여러 줄로 쪼개 더 읽기 좋게 만들 수 있다
- 추가 줄 앞에는 최소 하나의 스페이스 혹은 탭 문자가 와야 한다.

#### 3.2.4 엔티티 본문
- HTTP 메시지의 세번째 부분은 선택적인 엔티티 본문이다.
- 엔티티 본문은 HTTP 메시지의 화물이다.

#### 3.2.5 버전 0.9 메시지
- HTTP 버전 0.9는 HTTP 프로토콜의 초기 버전이다.
- 요청과 응답으로 이루어져 있지만, 요청은 그저 메서드와 URL을 가지고 있고
- 응답은 오직 엔티티로만 구성 되어 있다.

#### 3.3 메서드
- 모든 서버가 모든 메서드를 구현하지는 않는다.
- HTTP 1.1 과 호환되고자 한다면, GET, HEAD 메서드만을 구현하는 것으로 충분하다.

##### 3.3.1 안전한 메서드
- HTTP 는 안전한 메서드라 불리는 메서드의 집합을 정의한다.
- GET, HEAD 는 안전하다고 할 수 있는데, 이들은 HTTP의 결과로 서버에 어떠한 작용도 없음을 의미한다.

> 안전한 메서드가 서버에 작용을 유발하지 않는다는 보장은 없다.

##### 3.3.2 GET
- GET 메서드는 주로 서버에게 리소스를 달라고 요청하기 위해 사용한다.

##### 3.3.3 HEAD
- HEAD 메서드는 정확히 GET 처럼 행동하지만, 서버는 응답으로 헤더만을 돌려준다.
- 엔터티 본문은 존재하지 않으며, 리소스를 가져오지 않고 그의 타입, 개체 존재여부 확인, 리소스 변경 여부 검사가 가능하다.

##### 3.3.4 PUT
- PUT 서버에 문서를 쓴다.
- 요청 URL 의 이름대로 새 문서를 만들거나, 이미 존재한다면 본문을 이용해 교체하는 것이다.

> 콘텐츠를 변경할 수 있게 해주기 때문에, 수행전 사용자에게 인증을 요구한다.

##### 3.3.5 POST
- POST 메서드는 서버에 입력 데이터를 전송하기 위해 설계되었다.
- 실제로, HTML 폼을 지원하는 용도로 가장 많이 사용한다.

##### 3.3.6 TRACE
- 클라이언트가 어떤 요청시, 해당 요청은 방화벽, 프락시, 게이트웨이 등의 애플리케이션을 통과할 수 있다.
- TRACE 메서드는 클라이언트에게 자신의 요청에 서버에 도달했을때 어떻게 보이게 되는지 알려준다.
- 목적지 서버에서 **루프백(loopback)** 진단을 시작한다.
- 주로 진단을 위해 사용되며, 요청이 의도한 요청/응답 연쇄를 거쳐가는지 확인할 수 있다.

> 어떠한 엔티티 본문도 보낼 수 없다.

##### 3.3.7 OPTIONS
- 웹 서버의 특정 리소스에 대해 어떤 메서드가 지원되는지 알 수 있다.

##### 3.3.8 DELETE
- 요청 URL로 지정한 리소스를 삭제할 것을 요청한다.
- 하지만 클라이언트는 삭제가 수행되는 것을 보장하지 못한다.

##### 3.3.9 확장 메서드
- HTTP 는 필요에 따라 확장해도 문제가 없도록 설계되어 있다.
- 확장 메서드는 HTTP/1.1 명세에 정의되지 않은 메서드다.

> 모든 확장 메서드가 형식을 갖춘 명세로 정의된 것은 아니라는 점에 주의 해야한다.

#### 3.4 상태 코드
- HTTP 상태 코드는 크게 다섯가지로 나뉜다.
- 상태 코드는 클라이언트에게 그들의 트랜잭션을 이해할 수 있는 쉬운 방법을 제공한다.

##### 3.4.1 100-199: 정보성 상태코드
- 정보성 상태코드는 HTTP/1.1 에서 도입되었다.
- 100 Continue 는 HTTP 클라이언트 애플리케이션이 서버에 엔티티 본문을 전송하기 전에 그 엔티티 본문을 서버가 받아 들일 것인지 
- 확인하려고 할 때, 그 확인 작업을 최적화하기 위한 의도로 도입된 것이다.

###### 클라이언트와 100 Continue
- 100-continue 는 여러 측면에서 최적화를 위한 것이다.
- 서버가 다루거나 사용 할 수 없는 큰 엔티티를 서버에게 보내지 않으려는 목적으로만 사용해야 한다.

###### 서버와 100 Continue
- 서버가 100-continue 값이 답긴 Expect 헤더가 포함된 요청을 받는다면, 100 Continue 응답 혹은 에러코드로 답해야 한다.

###### 프락시와 100 Continue
- 클라이언트로 부터 100-continue 응답을 의도한 요청을 받은 프락시는 몇가지 해야할 일이 있다.
- 다음 홉 서버가 HTTP/1.1 을 따르거나 어떤 버전을 따르는지 모를 경우 Expect 헤더를 포함시켜서 요청을 다음으로 전달해야 한다.
- 다음홉 서버가 1.1 보다 이전 버전의 HTTP 버전을 따른다면 프락시는 417 Expectation Failed 에러로 응답해야 한다.

##### 3.4.2 200-299: 성공 상태 코드

| 상태 코드 | 사유 구절 | 의미 |
|---|---|---|
| 200 | OK | 요청이 정상이고, 엔티티 본문은 요청된 리소스를 포함하고 있다. |
| 201 | Created | 서버 개체를 생성하는 요청을 위한것. 응답은 생성된 리소스에 대해 최대한 구체적인 참조가 담긴 Location 헤더와 함께, 그 리소스를 참조할 수 있는 URL을 엔티티 본문에 포함해야 한다. |
| 202 | Accepted | 요청은 받아들여졌지만, 서버는 아직 그에 대한 어떠한 동작도 수행하지 않았다. 요청에 대한 처리를 완료할 것인지에 대한 어떠한 보장은 없다. |
| 203 | Non-Authoritative Information | 엔티티 헤더에 들어있는 정보가 원래 서버가 아닌 리소스의 사본에서 왔다. 원래 서버에서 온 것이었다면 200응답 이었을 것지만 선택 사항이다. |
| 204 | No Content | 응답 메시지는 헤더와 상태줄을 포함하지만 엔티티 본문은 포함하지 않는다. 웹 브라우저를 새 문서로 이동시키지 않고 갱신하고자 할 때 사용한다. |
| 205 | Reset Content | 주로 브라우저를 위해 사용되는 또 하나의 코드. 브라우저에게 현재 페이지에 있는 HTML 폼에 채워진 모든 값을 비우라고 말한다. |
| 206 | Partial Content | 부분 혹은 범위 요청이 성공 했다. 206 응답은 반드시 Content-Rage 와 Date 헤더를 포함해야 하며 Etag, Content-Length 중 하나는 반드시 포함해야 한다. |

##### 3.4.3 300-399: 리다이렉션 상태 코드
- 리다이렉션 상태 코드는 클라이언트가 관심있어 하는 리소스에 대해 다른위치를 사용하라고 말해주거나 해당 리소스 내용 대신 다른 대안 응답을 제공한다.

##### 3.4.4 400-499: 클라이언트 에러 상태 코드
- 가끔 클라이언트는 서버가 다를수 없는 무엇인가를 보낸다.
- 잘못 구성된 요청 메시지 같은 것이 있을 수 있으며, 가장 흔한 것은 존재하지 않은 URL에 대한 요청이다.
- 많은 클라이언트 에러가 당신을 귀찮게 하지 않고 브라우저에 의해 처리된다.

##### 3.4.5 500-599: 서버 에러 상태 코드
- 프락시는 클라이언트의 입장에서 서버와 대화를 시도할 때 자주 에러를 만나게 된다.
- 프락시는 문제를 설명하기 위해 5XX 서버 에러 상태 코드를 생성한다.

#### 3.5 헤더
- 헤더와 메서드는 클라이언트와 서버가 무엇을 하는지 결정하기 위해 함게 사용된다.
- 헤더는 특정 종류의 메시지에만 사용할 수 있는 헤더와, 더 일반 목적으로 사용할 수 있는 헤더
- 응답과 요청 메시지 양쪽 모두에서 제공하는 헤더가 있으며 헤더는 크게 다섯가지로 분류 된다.

###### 일반 헤더
- 일반 헤더는 클라이언트와 서버 양쪽 모두가 사용한다.
- 클라이언트, 서버, 애플리케이션들을 위해 다양한 목적으로 사용된다.

> Date: Tue, 3 Oct 1974 02:16:00 GMT

###### 요청 헤더
- 요청 메시지를 위한 헤더
- 서버에게 클라이언트가 받고자 하는 데이터의 타입이 무엇인지와 같은 부가 정보를 제공한다.

> Accept: */*

###### 응답 헤더
- 응답 헤더는 클라이언트에게 정보를 제공하기 위한 자신만의 헤더를 갖고 있다.

> Server: Tiki-Hut/1.0

###### 엔티티 헤더
- 엔티티 본문에 대한 헤더
- 엔티티 본문에 들어있는 데이터 타입이 무엇인지 말해줄 수 있다.

> Content-Type: text/html; charset=iso-latin-1

###### 확장 헤더
- 애플리케이션 개발자들에게 의해 만들어 졌지만 아직 승인된 HTTP 명세에는 추가되지 않은 비표준 헤더이다.

##### 3.5.1 일반 헤더
- 일반 헤더들은 메시지에 대한 아주 기본적인 정보를 제공한다.
- 메시지 종류에 상관없이 유용한 정보를 제공한다.

| 헤더 | 설명 |
|---|---|
| Connection | 클라이언트와 서버가 요청/응답 연결에 대한 옵션을 정할 수 있게 해준다. |
| Date* | 메시지가 언제 만들어졌는지에 대한 날짜와 시간을 제공한다. |
| MIME-Version | 발송자가 사용한 MIME의 버전을 알려준다. |
| Trailer chunked transfer | 인코딩으로 인코딩된 메시지의 끝 부분에 위치한 헤더들의 목록을 나열한다. |
| Transfer-Encoding | 수신자에게 안전한 전송을 위해 메시지에 어떤 인코딩이 적용되었는지 말해준다. |
| Upgrade | 발송자가 '업그레이드' 하길 원하는 새 버전이나 프로토콜을 알려준다. |
| Via | 이 메시지가 어떤 중개자 (프락시, 게이트웨이)를 거쳐 왔는지 보여준다. |

###### 일반 캐시 헤더
| 헤더 | 설명 | 
|---|---|
| Cache-Control | 메시지와 함께 캐시 지시자를 전달하기 위해 사용한다. |
| Pragma* | 메시지와 함께 지시자를 전달하는 또 다른 방법. 캐시에 국한되지 않는다. |

##### 3.5.2 요청 헤더
- 요청 메시지에서만 의미를 갖는 헤더이다.
- 요청의 최초 근원지, 누가 혹은 무엇이 그 요청을 보냈는지에 대한 정보나 클라이언트의 선호나 능력에 대한 정보를 준다.
- 서버는 요청헤더가 준 정보를 바탕으로 클라이언트에게 더 나은 응답을 주기 위해 활용할 수 있다.

###### Accept 관련 헤더
- 클라이언트는 Accept 관련 헤더들을 이용해 서버에게 자신의 선호와 능력을 알려 줄 수 있다.
- 클라이언트가 무엇을 원하고 무엇을 할수있는지, 무엇보다도 원치 않는것은 무엇인지 알려 줄 수 있다.

###### 조건부 요청 헤더
- 클라이언트는 요청에 몇몇 제약을 넣기도 한다.
- 이미 어떤 문서 사본을 가지고 있는 상태라면, 서버에게 해당 문서 요청시 자신이 가지고 있는 사본과 다를때만
- 전송을 해달라고 요청 할 수 있다.

###### 요청 보안 헤더
- HTTP는 자체적으로 요청을 위한 간단한 인증요구/응답 체계를 갖고 있다.
- 어느 정도의 리소스에 접근하기 전에 자신을 인증하게 함으로써 트랜잭션을 약간 더 안전하게 만들고자 한다.

###### 프락시 요청 헤더
- 인터넷에서 프락시가 점점 흔해지면서, 그들의 기능을 돕기 위한 헤더이다.

#### 3.5.3 응답 헤더
- 응답 헤더는 클라이언트에게 부가 정보를 제공한다.
- 누가 응답을 보내고 있는지 혹은 응답자의 능력은 어떻게 되는지 알려주며, 더 나아가 응답에 대한 특별한 설명을 제공할 수 있다.

###### 협상 헤더
- 서버에 프랑스어와 독일어로 번역된 HTML문서가 있는 경우와 같이 여러가지 표현이 가능한 상황이라면
- 협상 헤더를 통해 어떤 응답을 보여줄 것인지 결정할 수 있다.

###### 응답 보안 헤더
- 기본적으로 HTTP 인증요구/응답 체계에서 응답 측에 해당하는 요청 보안 헤더가 있다.

#### 3.5.4 엔티티 헤더
- 엔티티 헤더는 엔티티와 그것의 내용물에 대한, 개체의 타입부터 시작해 주어진 리소스에 대해 요청할 수 있는 유효한 메서드들 까지 광범위한 정보를 제공한다.
- 일반적으로 엔티티 헤더는 메시지의 수신자에게 자신이 다루고 있는 것이 무엇인지 말해준다.

###### 콘텐츠 헤더
- 엔티티의 콘텐츠에 대한 구체적인 정보를 제공한다.
- 콘텐츠의  종류, 크기, 기타 콘텐츠를 처리할 때 유용하게 활용될 수 있는 것들이다.

###### 엔티티 캐싱 헤더
- 엔티티 캐싱 헤더는 엔티티 캐싱에 대한 정보를 제공한다.
- 리소스에 대해 캐시된 사본의 유효여부, 캐시된 리소스가 더 이상 유효하지 않게 되는 시점을 더 잘 추정하기 위한 단서이다.

### 4장 커넥션 관리

#### 4.1 TCP 커넥션
- 모든 HTTP 통신은 TCP/IP를 통해 이루어 진다.

`브라우저에 URL 입력시 동작`
1. 브라우저가 www.naver.com 이라는 호스트를 추출
2. 브라우저가 이 호스트 명에 대한 IP주소를 찾는다.
3. 브라우저가 포트 번호를 얻는다.
4. 브라우저가 xxx.xxx.xxx.xxx 의 xx포트로 TCP 커넥션을 생성한다.
5. 브라우저가 서버로 HTTP GET 요청 메시지를 보낸다.
6. 브라우저가 서버에서 온 HTTP 응답 메시지를 읽는다.
7. 브라우저가 커넥션을 끊는다.

##### 4.1.1 신뢰할 수 있는 데이터 전송 통로인 TCP
- TCP는 HTTP에게 신뢰할 만한 통신 방식을 제공 한다.
- TCP 커넥션의 한쪽에 있는 바이트들은 반대쪽으로 순서에 맞게 정확히 전달된다.

> 충돌 없이 순서에 맞게 HTTP 데이터를 전달한다.

##### 4.1.2 TCP 스트림은 세그먼트로 나뉘어 IP패킷을 통해 전송된다.
- TCP는 IP 패킷 (데이터그램) 이라고 불리는 작은 조각을 통해 데이터를 전송한다.
- HTTPS는  TLS, SSL 이라고 불리기도 하며 HTTP와 TCP사이에 있는 암호화 계층이다.
- TCP는 세그먼트라는 단위로 데이터 스트림을 잘게 나누고, 세그먼트를 IP 패킷이라고 불리는 봉투에 담아 인터넷을 통해 데이터를 전달한다.

`IP 패킷 구성요소`
- IP패킷 헤더 (보통 20바이트)
    - 발신지와 목적지 IP주소, 크기, 기타 플래그를 가진다.
- TCP 세그먼트 헤더 (보통 20바이트)
    - TCP 포트 번호, TCP 제어 플래그, 데이터의 순서와 무결성을 검사하기 위해 사용하는 숫자값을 포함
- TCP 데이터 조각 (0 혹은 그이상의 바이트)

##### 4.1.3 TCP 커넥션 유지하기
- 컴퓨터는 항상 TCP 커넥션을 여러 개 가지고 있따.
- TCP 는 포트 번호를 통해서 이런 여러 개의 커넥션을 유지한다.

`TCP 커넥션`
TCP 커넥션은 다음과 같이 네 가지 값으로 식별한다.
이 네가지 값으로 유일한 커넥션을 생성하며, 서로 다른 두 개의 TCP 커넥션은 구송요소의 값이 모두 같을 수 없다.
```
<발신지 IP주소, 발신지포트, 수신지 IP주소, 수신지 포트>
```

##### 4.1.4 TCP 소켓 프로그래밍
- 운영체제는 TCP 커넥션의 생성과 관련된 여러 기능을 제공한다.
- 소켓 API를 사용하면 TCP 종단(endPoint) 데이터 구조를 생성하고, 원격 서버의 TCP 종단에 그 종단 데이터 구조를 연결하여 
데이터 스트림을 읽고 쓸 수 있다.

> TCP API는, 기본적인 네트워크 프로토콜의 핸드셰이킹, TCP 데이터 스트림과 IP 패킷 간의 분할 및 재조립에 대한 모든 세부
사항을 외부로 부터 숨긴다.

`클라이언트와 서버가 TCP 소켓 인터페이스를 사용하여 상호작용 하는 방법`
1. 서버는 새로운 소켓을 생성한다.
2. 80 포트로 소켓을 묶는다.
3. 소켓 커넥션을 허가한다 (listen)
4. 커넥션을 기다린다. (accept)
5. 클라이언트는 IP주소와 포트를 얻는다.
6. 새로운 소켓을 생성한다.
7. 서버의 IP:포트로 연결한다. (connect)
8. 서버는 애플리케이션 커넥션을 통지한다.
9. 요청을 읽기 시작한다. (read)
10. 클라이언트는 서버와 성공적으로 연결한다.
11. 클라이언트는 서버로 HTTP 요청을 보냄과 동시에 기다린다.
12. 서버는 HTTP요청 메시지를 처리한다.
13. 서버는 HTTP응답을 보낸다.
14. 클라이언트는 HTTP 응답을 처리하고, 커넥션을 닫는다.
15. 서버는 커넥션을 닫는다.

#### 4.2 TCP 성능에 대한 고려
- HTTP는 TCP 바로 위에 있는 계층이기 때문에 HTTP 트랜잭션의 성능은 TCP 성능에 영향을 받는다.

##### 4.2.1 HTTP 트랜잭션 지연
- 트랜잭션을 처리하는 시간은 TCP 커넥션을 설정하고, 요청을 전송하고, 응답 메시지를 보내는 것에 비하면 상당히 짧다.
- 클라이언튼 서버가 너무 많은 데이터를 내려받거나, 복잡하고 동적인 자원들을 실행하지 않는 한, 대부분의 HTTP지연은 
TCP 네트워크 지연 때문에 발생한다.

`HTTP 트랜잭션을 지연시키는 원인`
1. 클라이언트는 URI에서 웹서버의 IP 주소와 포트 번호를 알아내야 한다. DNS를 통해야 한다.
2. 다음으로 클라이언트는 TCP 커넥션 요청을 서버에 보내고 서버가 커넥션 허가 응답을 회신하기를 기다린다. 커넥션 설정 시간은
새로운 TCP 커넥션 생성시 항상 발생한다.
3. 커넥션이 맺어지면 클라이언트는 HTTP 요청을 새로이 생성된 TCP 파이프를 통해 전송한다.
4. 웹 서버가 HTTP 응답을 보내는 것 역시 시간이 소요된다.

> TCP 네트워크 지연은 하드웨어의 성능, 네트워크와 서버의 전송 속도, 요청과 응답 메시지의 크기, 클라이언트와 서버 간의
거리에 따라 크게 달라진다. TCP 프로토콜의 기술적인 복잡성도 지연에 큰 영향을 끼친다.

##### 4.2.2 성능 관련 중요 요소
- TCP 커넥션으 핸드 셰이크 설정
- 인터넷의 혼잡을 제어하기 위한 TCP의 느린 시작(slow-start)
- 데이터를 한데 모아 한 번에 전송하기 위한 네이글(nagle) 알고리즘
- TCP의 편승(piggyback) 확인응답(acknowledgement)을 위한 확인응답 지연 알고리즘
- TIME_WAIT 지연과 포트 고갈

##### 4.2.3 TCP 커넥션 핸드셰이크 지연
- 새로운 TCP 커넥션을 열때, 커넥션을 맺기 위한 조건을 맞추기 위해 연속적인 IP 패킷을 교환한다.
- 작은 크기의 데이터 전송에 커넥션이 사용된다면 HTTP 성능을 크게 저하시킬 수 있다.

`TCP 커넥션이 핸드셰이크를 하는 과정`
1. 새로운 TCP를 생성하기 위해 작은 TCP 패킷 (보통 40~60바이트)를 서버에서 보낸다. 해당 패킷은 'SYN' 이라는 플래그를 가진다.
해당 요청은 **커넥션 생성 요청** 이라는 의미이다.
2. 서버가 해당 커넥션을 받으면, 몇가지 커넥션 매개변수를 산출하고, 해당 요청이 받아졌음을 의미하는 패킷을 보낸다.
('SYN', 'ACK' 라는 플래그를 포함한다.)
3. 마지막으로 클라이언트는 커넥션이 잘 맺어졌음을 알리기 위해 서버에 다시 확인응답 신호를 보낸다. 요즘은 이 확인 응답
패킷과 함께 데이터를 보낼 수 있다.

> HTTP 트랜잭션이 아주 큰 데이터를 주고받지 않는 한, 핸드셰이크가 눈에 띄는 지연을 발생시킨다.

##### 4.2.4 확인응답 지연
- 각 TCP 세그먼트는 순번과 데이터 무결성 체크섬을 가진다.
- 만약 송신자가 특정 시간 안에 확인응답 메시지를 받지 못하면, 패킷이 파기되었거나 오류로 판단하고 해당 데이터를 다시
전송한다.

> 확인응답은 크기가 작기때문에, TCP는 데이터 패킷에 확인응답을 편승 시킨다. (송출 데이터패킷과 확인응답을 하나로 묶음)
> 또한 확인응답이 데이터 패킷에 편승되는 경우를 늘리기 위해 **확인응답 지연 알고리즘**을 구현한다.

`확인응답 지연`
- 송출할 확인응답을 특정 시간(0.1 ~ 0.2초) 동안 버퍼에 저장해두고 확인응답을 편승시키기 위한 송출 데이터 페킷을 찾는다.
- 만약 일정 시간 안에 송출 데이터 패킷을 찾이 못하면 확인 응답은 별도의 패킷을 만들어 전송된다.

##### 4.2.5 TCP 느린시작 (slow start)
- TCP 데이터 전송속도는 TCP 커넥션이 만들어진지 얼마나 지났는지에 따라 달라진다.
- TCP 커넥션은 시간이 지나면서 자체적으로 '튜닝' 되어, 처음에는 커넥션 최대 속도를 제한하고, 데이터가 성공적으로 전송
됨에 따라 속도제한을 높혀나간다.
- TCP가 한번에 전송할 수 있는 패킷의 수를 제한한다.
- HTTP 트랜잭션에서 전송할 데이터의 양이 많으면 모든 패킷을 한 번에 전송할 수 없다.
- 대신 한 개의 패킷을 먼저 보내고, 확인응답을 받으면 2개의 패킷을 보낼 수 있으며, 그 패킷 각각에 대한 응답을 받으면
총 4개의 패킷을 보낼 수 있게 된다.

> 이를 '혼잡 윈도를 연다(opening the congestion window)' 라고 한다.
> 이 혼잡제어 기능 덕에 새로운 커넥션은 '튜닝' 된 커넥션 보다 느리다.

##### 4.2.6 네이글(Nagle) 알고리즘과 TCP_NODELAY
- TCP는 매우 적은 크기의 데이터도 TCP 스택으로 전송 가능하도록 제공한다.
- 각 TCP 세그먼트는 40바이트 상당의 플래그와 헤더를 포함하기 때문에 작은 크기의 데이터를 포함한 많은 수의 패킷을 
전송한다면 네트워크 성능은 크게 떨어진다.

`네이글 알고리즘`
- 네이글 알고리즘은 네트워크 효율을 위해, 패킷을 전송 하기 전 많은 양의 TCP 데이터를 한개의 덩어리로 합친다.
- 세그먼트가 최대 크기가 되지 않으면 전송을 하지 않는다.
- 하지만 다른 모든 패킷이 확인응답을 받았을 경우에는 최대 크기보다 작은 경우에도 전송이 된다.

`네이글 알고리즘의 문제점`
1. 크기가 작은 HTTP 메시지는 패킷을 채우지 못하기 때문에 앞으로 생길지 안생길지 모르는 추가적인 데이터를 기다린다.
2. 확인응답 지연과 함께 쓰일경우 형편없이 동작한다. 확인응답이 도착할 때 까지 데이터 전송을 멈추고 있게 된다.

> HTTP는 성능 향상을 위해 HTTP 스택에 TCP_NODELAY 파라미터 값을 설정하여 네이글 알고리즘을 비활성화 하기도 한다.

##### 4.2.7 TIME_WAIT의 누적과 포트 고갈
- TIME_WAIT 포트 고갈은 성능 측정시 심각한 성능저하를 발생시키지만, 실제상황에서는 문제를 발생시키지 않는다.
- 클라이언트가 서버에 접속할 때 마다, 유일한 커넥션을 생성하기 위해 새로운 발신지 포트를 쓴다.
- 하지만 사용할 수 있는 발신지 포트의 수는 제한되어 있고 2MSL초 동안 커넥션이 재사용될 수 없으므로, 초당 500개로 커넥션이
제한된다.
- 서버가 초당 500개 이상의 트랜잭션을 처리할 만큼 빠르지 않다면 TIME_WAIT 포트 고갈은 일어나지 않는다.

#### 4.3 HTTP 커넥션 관리

##### 4.3.1 흔히 잘못 이해하는 Connection 헤더
- HTTP Connection 헤더 필드는 커넥션 토큰을 쉼표로 구분하여 가지고 있으며, 그 값들은 다른 커넥션에 전달되지 않는다.
- 다음 메시지를 보낸 다음 끊어져야 할 커넥션은 Connection: close 라고 명시할 수 있따.

`Connection 헤더`
- 다음 세가지 종류의 토큰이 전달될 수 있기 때문에 다소 혼란스러울 수 있다.
1. HTTP 헤더 필드 명은, 이 커넥션에만 해당되는 헤더들을 나열한다.
2. 임시적인 토큰 값은, 커넥션에 대한 비표준 옵션을 의마한다.
3. close 값은, 커넥션이 작업이 완료되면 종료되어야 함을 의미한다.

> Connection 헤더에 있는 모든 헤더 필드는 메시지를 다른 곳으로 전달하는 시점에 삭제 되어야 한다.

- Connection 헤더에는 홉별(hop-by-hop) 헤더 명을 기술하는데, 이것을 '헤더 보호하기' 라고 한다.

##### 4.3.2 순차적인 트랜잭션 처리에 의한 지연
- 커넥션 관리가 제대로 이루어지지 않으면 TCP 성능이 매우 안좋아질 수 있따.
- 이미지가 3개가 있는 웹 페이지가 있다면 HTTP 트랜잭션은 총 4개를 생성해야한다.
- 각 트랜잭션이 새로운 커넥션을 필요로 하다면 커넥션을 맺는데 발생한 지연과 함께 느린 시작지연이 발생할것이다.

#### 4.4 병렬 커넥션
- HTTP는 클라이언트가 여러 개의 커넥션을 맺음으로써 여러 개의 HTTP 트랜잭션을 병렬로 처리할 수 있게 한다.

1. 병렬 커넥션은 페이지를 더 빠르게 내려받는다.
2. 병렬 커넥션이 항상 더 빠르지는 않다.
3. 병렬 커넥션은 더 빠르게 느껴질 수 있다.


#### 4.5 지속 커넥션
- 웹 클라이언트는 보통 같은 사이트에 여러 개의 커넥션을 맺는다.
- 웹페이지에 첨부된 이미지들, 하이퍼 링크도 같은 사이트를 가리킨다.
- 서버에 HTTP요청을 하기 시작한 애플리케이션은 웹페이지 내의 이미지 등을 가져오기 위해 그 서버에 또 요청하게 되는데
이를 **사이트 지역성(site locality)** 이라고 한다.

> HTTP/1.1 을 지원하는 기기는 처리가 완료된 후 TCP 커넥션을 유지하여, HTTP 요청에 재사용할 수 있다. 이를 지속커넥션 이라고 한다.

##### 4.5.1 지속 커넥션 vs 병렬 커넥션
`병렬 커넥션의 단점`
1. 각 트랜잭션 마다 새로운 커넥션을 맺고 끊기 때문에 시간과 대역폭이 소요된다.
2. 각각의 새로운 커넥션은 TCP 느린 시작 때문에 성능이 떨어진다.
3. 실제로 연결할 수 있는 병렬 커넥션의 수에는 제한이 있다.

`지속 커넥션의 장점`
1. 커넥션을 맺기 위한 사전 작업과 지연을 줄여준다.
2. 튜닝된 커넥션을 유지하며, 커넥션 수를 줄여준다.

> 지속 커넥션은 잘못 관리할 경우, 연결된 상태로 수많은 커넥션이 쌓여 리소스에 불필요한 소모를 발생 시킨다.

**지속 커넥션은 병렬 커넥션과 함께 사용될 때 가장 효과적이며, 오늘날 많은 웹 애플리케이션은 적은 수의 병렬 커넥션만을 맺고
그것을 유지한다.**

##### 4.5.2 HTTP/1.0+의 Keep-Alive 커넥션
`keep-alive 커넥션의 장점`
- 같은 네 개의 HTTP 트랜잭션에 대해 연속적으로 네 개의 커넥션을 생성하는 방식과 비교 했을때, 커넥션을 맺고 끊는데 
필요한 작업이 없어서 시간이 단축된다.

##### 4.5.3 Keep-Alive 동작
- Keep-Alive 는 사용하지 않기로 결정되어 HTTP/1.1 명세에서 빠졌지만 keep-alive 핸드셰이크가 널리 사용돠고 있다.
1. 요청시 Connection:Keep-Alive 헤더를 포함시킨다.
2. 요청을 받은 서버는 그 다음 요청에도 이 커넥션을 통해 받고자 한다면, 응답메시지에 같은 헤더를 포함시켜 응답한다.
3. 응답에 Keep-Alive 헤더가 없다면 서버가 keep-alive를 지원하지 않으며, 응답 메시지가 전송된 후 서버는 커넥션을 끊을 것이라 추정한다.

##### 4.5.4 Keep-Alive 옵션
- Keep-Alive 헤더는 커넥션을 유지하기를 바라는 요청일 뿐이다.
- 클라이언트나 서버가 해당 요청을 받았다고 해서 무조건 따를 필요는 없다.
- 언제든지 커넥션을 끊을 수 있으며, 처리되는 트랜잭션의 수를 제한할 수 있다.

**keep-alive의 동작은 헤더의 쉼표로 구분된 옵션들로 제어할 수 있다.**
`keep-alive의 각 옵션들`
1. timeout파라미터는 커넥션이 얼마간 유지될 것인지 의미한다. 
2. max 파라미터는 해당 커넥션이 몇 개의 HTTP 트랜잭션을 처리할때 까지 유지할것인지 의미한다.

##### 4.5.5 Keep-Alive 커넥션 제한과 규칙
1. keep-alive는 HTTP/1.0에서는 기본으로 사용되지 않는다. 클라이언트는 keep-alive 요청헤더를 보내야 한다.
2. 커넥션을 계속 유지하려면 모든 메시지에 Connection:Keep-Alive 헤더를 포함해야 한다.
3. 클라이언트는 Keep-Alive 헤더가 없는것을 보고 서버가 응답후 커넥션을 끊을것임을 알 수 있다.
4. 커넥션이 끊어지기 전, 엔티티 본문의 길이를 알아야 커넥션을 유지할 수 있다.
    - 트랜잭션이 끝나는 시점에 기존 메시지의 끝과 새로운 메시지의 시작점을 정확히 알 수 있어야 한다.
5. 프락시, 게이트웨이는 Connection 헤더의 규칙을 철저히 지커야 한다.
    - 메시지를 전달하거나 캐시에 넣기 전, Connection 헤더에 명시된 모든 헤더 필드와 Connection 헤더를 제거해야 한다.
6. 원래 대로라면, keep-alive 커넥션은 Connection 헤더를 인식하지 못하는 프락시와 맺어지면 안된다.
7. 기술적으로 HTTP/1.0을 따르는 기기로부터 받는 모든 Connection 헤더 필드는 무시해야 한다.
8. 클라이언트는 응답 전체를 모두 받기전에 커넥션이 끊어졌응ㄹ 경우, 별다른 문제가 없다면 요청을 다시 보낼수 있게 준비되어야 한다.

##### 4.5.6 Keep-Alive와 멍청한 프락시
- 만약 Connection 헤더를 지원하지 않는 프락시와 상호작용을 한다면, 다음과 같은 문제가 발생한다.

1. 클라이언트가 서버로 Connection:Keep-Alive 헤더가 포함된 요청을 보낸다.
2. 프락시는 Connection 헤더를 모르기 때문에 그대로 서버로 전달한다.
3. 서버는 keep-alive 요청을 받았기 때문에 처리가 완료된 후에도 커넥션을 끊지 않는다.
4. 서버로부터 응답을 받은 프락시는 클라이언트에게 Connection:Keep-Alive 헤더가 포함된 응답을 보낸다.
5. 프락시는 Connection 헤더를 모르기 때문에 서버와 커넥션이 끊어지는것을 기다리고 있다. 해당 keep-alive 커넥션을 통해
오는 클라이언트의 새 요청을 무시한다.
6. 이런 잘못된 통신 때문에, 브라우저는 자신이나 서버가타임아웃이 나서 커넥션이 끊길 때까지 기다린다.

##### 4.5.7 Proxy-Connection 살펴보기
- 멍청한 프락시는 Connection:Keep-Alive 같은 홉별 헤더를 무조건 전달하기 때문에 문제를 일으킨다.
- 이를 해결하기 위해 브라우저는 Connection 헤더 대신 비표준인 Proxy-Connection 확장 헤더를 프락시에게 전달한다.
- 프락시가 이를 무조건 전달하더라도 문제가 발새앟지 ㅇ낳는다.
- 하지만 영리한 프락시라면 이를 Connection:Keep-Alive 헤더로 변환하여 처리를 하게 된다.

> 하지만 여러개의 프락시 서버가 존재하는 경우 문제가 발생할 수 있다.

##### 4.5.8 HTTP/1.1의 지속 커넥션
- HTTP/1.1에서는 keep-alive 커넥션 대신 설계가 더 개선된 지속 커넥션을 지원한다.
- HTTP/1.1의 지속커넥션은 기본으로 활성화 되어있다. 모든 커넥션을 지속 커넥션으로 인식한다.

> HTTP/1.1 애플리케이션은 트랜잭션이 끝난 뒤 커넥션을 끊으러면 Connection:close 헤더를 명시해야 한다.

##### 4.5.9 지속 커넥션의 제한과 규칙
1. 클라이언트가 요청에 Connection: close 헤더를 포함했다면 클라이언트는 그 커넥션으로 추가 요청을 할 수 없다.
2. 클라이언트는 마지막 요청에 Connection: close 헤더를 보내야 한다.
3. 커넥션에 있는 모든 메시지가 자신의 길이 정보를 정확히 가지고 있을때만 커넥션을 지속할 수 있다.
4. HTTP/1.1 프락시는 클라이언트와 서버 각각에 대해 별도의 지속 커넥션을 맺고 관리해야 한다.
5. HTTP/1.1 프락시 서버는 클라이언트가 커넥션 관련 기능에 대한 지원 범위를 알고 있지 않다면 지속 커넥션을 맺으면 안된다.
6. HTTP/1.1 기기는 Connection 헤더의 값과 상관없이 언제든지 연결을 끊을 수 있다.
7. HTTP/1.1 애플리케이션은 중간에 끊어지는 커넥션을 복구할 수 있어야 한다.
8. 크라이언트는 전체 응답을 받기 전에 커넥션이 끊어질경우, 요청을 반복해서 보내도 문제없는 경우에는 요청을 다시 보낼준비가 되어야 한다.
9. 클라이언트는 서버의 과부하를 방지하기 위해 2개의 지속 커넥션만을 유지해야 한다.

#### 4.6 파이프라인 커넥션
- HTTP/1.1 은 지속 커넥션을 통해 요청을 파이프라이닝 할 수 있다.
- 이는 keep-alive의 성능을 더 높혀준다. (대기 시간이 긴 네트워크 상황에서 왕복으롤 인한 시간을 줄여줌)

`파이프 라인의 제약사항`
1. HTTP 클라이언트는 커넥션이 지속 커넥션인지 확인 하기전에는 파이프라인을 이어서는 안된다.
2. 응답은 요청 순서와 같게 와야한다. (순서가 없기 때문에 정렬할 방법이 없음)
3. 클라이언트는 커넥션이 언제 끊어지더라도 완료되지 않은 요청이 파이프라인에 있으면 언제든 다시 요청을 보낼 준비가 되어야한다.
4. 클라이언트는 POST 처럼 비멱등 요청을 파이프라인을 통해 보내선 안된다.

#### 4.7 커넥션 끊기에 대한 미스터리
- 커넥션 관리에는 명확한 기준이 없다.

##### 4.7.1 마음대로 커넥션 끊기
- 어떠한 클라이언트, 서버, 프락시던지 언제든 TCP 전송 커넥션을 끊을 수 있다.
- 보통 커넥션은 메시지를 다 보낸뒤 끊지만, 에러가 있는 상황에서는 헤더의 중간이나 다른 엉뚱한 곳에서 끊길수 있다.

##### 4.7.2 Content-Length 와 Truncation
- 클라이언트나 프락시가 커넥션이 끊어졌다는 응답을 받은후, 실제 전달된 엔티티길이와 Content-Lengt값이 일치하지 않거나
Content Length자체가 존재하지 않으면 수신자는 데이터의 정확한 길이를 서버에 물어봐야 한다.
- 수신자가 캐시 프락시일 경우 응답을 캐시하면 안된다.

##### 4.7.3 커넥션 끊기의 허용, 재시도, 멱등성
- HTTP애플리케이션은 예상치 못하게 커넥션이 끊어졌을 때에 적절히 대응할 수 있는 준비가 되어 있어야 한다.
- 한 번 혹은 여러 번 실행됬는지에 상관없이 같은 결과를 반환한다면 그 트랜잭션은 멱등이라고 한다.
- GET, HEAD, PUT, DELETE, TRACE, OPTIONS 메서드가 멱등이라고 이해하면 된다.
- 클라이언트는 POST와 같이 멱등이 아닌 요청은 파이프라인을 통해 요청하면 안된다.

##### 4.7.4 우아한 커넥션 끊기
- TCP 커넥션은 양방향이다.

###### 전체 끊기와 절반 끊기
- TCP 입력 채널과 출력 채널 중 한개만 끊거나 둘 다 끊을수 있다.
- close() 호출시 입력, 출력 채널 모두 끊으며 이를 전체 끊기라고 한다.
- 둘중 하나만 개별적으로 끊으려면 shutdown()을 호출해야하는데 이를 절반 끊기 라고한다.

###### 우아하게 커넥션 끊기
- 클라이언트나 서버가 예기치 않게 커넥션을 끊어야 한다면 우아하게 커넥션을 끊어야 한다고 하지만, 정작 그 방법은 설명하고
있지 않다.
- 일반적으로 우아한 끊기를 구현하는 것은 자신의 출력 채널을 먼저 끊고 다른 쪽에 있는 기기의 출력 채널이 끊기는 ㄱ서을
기다린다.
- 하지만 상대방이 절반 끊기를 구현했다는 보장도 없고 절반 끊기를 했는지 검사해준다는 방법 이없다.
- 절반 끊기를 한 뒤 식별하기 위해 입력채널에 대해 상태 검사를 주기적으로 해야한다.

### 5장 웹 서버

#### 5.1 다채로운 웹서버
- 웹 서버는 HTTP 요청을 처리하고 응답을 제공한다.
- 웹서버는 기능, 형태 크기가 다양하다. 그러나 기능은 달라도, 모든 웹서버는 리소스에 대한 HTTP 요청을 받아 클라이언트에게 돌려준다.

##### 5.1.1 웹 서버 구현
- 웹 서버는 HTTP 프로토콜을 구현하고, 웹 리소스를 관리하고, 웹서버 관리 기능을 제공한다.
- 웹 서버는 TCP 커넥션 관리에 대한 책임을 운영체제와 나눠 갖는다.

##### 5.1.2 다목적 소프트웨어 웹서버
- 웹 서버 소프트웨어는 거의 모든 컴퓨터와 운영체제에서 동작한다.
- 웹 사이트의 37%가 마이크로소프트의 웹서버를 통해 서비스 되고 있으며, 아파치 웹서버가 35%, nginx가 14%를 점유하고 있다.

##### 5.1.3 임베디드 웹 서버
- 임베디드 웹 서버는 일반 소비자용 제품에 내장될 목적으로 만들어진 작은 웹 서버이다.
- 사용자가 그들의 일반 소비자용 기기를 간편한 웹 브라우저 인터페이스로 관리할 수 있게 해준다.

#### 5.2 간단한 펄 웹서버
- 완전한 기능을 갖춘 HTTP 서버를 만들고자 한다면 할일이 많다.
- HTTP/1.1의 기능들을 지원하려면, 풍부한 리소스 지원, 가상 호스팅, 접근 제어, 로깅, 설정, 모니터링, 그외 성능을 위한
각종 기능들이 필요하다.
- 하지만 최소한의 기능만을 만든다면 30줄이하의 펄 코드로 만들 수 있다.

#### 5.3 진짜 웹 서버가 하는 일
1. 커넥션을 맺는다 - 클라이언트의 접속을 받아들이거나, 원치 않는 클라이언트라면 닫는다.
2. 요청을 받는다 - HTTP 요청 메시지를 네트워크로부터 읽어 들인다.
3. 요청을 처리한다. - 요청 메시지를 해석하고 행동을 취한다.
4. 리소스에 접근한다. - 메시지에서 지정한 리소스에 접근한다.
5. 응답을 만든다. - 올바른 헤더를 포함한 HTTP 응답 메시지를 생성한다.
6. 응답을 보낸다. - 응답을 클라이언트에게 돌려준다.
7. 트랜잭션을 로그로 남긴다. - 로그파일에 트랜잭션 완료에 대한 기록을 남긴다.

#### 5.4 단계 1: 클라이언트 커넥션 수락
- 클라이언트가 이미 서버에 대해 열려있는 지속적 커넥션을 갖고 있다면, 클라이언트는 요청을 보내기위해 커넥션을 사용할 수 있다.
- 그렇지 않을 경우 클라이언트는 서버에 대한 새 커넥션을 열 필요가 있다.

##### 5.4.1 새 커넥션 다루기
- 웹 서버에 TCP 커넥션 요청을 하면, 웹 서버는 커넥션을 맺고 TCP 커넥션에서 IP주소를 추출하여 맞은편에 어떤 클라이언트가
있는지 확인한다.
- 서버는 새 커넥션을 커넥션 목록에 추가하고 커넥션에서 오가는 데이터를 지켜보기 위한 준비를 한다.
- 웹 서버는 어떤 커넥션이든 마음대로 거절하거나 즉시 닫을 수 있다.

##### 5.4.2 클라이언트 호스트 명 식별
- 대부분은 DNS 를 이용하여 클라이언트의 IP주소를 클라이언트 호스트 명으로 변환하도록 설정되어 있다.
- 웹 서버는 클라이언트 호스트 명을 구체적인 접근 제어 및 로깅에 사용한다.

> hostname lookup은 꽤 시간이 많이 걸릴 수 있어 웹 트랜잭션을 느려지게 할 수 있다.

##### 5.4.3 ident를 통해 클라이언트 사용자 알아내기
- ident 프로토콜은 서버에게 어떤 사용자 이름이 HTTP 커넥션을 초기화 했는지 찾아낼 수 있게 해준다.
- 이 정보는 웹서버 로깅에서 유용하기 때문에, 널리 쓰이는 일반 로그 포맷의 두 번째 필드는 HTTP요청의 ident 사용자 이름을
담고 있다.
- ident 프로토콜을 지원한다면, ident 결과를 위해 TCP 113번 포트를 listen한다.
- ident는 조직내부에서는 잘 사용하지만, 공공 인터넷에서는 잘 동작하지 않는다.

`ident가 공공 인터넷에서 잘 동작하지 않는 이유`
1. 많은 클라이언트 PC는 identd 신원확인 프로토콜 데몬을 실행하지 않는다.
2. ident 프로토콜은 HTTP 트랜잭션을 유의미하게 지연시킨다.
3. 방화벽이 ident 트래픽이 들어오는 것을 막는 경우가 많다.
4. ident 프로토콜은 안전하지 않고 조작하기 쉽다.
5. ident 프로토콜은 가상 ip주소를 잘 지원하지 않는다.
6. 클라이언트 사용자 이름의 노출로 인한 프라이버시 침해의 우려가 있다.

#### 5.5 단계 2: 요청 메시지 수신
`요청 메시지를 파싱할때 웹서버의 동작`
1. 요청줄을 파싱하여 요청 메서드, 지정된 리소스의 식별자(URI), 버전 번호를 찾는다. 각 값은 스페이스 한 개로 분리되어
됬으며, 요청줄은 캐리지 리턴 줄바꿈(CRLF) 문자열로 끝난다.
2. 메시지 헤더들을 읽는다. 각 메시지 헤더들은 CRLF 로 끝난다.
3. 헤더의 끝을 의미하는 CRLF로 끝나는 빈줄을 찾아낸다.
4. 요청 본문이 있다면, 읽ㄹ어들인다. 길이는 Content-Length 헤더로 정의된다.

##### 5.5.1 메시지의 내부 표현
- 몇몇 웹 서버는 요청 메시지를 쉽게 다르기 위해 내부의 자료구조에 저장한다.

##### 5.5.2 커넥션 입력/출력 처리 아키텍쳐
- 고성능 웹 서버는 수천 개의 커넥션을 동시에 열 수 있도록 지원한다.

###### 단일 스레드 웹 서버
- 한번에 하나씩 요청을 처리한다.
- 트랜잭션이 완료되면 다음 커넥션이 처리된다.
- 로드가 적은 서버나 type-o-serve 같은 진단도구에서만 적당하다.

###### 멀티프로세스와 멀티스레드 웹 서버
- 여러 요청을 동시에 처리하기 위해 여러 개의 프로세스 또는 고효율 스레드를 할당한다.
- 프로세스/스레드는 필요시마다 만들어질 수 도 있고, 미리 만들어질 수 있다.
- 서버가 수천 수만개의 동시 커넥션을 처리할때 발생할 문제를 대비하여 스레드/프로세스의 최대 개수에 제한을 건다.

###### 다중 I/O 서버
- 대량의 커넥션을 지원하기 위해 많은 웹 서버는 다중 아키텍처를 채택했다.
- 다중 아키텍쳐에서 모든 커넥션은 동시에 그 활동을 감시 당한다.

###### 다중 멀티스레드 웹서버
- 몇몇 시스템은 CPU가 여러개 인것의 이점을 살리기 위해 멀티스레딩과 다중화를 결합한다.
- 여러개의 스레드는 각각 열려있는 커넥션을 감시하고 각 커넥션에 대해 조금씩 작업을 수행한다.

#### 5.6 단계 3: 요청 처리
- 웹 서버가 요청을 받으면, 서버는 요청으로 부터 메서드, 리소스, 헤더, 본문 을 얻어내어 처리한다.
- POST 를 비롯한 몇몇 메서드는 요청 멧지ㅣ에 엔터티 본문이 있을 것을 요구한다.
- GET과 같이 요청 메시지에 본문이 있는것을 금지하는 메서드도 있다.

#### 5.7 단계 4: 리소스의 매핑과 접근
- 웹 서버는 리소스 서버이다.
- 서버위에서 동작하는 리소스 생성 애플리케이션을 통해 만들어진 동적 콘텐츠도 제공한다.

##### 5.7.1 Docroot
- 웹 서버는 여러 종류의 리소스 매핑을 지원한다.
- 일반적으로 웹 서버 파일시스템의 특별한 폴더를 웹 콘텐츠를 위해 예약해둔다 이 폴더를 docroot 라고 부른다.

##### 5.7.2 디렉터리 목록
- 웹 서버는 경로가 파일이 아닌 디렉터리를 가리키는, 디렉터리 URL에 대한 요청을 받을 수 있다.

##### 5.7.3 동적 콘텐츠 리소스 매핑
- 웹 서버는 URI를 동적 리소스에 매핑할 수 있다.
- 요청에 맞게 콘텐츠를 생성하는 프로그램에 URI를 매핑하는 것이다.

##### 5.7.4 서버사이드 인클루드 (Server-Side Includes, SSI)
- 많은 웹서버가 서버사이드 인클루드도 지원한다.
- 서버는 콘텐츠에 변수 명이나 내장된 스크립트가 될 수 있는 어떤 패턴이 있는지 검사를 받는다.
- 특별한 패턴은 변수 값이나 실행 가능한 스크립트의 출력 값으로 치환된다.

##### 5.7.5 접근 제어
- 웹 서버는 각각의 리소스에 접근 제어를 할당할 수 있다.
- 클라이언트의 IP주소에 근거하여 접근을 제어할 수 있고, 비밀번호를 물어볼 수도 있다.

#### 5.8 단계 5: 응답 만들기
- 서버가 리소스를 식별하면, 서버는 요청 메서드로 서술되는 동작을 수행한 뒤 응답 메시지를 반환한다.
- 응답 메시지는 상태코드, 헤더, 응답 본문을 포함한다.

##### 5.8.1 응답 엔티티
`응답 메시지가 주로 포함하는 내용`
- 응답 본문의 MIME 타입을 서술하는 Content-Type 헤더
- 응답 본문의 길이를 서술하는 Content-Length 헤더
- 실제 응답 본문의 내용

##### 5.8.2 MIME 타입 결정하기
- 웹 서버는 응답 본문의 MIME 타입을 결정해야 하는 책임이 있다.

`mime.types`
- 웹 서버는 MIME 타입을 나타내기 위해 파일 이름의 확장자를 사용할 수 있다.

`매직 타이핑(Magic typing)`
- 아파치 웹 서버는 MIME타입을 알아내기 위해 파일의 내용을 검사해서 알려진 패턴에 대한 테이블 (매직 파일) 에 해당하는 패턴
이 있는지 찾아 볼 수 있다.

`유형 명시(Explicit typing)`
- 특정 파일이나 디렉터리 안의 파일들이 파일 확장자나 내용에 상관없이 어떤 MIME 타입을 갖도록 웹서버를 설정할 수 있다.

`유형 협상(Type negotiation)`
- 어떤 웹서버는 한 리소스가 여러 종류의 문서 형식에 속하도록 설정할 수 있다.
- 특정 파일이 특정 MIME 타입을 갖게끔 설정할 수도 있다.

##### 5.8.3 리다이렉션
- 웹 서버는 종종 성공 메시지 대신 리다이렉션 응답을 반환한다.
- 요청을 수행하기 위해 브라우저가 다른 곳으로 가도록 리다이렉트 할 수 있다.
- 3XX 상태코드로 지칭되며, Location 응답 헤더는 콘텐츠의 새로운 혹은 선호하는 위치에 대한 URI를 포함한다.

#### 5.9 단계 6: 응답 보내기
- 웹 서버는 받을때와 마찬가지로 데이터를 보낼 때에도 비슷한 이슈에 직면한다.
- 서버는 커넥션 상태를 추적해야 하며 지속적인 커넥션은 특별히 주의하여 다를 필요가 있다.

#### 5.10 단계 7: 로깅
- 트랜잭션이 완료되었을 때 웹 서버는 트랜잭션이 어떻게 수행되엇는지에 대한 로그를 로그파일에 기록한다.


### 6장 프락시
- 웹 프락시 서버는 중개자이다.
- 프락시는 클라이언트와 서버 사이에 위치하여 그들 사이의 HTTP 메시지를 정리하는 중개인 처럼 동작한다.

#### 6.1 웹 중개자
- 웹 프락시 서버는 클라이언트의 입장에서 트랜잭션을 수행하는 중개인이다.
- HTTP프락시는 웹서버 이기도하고, 웹 클라이언트이기도 하다.

##### 6.1.1 개인 프락시와 공유 프락시
- 하나의 클라이언트 만을 위한 프락시를 개인프락시라고 한다.
- 여러 클라이언트가 함께 사용하는 프락시는 공용 프락시라고 한다.

###### 공용 프락시
- 대부분의 프락시는 공용이며 공유된 프락시이다.
- 중앙 집중형 프락시를 관리하게는 더 비용효율이 높도 쉽다.
- 캐시 프락시같은 몇몇 프락시는 이용자가 많을수록 유리하다. -> 여러사용자들을 통해 공통된요청에서 이득을 취함

###### 개인 프락시
- 개인 프락시는 흔한 형태는 아니다.
- 브라우저 기능 확장, 성능 개선 등을 위해 작은 프락시를 컴퓨터에서 직접 실행한다.

##### 6.1.2 프락시 대 게이트웨이
- 프락시는 같은 프로토콜을 사용하는 둘이상의 애플리케이션을 연결한다.
- 게이트웨이는 서로다른 프로토콜을 사용하는 둘 이상을 연결한다.

> 게이트 웨이는 서로 다른 프로토콜로 통신이 가능하도록 프로토콜 변환기처럼 동작한다.

#### 6.2 왜 프락시를 사용하는가 ?

###### 어린이 필터
- 초등학교에서 어린이 들에게 교육사이트를 제공하는 동시에 성인컨텐츠를 타단하는 목적으로 필터링 프락시를 사용할 수 있다.

###### 문서 접근 제어자
- 프락시 서버는 많은 웹서버들과 웹 리소스에 대한 단일한 접근 제어 전략을 구현하고 감사 추적을 하기 위해 사용될 수 있다.

###### 보안 방화벽
- 네트워크 보안 엔지니어는 종종 보안을 강화하기 위해 프락시 서버를 사용한다.
- 조직 안에 들어오거나 나가는 응용 레벨 프로토콜의 흐름을 네트워크의 한 지점에서 통제한다.

###### 웹 캐시
- 프락시 캐시는 인기 있는 문서의 로컬 사본을 관리하고 해당 문서에 대한 요청이 오면 빠르게 제공한다.

###### 대리 프락시
- 어떤 프락시들은 웹 서버인 것처럼 위장한다.
- 대리 혹은 리버스 프락시라고 불린다.
- 웹 서버 요청을 받아 웹 서버와는 다르게 요청 받은 콘텐츠의 위치를 찾아내기 위해 다른 서버와의 통신을 한다.

###### 콘텐츠 라우터
- 인터넷 트래픽 조건과 콘텐츠의 종류에 따라 요청을 특정 웹서버로 유도하는 콘텐츠 라우터로 사용할 수 있다.

###### 트랜스코더
- 콘텐츠를 클라이언트에게 전달하기 전, 본문 포맷을 수정할수 잇으며 이런 방식을 트랜스 코딩이라고 한다.
- 크기를 줄이기 위해 GIF 를 JPG로 변환하는 등의 작업을 할수 있다.

###### 익명화 프락시
- HTTP 메시지에서 신원을 식별할 수 있는 특성들을 제거함으로써 개인정보 보호와 익명성 보장에 기여한다. 

#### 6.3 프락시는 어디에 있는가 ?
- 어떻게 프락시가 네트워크에 배치되는가
- 어떻게 프락시의 연쇄가 계층을 이루는가
- 어떻게 트래픽이 올바르게 프락시를 찾아가는가

##### 6.3.1 프락시 서버 배치

###### 출구(Egress) 프락시
- 로컬 네트워크와 더 큰 인터넷 사이를 오가는 트래픽을 제어하기 위해 프락시를 로컬 네트워크의 출구에 박아 넣을 수 있다.
- 방화벽 제공, 인터넷 요금을 절약하고 트래픽 성능을 개선, 부적절한 컨텐츠 제어가 가능하다.

###### 접근(입구) 프락시
- 고객으로 부터 모든 요청을 종합적으로 처리하기 위해 프락시는 ISP 접근 지점에 위치한다.
- 다운로드 속도를 개선하고, 인터넷 대역폭 비용을 줄이기 위해 캐시 프락시를 사용한다.

###### 대리 프락시
- 대리 프락시 (리버스 프락시) 로 사용된다.
- 대리 프락시는 웹 서버들의 바로 앞에 위치하여 웹 서버로 향하는 모든 요청을 처리하고 필요시에만 웹서버에게 자원을 요청 한다.
- 일반적으로 웹 서버의 이름과 IP 주소로 스스로를 가장하기 때문에 모든 요청은 서버가 아닌 프락시로 가게 된다.

###### 네트워크 교환 프락시
- 캐시를 이용해 인터넷 교차로의 혼잡을 완화하고 트래픽 흐름을 감시하기 위해, 충분한 처리 능력을 갖춘 프락시가 네트워크
사이의 인터넷 피어링 교환 지점들에 놓일 수 있다.

##### 6.3.2 프락시 계층
- 프락시 계층은 연쇄를 구성할 수 있다.
- 메시지는 최종적으로 원 서버에 도착할 때 까지 프락시와 프락시 사이를 거쳐 이동한다.
- 프락시 서버들은 부모와 자식 관계를 가지며 인바운드 프락시 (서버에 가까운쪽)를 부모라 부르고, 아웃바운드 프락시 (클라이언트에 가까운 쪽)
를 자식 이라고 부른다.

##### 6.3.3 어떻게 프락시가 트래픽을 처리하는가 ?
- 클라이언트 트래픽이 프락시로 가도록 만드는 방법에는 네 가지 방법이 있다.

`클라이언트를 수정한다.`
- 구글 크롬을 포함한 많은 웹 클라이언트 들은 수동 혹은 자동 프락시 설정을 지원한다.
- 클라이언트가 프락시를 사용하도록 설정 되어 있다면, 클라이언트는 HTTP 요청을 바로 그리고 의도적으로 원 서버가 아닌 프락시로 보낸다.

`네트워크를 수정한다.`
- 네트워크 인프라를 가로채서 웹 트래픽을 프락시로 가도록 조정하는 기법이 있다.
- 이 가로챔은 일반적으로 HTTP 트래픽을 지켜보고 가로채어 클라이언트 모르게 프락시로 보내는 스위칭 장치와 라우팅 장치를
필요한다.
- 이것을 **인터셉트 프락시** 라고 한다.

`DNS 이름공간을 수정한다.`
- 대리 프락시는 웹 서버의 이름과 IP 주소를 자신이 직접 사용한다.
- 이를 DNS 이름 테이블을 수동으로 편집하거나 사용할 적절한 프락시나 서버를 계산해주는 특별한 동적 DNS 서버를 이용해서
조정될 수 있다.

`웹 서버를 수정한다.`
- 몇몇 웹 서버는 HTTP 리다이렉션 명령을 클라이언트에게 돌려줌으로써 클라이언트의 요청을 프락시로 리다이렉트 하도록
설정할 수 있다.

#### 6.4 클라이언트 프락시 설정

1. 수동설정
    - 프락시를 사용하겠다고 명시적으로 설정한다.

2. 브라우저 기본 설정
    - 브라우저 벤더나 배포자는 브라우저를 소비자에게 전달 하기 전에 프락시를 미리 설정해 놓을 수 있다.
    
3. 프락시 자동 설정 (Proxy Auto Configuration, PAC)
    - 자바스크립트 프락시 자동 설정 파일에 대한 URI를 제공할 수 있다.
    - 프락시 사용 유무를 자바스크립트 파일을 가져와 실행한다.
    
4. WPAD 프락시 ㅂ라견
    - 대부분의 브라우저는 자동설정 파일을 다운받을수 있는 웹 프락시 자동발견 프로토콜 (Web Proxy Autodiscovery Protocol, WPAD) 를 제공한다.

##### 6.4.1 클라이언트 프락시 설정: 수동
- 많은 웹 클라이언트가 프락시를 수동으로 설정할 수 있도록 하고 있다.
- 구글 크롬과 마이크로소프트 인터넷 익스플로러 둘 모두 간편하게 프락시 설정을 할 수 있도록 지원한다.

##### 6.4.2 클라이언트 프락시 설정: PAC 파일
- 수동 프락시 설정은 단순하지만 유연하지 못하다.
- PAC 파일은 프락시 설정에 대한 보다 동적인 해결책이다.
- 문서에 접근할 때 마다 자바스크립트 함수가 적절한 프락시 서버를 선택한다.

##### 6.4.3 클라이언트 프락시 설정: WPAD
- 브라우저 설정을 위한 웹 프락시 자동발견 프로토콜 (WPAD)
- WPAD 프로토콜이 구현된 클라이언트가 하는일은 다음과 같다.

1. PAC URI를 찾기위해 WPAD를 사용한다.
2. URI에서 PAC 파일을 가져온다.
3. 프락시 서버를 알아내기 위해 PAC 파일을 실행한다.
4. 알아낸 프락시 서버를 이용해서 요청을 처리한다.

#### 6.5 프락시 요청의 미묘한 특징들
1. 프락시 요청의 URI는 서버 요청과 어떻게 다른가
2. 인터셉트 프락시와 리버스 프락시는 어떻게 서버 호스트 정보를 알아내기 어렵게 만드는가
3. URI 수정에 대한 규칙
4. 프락시는 브라우저의 똑똑한 URI 자동완성이나 호스트 명 확장기능에 어떻게 영향을 주는가

##### 6.5.1 프락시 URI는 서버 URI와 다르다.
- 웹 서버와 웹 프락시 메시지의 문법은 서로 같지만 클라이언트가 프락시 대신 서버로 요청을 보내면 요청 URI가 달라진다.

`클라이언트가 웹 서버로 요청을 보낼 때`
```
GET /index.html HTTP/1.0
User-Agent: ...
```

`클라이언트가 프락시로 요청을 보낼 떄`
```
GET https://www.naver.com/index.html HTTP/1.0
User-Agent: ...
```

> 클라이언트가 프락시로 요청을 보낼때 다음과 같이 완전한 URI를 가진다.

###### 서버와 프락시가 다른 요청 형식을 가지는 이유
- 기존 HTTP 설계에서는 클라이언트는 서버와 직접 대화를 했다.
- 단일 서버는 자신의 호스트명과 포트번호를 알고 있기 때문에 클라이언트는 불필요한 전송 정보를 제거하고 URI를 보냈다.
- 프락시는 목적지 서버와 커넥션을 맺어야 하기 때문에 해당 서버의 이름을 알아야한다.
- 프락시 기반 게이트웨이는 다른 스킴과 연결하기 위해 URI의 스킴도 필요했다.

> 클라이언트가 프락시를 사용하지 않는다면 부분 URI를, 프락시를 사용한다면 완전한 URI를 보낸다.

##### 6.5.2 가상 호스팅에 일어나는 같은 문제
- 가상 호스팅되는 웹 서버는 여러 사이트가 같은 물리적 웹서버를 공유한다.
- 프락시와 비슷한 문제를 가짐에도 불구하고 서로 다른 방법으로 해결되었다.

1. 명시적 프락시는 요청 메시지가 완전한 URI를 가지게 한다.
2. 가상으로 호스팅되는 웹 서버는 호스트와 포트에 대한 정보를 가지는 Host 헤더를 요구한다.

##### 6.5.3 인터셉트 프락시는 부분 URI를 받는다.
- 클라이언트는 프락시와 대화중인것을 항상 알고 있는것이 아니다.
- 클라이언트가 프락시를 사용하지 않더라도, 대리 프락시나 인터셉트 프락시를 지날 수 있다.

##### 6.5.4 프락시는 프락시 요청과 서버 요청을 모두 다룰 수 있다.
- 다목적 프락시 서버는 요청 메시지의 완전한 URI, 부분 URI를 모두 지원해야 한다.

`완전한 URI와 부분 URI를 사용하는 규칙`
1. 완전한 URI가 주어 졌다면 프락시는 그것을 사용해야 한다.
2. 부분 URI가 주어지고, Host 헤더가 있다면 Host헤더를 이용해 원 서버의 이름과 포트를 알아내야 한다.
3. 부분 URI가 주어졌고, Host 헤더가 없다면 다음의 방법으로 원 서버를 알아내야 한다.
    1. 프락시가 원 서버를 대신하는 대리 프락시라면, 프락시에 실제 서버 주소와 포트번호가 설정되었을 수 있다.
    2. 이전에 어떤 언테섭트 프락시가 가로챘던 트래픽을 받았고, 인터셉트 프락시가 원 IP주소와 포트번호를 설정할 수
    있게 되어있따면 해당 주소와 포트를 사용할 수 있다.
    3. 모두 실패 했다면, 반드시 에러 메시지를 반환해야 한다.
    
##### 6.5.5 전송중 URI 변경
- 프락시 서버는 요청 URI의 변경에 매우 신경을 써야한다.
- 사소한 URI 변경이라도 다운스트림 서버와 상호운용성 문제를 일으킬 수 있다.

> HTTP 명세는 일반적인 인터셉트 프락시가 URI를 전달할 때 절대 경로를 고쳐쓰는것을 금지하며 빈 경로를 '/' 로 대체하는것만 허용한다.

##### 6.5.6 URI 클라이언트 자동확장과 호스트 명 분석
- 브라우저는 프록시의 존재 여부에 따라 요청 URI를 다르게 분석한다.

##### 6.5.7 프락시 없는 URI 분석
- 브라우저는 호스트명이 발견될 때 까지 다양한 호스트명의 가능성을 찾는다.
- 호스트를 찾았다면 대응하는 IP주소를 찾아 연결을 시도한다.

##### 6.5.8 명시적인 프락시 사용시 URI 분석
- 브라우저는 편리한 확장기능중 어느것도 수행할 수 없다.
    - 브라우저의 URI가 프락시를 지나쳐버리기 떄문

##### 6.5.9 인터셉트 프락시를 이용한 URI 분석
- 인터셉트 프락시와 함께라면, 클라이언트는 성공적으로 웹 서버와 대화했다고 믿지만, 웹 서버는 죽어있을 수도 있다.

#### 6.6 메시지 추적
- 프락시가 점점 더 흔해지면서 프락시를 넘나드는 메세지의 흐름을 추적하고 문제점을 찾아내는것도 중요한 일이 되었다.

##### 6.6.1 Via 헤더
- Via헤더 필드는 메시지가 지나는 각 중간 노드(프락시 또는 게이트웨이)의 정보를 나열한다.
- 메시지가 노드를 지날때 마다 Via 목록의 끝에 반드시 추가 되어야 한다.
- Via 헤더 필드는 메시지의 전달을 추적, 메시지 루프를 진단, 요청 전송 및 그에 대한 응답을 돌려주는 과정에서 관여하는 모든
메시지 발송자들의 프로토콜을 확인하기 위해 사용된다.

###### Via 문법
- Via 헤더 필드는 쉼표로 구분된 경유지 (waypoint) 이다.
- 개별의 프락시 서버나 게이트웨이 홉을 나타낸다.
- 각 Via waypoint는 프로토콜 이름, 프로토콜 버전, 노드 이름, 코멘트의 최대 4개의 구성요소를 담을 수 있다.

> Via: proxy-62.irene-isp.net, 1.0 cache.joes-hardware.com

###### Via 요청과 응답경로
- 요청 메시지와 응답 메시지 모두 프락시를 지나므로 둘 모두 Via 헤더를 가진다.
- 요청 메시지가 프락시 A,B,C를 지나간다면, 응답 메시지는 프락시 C,B,A를 지나간다.

> 응답의 Via 헤더는 거의 언제나 요청 Via 헤더와 반대이다.

###### Via와 게이트웨이
- Via 헤더는 프로토콜 변환을 기록하므로 HTTP 애플리케이션은 프락시 연쇄에서 프로토콜 능력과 변환이 있었는지를 알 수 있다.

###### Server 헤더 와 Via 헤더
- Server 응답 헤더 필드는 원서버에 의해 사용되는 소프트웨어를 알려준다.
- 응답 메시지가 프락시를 통과할때 Server 헤더를 수정해서는 안되며, Via 항목을 추가해야한다.

###### Via가 개인정보 보호와 보안에 미치는 영향
- Via 노드 이름 전달이 가능하지 않다면, 프락시는 호스트 명을 그 호스트에 대한 적당한 가명으로 교체 해야 한다.
- 방화벽 뒤의 네트워크 아키텍쳐에 대한 정보가 악의적인 집단에 의해 이용될 수 있다.

##### 6.6.2 TRACE 메서드
- TRACE메서드는 요청 메시지를 프락시의 연쇄를 따라가면서 어떤 프락시를 지나가고, 어떻게 각 프락시가 요청 메시지를 수정하는지
관찰/추적할 수 있도록 해준다.

###### Max-Forwards
- 일반적으로 TRACE 메시지는 중간에 프락시가 몇개나 있던지 신경쓰지 않고 모든 경로를 여행한다.
- 이 때 경유하는 홉의 갯수를 제한하기 위해 Max-Forwards 헤더를 사용할 수 있는데 전달되는 메시지가 무한 루프에 빠지지는 않는지,
프락시 연쇄를 테스트하거나 연쇄 중간의 특정 프락시를 테스트하기에 용이하다. 

#### 6.7 프락시 인증
- 프락시는 접근 제어 장치로 제공될 수 있다.
- 사용자가 유효한 접근 권한자격을 프락시에게 제출하지 않는 이상 콘텐츠에 대한 요청을 차단하는 프락시 인증이라는 메커니즘이 있다.

> 프락시 인증은 인증에 참여하는 프락시가 연쇄상 여러개 있을 경우에는 일반적으로 잘 동작하지 않는다.

#### 6.8 프락시 상호운용성
- 프락시 서버는 서로 다른 프로토콜을 구현했을 수도 있고 골치 아프게 이상한 동작을 할수도 있는 클라이언트와 서버 사이를 중개해야한다.

##### 6.8.1 지원하지 않는 헤더와 메서드 다루기
- 프락시는 이해할수 없는 헤더 필드는 반드시 그대로 전달 해야한다.
- 같은 이름의 헤더 필드가 여러개 존재할 경우 순서도 반드시 유지해야 한다.
- 메서드다 이와 비슷하게 동작을 해야한다.

##### 6.8.2 OPTIONS: 어떤 기능을 지원하는지 알아보기
- HTTP OPTIONS 메서드는 서버나 웹 서버의 특정 리소스가 어떤 기능을 지원하는지 알아볼수 있게 해준다.

##### 6.8.3 Allow 헤더
- Allow 엔티티 헤더는 요청 URI에 의해 식별되는 자원에 대해 지원되는 메서드들이나 서버가 지원하는 모든 메서드를 열거한다.
- Allow 헤더는 새 리소스가 지원했으면 하는 메서드를 추천하기 위해 요청 헤더로 사용될 수 있다.
- 또한 프락시는 Allow 헤더를 수정할 수 없다.

### 7장 캐시
- 웹 캐시는 자주 쓰이는 문서의 사본을 자동으로 보관하는 HTTP 장치이다.

###### 장점
1. 불필요한 데이터 전송을 줄여, 네트워크 요금으로 인한 비용을 줄여준다.
2. 네트워크 병목을 줄여주고, 대역폭을 늘리지 않고도 페이지를 빨리 불러올수 있게 된다.
3. 원 서버에 대한 요청을 줄여주어 서버의 부하를 줄이고 응답속도를 높혀준다.
4. 거리로 인한 지연을 줄여준다.

#### 7.1 불필요한 데이터 전송
- 캐시를 이용하면 첫번째 응답은 캐시에 보관되고, 뒤이은 요청에 대한 응답으로 사용되어 중복되는 트래픽을 줄여준다.

#### 7.2 대역폭 병목
- 가장 빠른 LAN에 있는 캐시로 부터 사본을 가져와, 캐싱은 성능을 대폭 개선할 수 있다.

#### 7.3 갑작스런 요청 쇄도 (Flash Crowds)
- 캐시는 갑작스런 트래픽 급증에 대처하기위해 중요하다.

#### 7.4 거리로 인한 지연
- 모든 네트워크 라우터는 제각각 인터넷 트래픽을 지연시킨다.
- 캐시로 인해 거리로 인한 트래픽 지연을 줄일 수 있다.

#### 7.5 적중과 부적중
- 캐시에 요청이 왔을때 그에 맞는 사본이 있다면 해당 요청을 처리할수 있으며 이를 **캐시 적중(Cache Hit)** 이라고 한다.
- 대응하는 사본이 없다면 원서버로 요청이 전달되며 이를 **캐시 부적중(Cache Miss)** 라고 한다.

##### 7.5.1 재검사 (Revalidation)
- 캐시는 반드시 사본이 여전히 최신인지 서버를 통해 점검을 해야한다. 이를 **HTTP 재검사**라고 한다.
- 대부분의 캐시는 클라이언트가 사본을 요청하고, 해당하는 사본이 충분히 오래된 경우에만 재검사를 한다.

###### 느린 적중
- 캐시는 사본의 재검사가 필요할때 서버에 작은 재검사 요청을 보내고, 서버로부터 유효하다는 응답 (304 Not Modified) 응답을 받게되면
- 해당 사본이 유효하기 때문에 클라이언트에게 응답을 하게된다. 이를 재검사 적중 혹은 느린 적중이라고 한다.

> 느린 적중은 캐시 적중보다는 느리지만, 캐시 부적중보다는 빠르다.
> 캐시된 객체를 확인하기 위해 가장 많이 쓰이는 것은 If-Modified_Since 헤더 이다.

##### 7.5.2 적중률
- 캐시가 요청을 처리하는 비율을 캐시 적중률 혹은 문서 적중률 이라고 한다.
- 보통 적중률 40%라면 웹 캐시로 괜찮은 편이다.

##### 7.5.3 바이트 적중률
- 문서 적중률이 모든것을 말해주지는 않는다.
- 바이트 단위 적중률은 캐시를 통해 제공된 모든 바이트의 비율을 표현한다.

> 문서 적중률과 바이트 단위 적중률은 둘다 캐시 성능에 대한 유용한 지표이다.

##### 7.5.4 적중과 부적중의 구별
- HTTP는 클라이언트에게 응답이 캐시 적중인지, 원서버 로부터 가져온 응답인지 말해줄 수 있는 방법을 제공하지 않는다.
- 한가지 방법은 Date헤더를 이용해 응답의 생성일이 현재보다 오래되었다면 캐시된 것임을 아는방법 뿐이다.

#### 7.6 캐시 토폴로지
- 한 명에게만 할당된 캐시를 개인 전용 캐시 (Privacy Cache)
- 공유된 캐시는 공용 캐시 (Public Cache) 라고 부른다.
- 개인 캐시는 개인만을 위한 캐시이고, 공용 캐시는 사용자 집단에게 자주 쓰이는 캐시이다.

##### 7.6.1 개인 전용 캐시
- 개인 전용 캐시는 많은 에너지나 저장 공간을 필요로하지 않으므로 작고 저렴하다
- 웹 브라우저는 개인 전용 캐시를 내장하고 있다.

##### 7.6.2 공용 프락시 캐시
- 공용 캐시는 캐시 프락시 혹은 프락시 캐시 라고 불리는 공유된 프락시 서버이다.
- 공용 캐시에는 여러 사용자가 접근하기 때문에 불필요한 트래픽을 줄일 수 있다.

##### 7.6.3 프락시 캐시 계층들
- 캐시 계층이 깊다면 요청은 캐시의 긴 연쇄를 따라가게 될 것이다.
- 프락시 연쇄가 깊어질 수록 중간 프락시들은 현저한 성능 저하가 발생할 것이다.

##### 7.6.4 캐시망, 콘텐츠 라우팅, 피어링

`캐시망 내에서 콘텐츠 라우팅을 위해 설계된 캐시들이 하는일`
1. URL에 근거하여, 부모 캐시와 원 서버중 하나를 동적으로 선택한다.
2. URL에 근거하여 특정 부모 캐시를 동적으로 선택한다.
3. 부모 캐시에게 가기 전에, 캐시된 사본을 로컬에서 찾아본다.
4. 다른 캐시들이 그들의 캐시된 콘텐츠에 부분적으로 접근할 수 있도록 허용한되, 그들의 캐시를 통한 인터넷 트랜짓은 허용하지 않는다.

`형제 캐시`
- 한층더 복잡한 캐시 사이의 관계는 서로 다른 조직이 상호간의 이득을 위해 서로 캐시르 연결하여 찾아볼 수 있도록 한다.
- 선택적인 피어링을 지원하는 캐시를 형제캐시라고 한다.

#### 7.7 캐시 처리 단계
1. 요청 받기 - 캐시는 네트워크로부터 도착한 요청 메시지를 읽는다.
2. 파싱 - 캐시는 메시지를 파싱하여 URL과 헤더들을 추출한다.
3. 검색 - 캐시는 로컬 복사본이 있는지 검사하고, 사본이 없다면 사본을 받아온다.
4. 신선도 검사 - 캐시는 캐시된 사본이 충분히 신선한지 검사하고, 신선하지 않다면 변경사항이 있는지 서버에게 물어본다.
5. 응답 생성 - 캐시는 새로운 헤더와 캐시된 본문으로 응답 메시지를 만든다.
6. 발송 - 캐시는 네트워크를 통해 응답을 클라이언트에게 돌려준다.
7. 로깅 - 선택적으로, 캐시는 로그파일에 트랜잭션에 대해 서술한 로그 하나를 남긴다.

##### 7.7.1 단계 1: 요청 받기
- 고성능 캐시는 여러 개의 들어오는 커넥션들로 부터 데이터를 동시에 읽어 들이고 메시지 전체가 도착하기전 트랜잭션 처리를 시작한다.

##### 7.7.2 단계 2: 파싱
- 캐시는 요청 메시지를 여러부분으로 파싱하여 헤더 부분을 조작하기 쉬운 자료 구조에 담는다.

##### 7.7.3 단계 3: 검색
- 캐시는 URL을 알아내고 그에 해당하는 로컬 사본이 있는지 검사한다.
- 캐시된 객체는 객체가 얼마나 오랫동안 캐시에 머물렀는지 알려주는 기록 등에 대한 몇몇 메타데이터를 가지고 있다.

##### 7.7.4 단계 4: 신선도 검사
- 캐시된 객체는 신선도 한계를 넘을 정도로 너무 오래 갖고 있었다면 그 문서를 제공하기 전에 어떤 변경이 있었는지 검사하기 위해 서버와 재검사를 해야한다.

##### 7.7.5 단계 5: 응답 생성
- 캐시된 응답을 서버에서 온것 처럼 보이게 하기 위해 캐시된 서버의 응답 헤더를 토대로 응답 헤더를 생성한다.
- 캐시의 신선도 정보, Via 헤더 등을 포함하며, 캐시가 Date 헤더를 조정해서는 안된다.

##### 7.7.6 단계 6: 전송
- 응답 헤더가 준비되면, 캐시는 응답을 클라이언트에게 돌려준다.

##### 7.7.7 단계 7: 로깅
- 대부분의 캐시는 로그 파일과 캐시 사용에 대한 통계를 유지한다.
- 캐시 적중과 부적중 횟수, 요청 종류, URL 등을 남긴다.
- 가장 많이 쓰이는 캐시 로그 포맷은 스퀴드 로그포맷, 넷스케이프 확장 공용 로그포맷 이다.

#### 7.8 사본을 신선하게 유지하기
- 캐시된 사본 모두가 서버의 문서와 항상 일치하는 것은 아니다.
- 캐시된 데이터는 서버의 데이터와 일치하도록 관리되어야 한다.
- HTTP는 어떤 캐시가 사본을 갖고 있는지 서버가 기억하지 않더라도, 캐시된 사본이 서버와 충분히 일치하도록 유지할 수 있게
해주는 메커니즘을 갖고 있는데, 이를 **문서 만료 와 서버 재검사** 라고한다.

##### 7.8.1 문서 만료
- HTTP는 Cache-Control과 Expires라는 특별한 헤더들을 이용해서 원 서버가 각 문서에 유효기간을 붙일 수 있게 해준다.
- 이 헤더들을 콘텐츠가 얼마나 오랫된 신선한 상태로 보일 수 있는지 좌우한다.

##### 7.8.2 유효기간과 나이
- 서버는 CacheControl: max-age 헤더를 이용해 유효기간을 명시한다.
- Expries와 기본적으로 같은 일을 하지만, 절대 시간은 컴퓨터의 시계가 올바르게 맞춰져 있을 것을 요구한다.

##### 7.8.3 서버 재검사
- 캐시된 문서가 만료되었다는 것은, 원 서버의 문서와 다르다는 것을 의미하는것은 아니며, 이제 검사할 시간이 되었음을 의미한다.
- 캐시가 원 서버에게 문서 변경 여부를 알아보는 것을 '서버 재검사' 라고 한다.

##### 7.8.4 조건부 메서드와의 재검사
- HTTP는 캐시가 서버에게 **조건부 GET** 이라는 요청을 보낼수 있도록 한다.
- 이 요청은 서버가 가지고 있는 문서가 캐시된 것과 다른 경우에만 객체 본문을 보내달라고 하는 것이다.
- 조건부 GET은 GET 요청 메시지에 특별한 조건부 헤더를 추가함으로 써 시작 된다.

##### 7.8.5 IF-Modified-Since: 날짜 재검사
- 가장 흔히 쓰이는 캐시 재검사 헤더는 If-Modified-Since 이다.
- 흔히 IMS 요청으로 불리며, 이는 서버에게 리소스가 특정 날짜 이후로 변경된 경우에만 요청한 본문을 보내달라고 한다.

##### 7.8.6 If-None-Match: 엔티티 태그 재검사
- 최근 변경 일시 기반 재검사가 행해지기 어려운 검사가 몇가지가 있다.
- 내용에는 아무런 변화가 없지만 변경시각은 바뀌는 경우, 1초보다 작은 간격으로 갱신되는 문서를 제공하는 경우 등..
- 이런 경우 엔티티 태그를 활용한 검사를 한다.
- 퍼블리셔가 문서를 변경 했을때, 문서의 엔티티 태그를 새로운 버전으로 표현할 수 있다.
- 엔티티 태그가 변경되었디만 캐시는 새로운 문서를 캐싱하기 위해 If-None-Match 조건부 헤더를 사용할 수 있다.

##### 7.8.7 약한 검사기와 강한 검사기
- 캐시는 캐시된 버전이 최신인지 확인하기 위해 엔티티 태그를 사용한다.
- 강한 검사기는 콘텐츠가 수정될때 마다 변경된다.
- 약한 검사기는 어느정도 콘텐츠 변경을 허용하되, 중요한 의미가 변경되면 함께 변경 된다.
- 서버는 W/ 접두사로 약한 검사기를 구분한다.

> 강한 엔티티 태그는 값이 바뀔때마다 매번 반드시 같이 바뀌지만, 약한 엔티티 태그는 유의미한 변경이 있을때 마다 같이 변경되어야 한다.

##### 7.8.8 언제 엔티티 태그를 사용하고, 언제 Last-Modified 일시를 사용하는가 ?
- HTTP/1.1 클라이언트는 만약 서버가 엔티티 태그를 반환 했다면, 반드시 엔티티 태그 검사기를 사용해야 한다.
- 서버가 Last-Modified 값만 반환했다면 If-Modified-Since 검사를 사용할 수 있다.

#### 7.9 캐시 제어
1. Cache-Control: no-store
2. Cache-Control: no-cache
3. Cache-Control: must-revalidate
4. Cache-Control: max-age
5. Expires
6. 아무런 정보도 주지않고 캐시가 스스로 휴리스틱한 방법으로 결정하게 한다.

##### 7.9.1 no-cache와 no-store 응답 헤더
- no-store와 no-cache 헤더는 캐시가 검증되지 않은 캐시된 객체로 응답하는 것을 막는다.
- no-store 헤더는 캐시가 해당 응답의 사본을 막는 것을 금지한다.
- no-cache 는 로컬 저장소에 저장될 수 있지만, 먼저 서버와 재검사를 하지 않고서는 클라이언트로 제공할 수 없다.

##### 7.9.2 Max-Age 응답 헤더
- Cache-Control: max-age 헤더는 해당 문서가 서버로 부터 온 이후로 흐른 시간이며, 초로 나타낸다.

##### 7.9.3 Expires 응답 헤더
- 더이상 사용하지 않기를 권하는 헤더이다.
- 초 단위의 시간 대신 실제 만료 날짜를 명시한다.

> 몇몇 서버는 문서를 항상 만료되도록 하기위해 Expires: 0 헤더를 사용하지만 이는 문법 위반이며 몇몇 소프트웨어와 문제를 일으킬 수 있다.

##### 7.9.4 Must-Revalidate 응답 헤더
- Cache-Control: must-revalidate 헤더는  원 서버와 최초의 재검사 없이는 제공해서는 안됨을 의미한다.
- 캐시가 만료 정보를 엄격하기 따르길 윈할 경우 사용한다.

##### 7.9.5 휴리스틱 만료
- 응답이 max-age, Expires 중 어느것도 포함하고 있지 않다면 경험적인 방법으로 최대나이를 계싼한다.
- 어떤 알고리즘이나 사용될 수 있지만 최대 값이 24시간 보다 크다면 Heuristic Expiration 경고를 포함해야 한다.

##### 7.9.6 클라이언트 신선도 제약
- 웹 브라우저는 콘텐츠를 강제로 갱신시켜주는 리프레시나 리로드를 지원한다.
- Cache-control 요청헤더가 추가된 GET 요청을 발생시켜, 강제로 재검사하거나 서버로 부터 콘텐츠를 무조건 가져온다.

#### 7.10 캐시 제어 설정
- 웹 서버들은 캐시 제어와 만료 HTTP 헤더들을 설정하는 서로 다른 메커니즘을 제공한다.

##### 7.10.1 아파치로 HTTP 헤더 제어하기
`mod_headers`
- 개별 헤더들을 설정할 수 있게 해준다.
- 개별 HTTP 헤더를 설정할 수 있는 지시어를 이용해 아파치 설정 파일에 설정을 추가할 수 있다.

`mod_expires`
- 적절한 만료 날짜가 담긴 Expires 헤더를 자동으로 생성하는 프로그램 로직을 제공한다.

`mod_cern_meta`
- HTTP 헤더들의 파일을 특정 객체와 연결시켜 준다.

##### 7.10.2 HTTP-EQUIV을 통한 HTML 캐시 제어
- 웹 서버 설정 파일과 상호작용 없이도 쉽게 HTML 문서에 HTTP 헤더 정보를 부여할수 있게 하기위해
- HTML2.0은 META-HTTP-EQUIV 태그를 정의 했다.
- 하지만 이 기능을 지원하는 웹서버나 프락시는 거의 없다.
> 서버의 부하를 가중시키며, 설정값이 정적이고, HTML을 제외한 다른 타입의 파일은 지원하기 때문이다.

### 8장 통합점: 게이트웨이, 터널, 릴레이
- 게이트웨이: 서로 다른 프로토콜과 애플리케이션 간의 HTTP 인터페이스
- 애플리케이션 인터페이스: 서로 다른 형식의 웹 애플리케이션이 통신하는 데 사용
- 터널: HTTP 커넥션을 통해서 HTTP가 아닌 트래픽을 전송하는데 사용
- 릴레이: 일종의 단순한 HTTP 프락시로, 한 번에 한 개의 홉에 데이터를 전달하는데 사용한다. 

#### 8.1 게이트웨이
- 게이트웨이는 리소스와 애플리케이션을 연결하는 역할을 한다.
- 게이트웨이는 HTTP 트래픽을 다른 프로토콜로 자동으로 변환하여, HTTP 클라이언트가 다른 프로토콜을 알 필요 없이 서버에 접속할 수 있게 하기도 한다.

##### 8.1.1 클라이언트 측 게이트웨이와 서버 측 게이트웨이
- 웹 게이트웨이는 한쪽은 HTTP, 다른 한쪽은 다른 프로토콜로 통신한다.
- 클라이언트 측 프로토콜과 서버 측 프로토콜을 빗금(/)으로 구분해 기술한다.

> <클라이언트 프로토콜>/<서버 프로토콜>

#### 8.2 프로토콜 게이트웨이
- 프락시에 트래픽을 바로 보내듯이 게이트웨이에도 HTTP 트래픽을 바로 보낼 수 있다.
- 브라우저에 명시적으로 게이트웨이를 설정하여 자연스럽게 트래픽이 게이트웨이를 향하게 하거나, 게이트웨이를 리버스 프락시로 설정할 수도 있다.

##### 8.2.1 HTTP/*: 서버 측 웹 게이트웨이
- 서버 측 웹 게이트웨이는 클라이언트로부터 HTTP 요청이 원 서버 영역으로 들어오는 시점에 클라이언트 측의 HTTP 요청을 외래 프로토콜로 전환한다.

##### 8.2.2 HTTP/HTTPS: 서버측 보안 게이트웨이
- 모든 웹 요청을 암호화함으로써 개인 정보 보호와 보안을 제공하는 게이트웨이를 사용할 수 있다.

##### 8.2.3 HTTPS/HTTP: 클라이언트 측 보안 가속 게이트웨이
- HTTPS/HTTP 게이트웨이는 웹 서버의 앞단에 위치하고, 보이지 않는 인터셉트 게이트웨이나 리버스 프락시 역할을 한다.

#### 8.3 리소스 게이트웨이
- 게이트웨이의 가장 일반적인 형태인 애플리케이션 서버는 목적지 서버와 게이트웨이를 한 개의 서버로 결합한다.
- 애플리케이션 게이트웨이에서 유명했던 최초의 API는 CGI(Common Gateway Interface) 였다.
- CGI는 특정 URL에 대한 HTTP 요청에 따라 프로그램을 실행하고, 프로그램의 출력을 수집하여 HTTP응답으로 회신하는데 
웹 서버가 사용하는 표준화된 인터페이스 집합이다.

##### 8.3.1 공용 게이트웨이 인터페이스
- CGI는 최초의 서버 확장이자 지금까지도 가장 널리 쓰이는 서버 확장이다.
- 웹에서 동적인 HTML, 신용카드 처리, 데이터베이스 질의 등을 제공하는데 사용한다.

##### 8.3.2 서버 확장 API
- 서버 개발자는 웹 개발자가 자신의 모듈을 HTTP와 직접 연결할 수 있는 강력한 인터페이스인 서버 확장 API를 제공하였다.
- 프로그래머가 자신의 코드를 서버에 연결하거나 서버의 컴포넌트를 자신이 만든 것으로 교체해버릴 수 있게 하였다.  

#### 8.4 애플리케이션 인터페이스와 웹 서비스
- 각 웹 애플리케이션이 서로 통신하는데 사용할 표준과 프로토콜 집합을 개발하였다.
- 웹 서비스는 HTTP 같은 표준 웹 기술 위에서 개발한다.
- 웹 서비스는 SOAP를 통해 XML을 사용하여 정보를 교환한다.

#### 8.5 터널
- 웹 터널은 HTTP 프로토콜을 지원하지 않는 애플리케이션에 HTTP 애플리케이션을 사용해 접근하는 방법을 제공한다.
- HTTP 커넥션을 통해 HTTP가 아닌 트래픽을 전송할 수 있고, 다른 프로토콜을 HTTP 위에 얹일 수 있다.

##### 8.5.1 CONNECT로 HTTP 터널 커넥션 맺기
- 웹 터널은 HTTP의 CONNECT 메서드를 사용해 커넥션을 맺는다.
- 터널 게이트웨이가 임의의 목적 서버와 포트에 TCP 커넥션을 맺고 클라이언트와 서버 간에 오는 데이터를 무조건 전달하기를 요청한다.

##### 8.5.2 데이터 터널링, 시간, 커넥션 관리
- 터널을 통해 전달되는 데이터는 게이트웨이를 통해 볼 수 없다.
- 클라이언트는 성능을 높히기 위해 CONNECT 요청을 보낸뒤, 응답을 받기 전에 터널 데이터를 전송할 수 있다.

##### 8.5.3 SSL 터널링
- 웹 터널은 원래 방화벽을 통해 암호화된 SSL 트래픽을 전달하려고 개발되었다.
- 터널을 사용하면 SSL 트래픽을 HTTP 커넥션으로 전송하여 80포트의 HTTP만을 허용하는 방화벽을 통과시킬 수 있다.

##### 8.5.4 SSL 터널링 vs HTTP/HTTPS 게이트웨이
- HTTPS 프로토콜은 다른 프로토콜과 같은 방식으로 게이트웨이를 통과할 수 있다.
- 원격 HTTPS 서버와 SSL 세션을 시작하는 게이트웨이를 두고 클라이언트 측의 HTTPS 트랜잭션을 수행하는 방식이다.

##### 8.5.5 터널 인증
- 프락시 인증 기능은, 클라이언트가 터널을 사용할 수 있는 권한을 검사하는 용도로 터널에서 사용할 수 있다.

##### 8.5.6 터널 보안에 대한 고려사항들
- 터널 게이트웨이는 통신하고 있는 프로토콜이 터널을 올바른 용도로 사용중인지 검증할 방법이 없다.
- 터널 오용을 최소화 하기 위해, 게이트웨이는 HTTPS 전용 포트인 443 같이 특정 포트만 터널링 할 수 있게 허용해야한다.

#### 8.6 릴레이
- HTTP 릴레이는 HTTP 명세를 완전히 준수하지 않는 간단한 HTTP 프락시다.
- 릴레이는 커넥션을 맺기 위한 HTTP 통신을 한 다음, 바이트를 맹목적으로 전달한다.

### 9장 웹 로봇
- 웹 로봇은 사람과의 상호작용 없이 연속된 웹 트랜잭션들을 자동으로 수행하는 소프트웨어 프로그램이다.
- 이런 로봇들은 자동적으로 웹 사이트들을 탐색하며, 방식에 따라 크롤러, 스파이드, 웜, 봇 등 각양각색의 이름으로 불린다.

#### 9.1 크롤러와 크롤링
- 웹 크롤러는 웹 페이지 하나를 가져오고, 그 다음 해당 페이지가 가리키는 모든 웹페이지를 가져오고 또 ... 이런 일을 재귀적으로
반복하는 방식으로 동작하는 로봇이다.
- 웹 링크를 재귀적으로 따라가는 로봇을 크롤러 혹은 스파이더라고 부른다.

##### 9.1.1 어디에서 시작하는가: '루트집합'
- 크롤러는 먼저 출발지점을 지정햊 ㅜ어야한다.
- 크롤러가 방문을 시작하는 URL들의 초기 집합은 루트 집합이라고 불린다.
- 일반적으로 좋은 루트집합은 크고 인기있는 웹사이트, 새로생성된 페이지들의 목록 등으로 구성되어 있다.

##### 9.1.2 링크 추출과 상대 링크 정상화
- 크롤러들은 간단한 HTML 파싱을 해서 이들 링크들을 추출하고 상대 링크를 절대 링크로 변환할 필요가 있다.

##### 9.1.3 순환 피하기
- 웹을 크롤링할 때 루프나 순환에 빠지지 않도록 매우 조심해야 한다.
- 순환을 피하기 위해서는 반드시 그들이 어디를 방문했는지 알아야 한다.

##### 9.1.4 루프와 중복
- 순환이 크롤러에게 해로운 세가지 이유

1. 순환은 크롤러를 루프에 빠뜨려 꼼짝 못하게 만들 수 있다.
2. 크롤러가 같은 페이지를 반복해서 가져오면 고스란히 웹 서버의 부담이 된다.
3. 루프 자체가 문제가 되지 않더라도, 크롤러는 많은 수의 중복된 페이지를 가지고 오게 된다.

##### 9.1.5 빵 부스러기의 흔적
- 방문한 곳을 지속적으로 추적하는 것은 쉽지 않다.
- 대규모 웹 크롤러가 방문한 곳을 관리하기 위해 사용하는 기법은 다음과 같다.

1. 트리와 해시 테이블
2. 느슨한 존재 비트맵
3. 체크포인트
4. 파티셔닝

##### 9.1.6 별칭과 로봇 순환
- 올바른 자료 구조를 갖추었더라도 URL이 별칭을 가지는 이상 어떤 페이지를 이전에 방문했는지 판단하기 쉽지 않을때가 있다.

##### 9.1.7 URL 정규화 하기
- 대부분의 웹 로봇은 URL들을 표준 형식으로 정규화 함으로써 다른 URL과 같은 리소스를 가리키고 있음이 확실한 것들을 미리 제거한다.
- 기본적인 문법의 별칭을 제거할 수 있지만, 모든 URL에 대응할 수 있는것은 아니다.

##### 9.1.8 파일 시스템 링크 순환
- 파일 시스템의 심벌링 링크는 아무것도 존재하지 않으면서 끝없이 깊어지는 디렉터리 계층을 만들 수 있기 때문에, 매우 교묘한 종류의 순환을 유발할 수 있다.

##### 9.1.9 동적 가상 웹 공간
- 악의적인 웹 마스터들이 로봇들을 함정으로 빠뜨리기 위해 의도적인 복잡한 크롤러 루프를 만드는 일도 있다.
- 반면에 더 흔하게 일어날수 있는 일은 나쁜뜻이 없음에도 자신도 모르게 심벌릭 링크나 동적 콘텐츠를 통한 크롤러 함정을 만드는 것이다.

##### 9.1.10 루프와 중복 피하기
1. URL 정규화
    - URL을 표준 형태로 변환함으로써, 같은 리소스를 가리키는 중복된 URL이 생기는 것을 일부 회피한다.
2. 너비 우선 크롤링
    - 크롤러들이 웹 사이트들 전체에 걸쳐 너비 우선 스케줄링을 하면 순환의 영향을 최소화 할 수 있다.
3. 스로틀링
    - 일정 시간 동안 가져올 수 있는 페이지의 숫자를 제한함으로써 한 서버에 대한 접근 횟수와 중복 횟수를 제한할 수 있다.
4. URL 크기 제한
    - 순환으로 인해 계속해서 URL이 길어진다면 길이 제한으로 인해 순환이 중단된다.
5. URL/사이트 블랙리스트
    - 로봇 순환을 만들어 내거나 함정인 것으로 알려진 사이트와 URL 목록을 만들어 관리하고 그들을 피하도록 한다.
6. 패턴 발견
    - 로봇은 반복되는 구성요소를 갖고 있는 URL을 크롤링하는 것을 거절한다.
7. 콘텐츠 지문
    - 콘텐츠 지문을 사용하는 로봇들은 페이지의 콘텐츠에서 몇 바이트를 얻어내어 체크섬을 계산한다.
    - 체크섬을 이용해 동일한 체크섬을 가진 페이지를 가져올 경우 해당 페이지 링크는 크롤링 하지 않는다.
8. 사람의 모니터링
    - 로봇은 결국 자신에게 적용된 어떤 기법으로도 해결할 수 없는 문제에 봉착하게 된다.
    - 뭔가 특이한 일이 일어나면 즉각 인지할 수 있게끔 반드시 진단과 로깅을 포함하도록 설계되어야 한다.
    
#### 9.2 로봇의 HTTP
- 로봇또한 HTTP 명세의 규칙을 지켜야 한다.

##### 9.2.1 요청 헤더 식별하기
- 로봇 개발자들이 구현을 하도록 권장되는 기본적인 신원 식별 헤더들은 다음과 같다.

1. User-Agent
    - 서버에게 요청을 만든 로봇의 이름을 말해준다.
2. From
    - 로봇의 사용자/관리자의 이메일 주소를 제공한다.
3. Accept
    - 서버에게 어떤 미디어 타입을 보내도 되는지 말해준다.
4. Referer
    - 현재의 요청 URL을 포함한 문서의 URL을 제공한다.
    
##### 9.2.2 가상 호스팅
- 로봇 구현자들은 Host 헤더를 지원할 필요가 있다.
- 요청에 Host 헤더를 포함하지 않으면 로봇이 어떤 URL에 대한 잘못된 콘텐츠를 찾게 만든다.

##### 9.2.3 조건부 요청
- 로봇 중의 몇몇은 시간이나 엔티티 태그를 비교함으로써 그들이 받아간 마지막 버전 이후에 업데이트가 된 것인지 확인하는
조건부 HTTP 요청을 구현한다.

##### 9.2.4 응답 다루기
- 로봇들의 주 관심사는 단순히 GET 메서드로 콘텐츠를 요청해서 가져오는 것이기 때문에 응답 다루기라고 부를만한 일은 거의 하지 않는다.
- 웹 서버와의 상호작용을 더 잘해보려고 하는 로봇들은 여러 종류의 HTTP 응답을 다를 필요가 있다.

##### 9.2.5 User-Agent 타기팅
- 웹 관리자들은 로봇의 요청을 다루기 위한 전략을 세워야 한다.
- 최소한 로봇이 그들의 사이트에 방문 했다가 콘텐츠를 얻지 못하는 일이 없도록 대비해야 한다.

#### 9.3 부적절하게 동작하는 로봇들
- 로봇들이 저지르는 실수 몇 가지와 그로 인해 초래되는 결과는 다음과 같다.

###### 폭주하는 로봇
- 로봇은 사람보다 훨씬 빠르게 HTTP 요청을 만들 수 있다.
- 만약 로봇이 에러를 가지고 있거나, 순환에 빠질경우 웹 서버에 극심한 부하를 안겨줄 수 있다.

###### 오래된 URL
- 오래된 URL로 인해 로봇들이 존재하지 않는 문서에 대한 접근 요청으로 에러 로그 및 에러 페이지 제공을 위한 웹서버에 부하가 생긴다.

###### 길고 잘못된 URL
- 로봇은 웹 사이트에게 크고 의미 없는 URL을 요청할 수 있다.
- 이는 웹 서버의 접근 로그를 어지럽게 채우고, 고장을 일으킬 수도 있다.

###### 호기심이 지나친 로봇
- 사적인 데이터에 대한 URL을 얻어 그 데이터를 검색엔진등을 통해 쉽게 접근하도록 만들 수도 있다.

###### 동적 게이트웨이 접근
- 로봇들이 그들이 접근하고 있는 것에 대해 잘 알고 있는것은 아니다.
- 게이트웨이 애플리케이션의 콘텐츠에 대한 URL로 요청을 할수도 있다. 
   
#### 9.4 로봇 차단하기
- 웹 마스터에게 로봇의 동작을 제어할수 있는 표준 기법이 제안되었다. "Robots Exclusion Standard" 로 이름이 지어졌지만, 로봇의 접근을
제어하는 파일의 이름을 따서 종종 robots.txt 라고 불린다.
- robots.txt의 아이디어는 단순하다. 문서 루트에 robots.txt 파일을 제공하고 접근 가능 권한을 명시한다.

##### 9.4.1 로봇 차단 표준
- 로봇 차단 표준은 임시방편으로 마련된 표준이다.
- 대부분의 로봇들은 v0.0이나 v1.0 표준을 채택했다.

##### 9.4.2 웹 사이트와 robots.txt 파일들
- 웹 사이트에 방문하기 전 robots.txt 파일이 존재한다면 로봇은 해당 파일을 반드시 가져와서 처리해야한다.

##### 9.4.3 robots.txt 파일 포맷
- robots.txt 파일은 매우 단순한 줄 기반 문법을 갖는다.
- 각 줄은 빈줄, 주석줄, 규칙줄의 세가지 종류가 있다.

###### User-Agent 줄
- 각 로봇의 레코드는 하나이상의 User-Agent줄로 시작한다.
> User-Agent: <robot-name>

###### Disallow 줄과 Allow 줄들
- Disallow와 allow 줄은 로봇 차단 레코드의 User-Agent 줄들 바로 다음에 온다.
- 이 줄은 특정 로봇에 대해 어떤 URL 경로가 명시적으로 금지되어 있고 명시적으로 허용되는지 기술한다.

##### 9.4.4 그 외에 알아둘 점
- robots.txt 파일은 명세가 발전함에 따라 User-Agent, Disallow, Allow외 다른 필드를 포함할 수 있다. 로봇은 자신이 이해하지 못하는 필드들은 무시해야한다.
- 주석은 파일 어디에서든 허용된다.
- 로봇 차단 표준버전 0.0은 Allow 줄을 지원하지 않았다.

##### 9.4.5 robots.txt의 캐싱과 만료
- 로봇은 주기적으로 robots.txt파일을 가져와서 그 결과를 캐시해야한다.

##### 9.4.6 로봇 차단 펄 코드
- robots.txt 파일과 상호작용하는 공개된 펄 라이브러리가 몇가지 존재한다.
- 한가지는 CPAN 공개 펄 아카이브의 WWW:RobustRules 모듈이다.

##### 9.4.7 HTML 로봇제어 META 태그
- 로봇 차단 태그는 HTML META 태그를 이용해 제공된다.

1. NOINDEX: 로봇에게 이 페이지를 처리하지말고 무시하라고 말해준다.
2. NOFOLLOW: 이 페이지가 링크한 페이지를 크롤링하지 말라고 말해준다.
3. INDEX: 이 페이지의 콘텐츠를 인덱싱해도 된다고 말해준다.
4. FOLLOW: 이 페이지가 링크한 페이지를 크롤링 해도 된다고 말해준다.
5. NOARCHIVE: 이 페이지의 캐시를 위한 로컬 사본을 만들어서는 안 된다고 말해준다.
6. ALL: INDEX, FOLLOW 와 같다.
7. NONE: NOINDEX, NOFOLLOW와 같다. 

#### 9.5 로봇 에티켓
- 1993년, 웹 로봇 커뮤니티의 개척자인 마틴 코스터는 웹 로봇을 만드는 사람들을 위한 가이드라인 목록을 작성했다.
- 대다수는 아직도 유용하다.

#### 9.6 검색엔진
- 웹 로봇을 가장 광범위하게 사용하는 것은 검색엔진이다.

##### 9.6.1 넓게 생각하라
- 검색 엔진들은 사용자들이 웹상에서 문서의 위치를 알아내는 것을 돕는 상대적으로 단순한 데이터베이스 였다.

##### 9.6.2 현대적인 검색엔진의 아키텍쳐
- 오늘날 검색엔진들은 풀텍스트 색인 이라고하는 복잡한 로컬 데이터베이스를 생성한다.
- 이 색인은 웹 모든 문서에 대한 일종의 카드 카탈로그처럼 동작한다.

##### 9.6.3 풀 텍스트 색인
- 풀 텍스트 색인은 단어 하나를 입력받아 그 단어를 포함하고 있는 문서를 즉각 알려줄 수 있는 데이터베이스다.

### 10장 HTTP/2.0

#### 10.1 HTTP/2.0의 등장 배경
- HTTP/1.1의 메시지 포맷은 구현의 단순성과 접근성에 주안을 두고 최적화 되었다보니 성능은 어느정도 희생시키지 않을수 없었다.
- 커넥션 하나를 통해 요청 하나당 응답 하나만을 받는 메시지 교환방식은 심각한 회전 지연을 피할수 없었다.
- 이 문제를 피하기 위해 병렬 커넥션이나 파이프라인 커넥션이 도입되었지만 성능 개선에 대한 근본적인 해결책은 되지 못했다.

#### 10.2 개요
- HTTP/2.0 요청과 응답은 길이가 정의된 (최대 16383바이트) 한 개 이상의 프레임에 담긴다. HTTP 헤더는 압축되어 담긴다.
- 프레임에 담긴 요청과 응답은 스트림을 통해 보내지며, 한 개의 스트림이 한쌍의 요청과 응답을 처리한다.
- 하나의 커넥션 위에 여러개의 동시에 만들어질 수 있다.

#### 10.3 HTTP/1.1과의 차이

##### 10.3.1 프레임
- HTTP/2.0에서 모든 메시지는 프레임에 담겨 전송된다.
- 모든 프레임은 8바이트의 헤더로 시작하며 뒤이어 최대 16383바이트 크기의 페이로드가 온다.

##### 10.3.2 스트림과 멀티플렉싱
- 스트림은 HTTP/2.0 커넥션을 통해 클라이언트와 서버 사이에서 교환되는 프레임들의 독립된 양방향 시퀀스이다.
- 한 쌍의 요청과 응답은 하나의 스트림을 통해 이루어지며, 응답을 받고나면 스트림이 닫히게 된다.

##### 10.3.3 헤더 압축
- HTTP/2.0에서는 HTTP 메세지의 헤더를 압축하여 전송한다.
- HPACK 명세에 정의된 헤더 압축 방법으로 압축된 뒤 '헤더 블록 조각'들로 쪼개져서 전송된다.
- 받는 쪽에서는 이 조각들을 이은 뒤 압축으 풀어 원레의 헤더 집합으로 복원한다.

##### 10.3.4 서버 푸시
- HTTP/2.0은 서버가 하나의 요청에 대해 응답으로 여러 개의 리소스를 보낼 수 있도록 해준다.
- 리소스를 푸시하려는 서버는 클라이언트에게 먼저 자원을 푸시할것이라고 알려주어야한다.
- 이때 PUSH_PROMISE 프레임을 보내어 미리 알려준다.
- 클라이언트가 해당 프레임을 받게 되면, 프레임 스트림은 클라이언트 입장에서 예약 상태가 된다.
- 이 상태에서 클라이언트는 RST_STREAM 프레임을 보내어 푸시를 거절할 수 있고 스트림은 즉각 닫히게 된다.

#### 10.4 알려진 보안 이슈

##### 10.4.1 중개자 캡슐화 공격 (Intermediary Encapsulation Attacks)
- HTTP/2.0 메시지를 중간의 프락시가 HTTP/1.1 메시지로 변환할때 메시지 의미가 변질될 가능성이 있다.

##### 10.4.2 긴 커넥션 유지로 인한 개인정보 누출 우려
- HTTP/2.0은 사용자가 요청을 보낼떄 회전 지연을 줄이기 위해 클라이언트와 서버 사이의 커넥션을 오래 유지하는것을 염두하고 있따.
- 이것은 개인정보 유출에 악용될 가능성이 있다.

## 3부 식별, 인가, 보안

### 11장 클라이언트 식별과 쿠키

#### 11.1 개별 접촉
- HTTP는 stateless 하다.
- 웹 서버는 요청을 보낸 사용자를 식별하거나 방문자가 보낸 연속적인 요청을 추적하기 위해 약간의 정보를 이용할 수 있다.

#### 11.2 HTTP 헤더
- 사용자에 대한 정보를 전달하는 가장 일반적인 일곱가지 HTTP 요청 헤더가 있다.

| 헤더 이름 | 헤더 타입 | 설명 |
|---|---|---|
| From | 요청 | 사용자의 이메일 주소 |
| User-Agent | 요청 | 사용자의 브라우저 |
| Referer | 요청 | 사용자의 현재 링크를 타고 온 근원 페이지 |
| Authorizaiton | 요청 | 사용자 이름과 비밀번호 |
| Client-ip | 확장(요청) | 클라이언트의 IP 주소 |
| X-Forwarded-For | 확장(요청) | 클라이언트의 IP 주소 |
| Cookie | 확장(요청) | 서버가 생성한 ID 라벨 |

#### 11.3 클라이언트 IP 주소
- 웹 선구자들은 사용자 식별에 클라이언트 IP주소를 사용하려고 했다.
- 하지만 IP 주소로 식별하는 방식은 다음과 같은 약점을 가지고 있다.

1. IP는 사용자가 아닌 컴퓨터를 가리킨다, 만약 여러 사용자가 동일한 컴퓨터를 사용한다면 식별할수가 없다.
2. ISP는 사용자가 로그인하면 동적으로 IP주소를 할당하기 때문에 매번 다른 주소를 받으므로 IP주소로 식별할수가 없다.
3. 많은 사용자가 네트워크 주소 변환 (NAT) 방화벽을 통해 인터넷을 사용한다. 실제 IP주소를 방화벽 뒤로 숨기고, 하나의 방화벽 IP주소를 사용한다.
4. HTTP 프락시와 게이트웨이는 원 서버에 새로운 TCP연결을 한다. 웹 서버는 클라이언트의 IP주소 대신 프락시 서버의 IP주소를 본다.
 
#### 11.4 사용자 로그인
- IP 주소로 사용자를 식별하려는 수동적인 방식보다 웹서버는 사용자 이름과 비밀번호로 인증 할 것을 요구해서 사용자에게 명시적으로
식별 요청을 할 수 있다.
- HTTP는 WWW-Authenticate 와 Authorization 헤더를 사용해 웹 사이트에 사용자 이름을 전달하는 자체적인 체계를 가지고 있다.

#### 11.5 뚱뚱한 URL
- 어떤 웹 사이트는 사용자의 URL마다 버전을 기술하여 사용자를 식별하고 추적하였다.
- 아마존이 대표적인 예이다.
- 특정 사용자와 세션에 대한 상태정보를 포함하기 때문에 해당 주소를 공유할경우 본인도 모르게 개인정보를 공유하게 된다.
- 또한 캐시를 사용할 수 없다.

#### 11.6 쿠키
- 쿠키는 사용자를 식별하고 세션을 유지하는 방식 중 현재까지 가장 널리 사용하는 방식이다.

##### 11.6.1 쿠키의 타입
- 쿠키는 크게 세션 쿠키와 지속 쿠키 두가지 타입으로 나눌 수 있다.
- 세션 쿠키는 사용자가 해당 사이트를 탐색할 때 사용하는 임시 쿠키이다. 브라우저를 닫으면 삭제된다.
- 지속 쿠키는 삭제되지 않고 디스크에 저장되기 때문에 브라우저를 닫거나 재부팅을 해도 남아 있다.

##### 11.6.2 쿠키는 어떻게 동작하는가
- 쿠키는 서버가 사용자에게 '안녕? 내이름은 ..' 이라고 적어서 붙이는 스티커와 같다.
- 웹 서버는 사용자가 다시 돌아왔을 때, 해당 사용자를 식별하기 위한 유일 값을 쿠키에 할당한다.

##### 11.6.3 쿠키상자: 클라이언트 측 상태
- 쿠키의 기본적인 발상은 브라우저가 서버 관련 정보를 저장하고, 사용자가 서버에 접근할 때마다 그 정보를 함께 전송하게 하는 것이다.

##### 11.6.4 사이트마다 각기 다른 쿠키들
- 브라우저는 수백 수천 개의 쿠키를 가지고 있을 수 있지만, 브라우저가 쿠키 전부를 모든 사이트에 보내지는 않는다.
- 보통 브라우저는 쿠키를 생성한 서버에게만 쿠키에 담긴 정보를 전달한다.
- 그렇지 않으면 성능이 크게 저하되고, 대부분 특정 서버에 특화된 정보를 가지고 구성되기 때문에 무의미한 값이다.

##### 11.6.5 쿠키 쿠성요소
- 현재 사용되는 쿠키 명세에는 Version 0 쿠키 (넷스케이프 쿠키)와 Version 1 쿠키 (RFC 2965)가 있다.
- Version 1 쿠키는 Version 0 쿠키의 확장으로 널리 쓰이지는 않는다.

##### 11.6.6 Version 0 넷스케이프 쿠키
- 최초의 쿠키 명세는 넷스케이프가 정의 했따.
- Set-Cookie 응답 헤더와 Cookie 요청 헤더와 쿠키를 조작하는 데 필요한 필드들을 정의하였다.

> Set-Cookie: name=value [; expires=date] [; path=path] [; domain=domain] [; secure]
- Set-Cookie 헤더는 쿠키의 이름과 값을 가져야한다. 옵션 속성들에 세미콜론으로 이어 기술한다.

> Cookie: name1=value1 [; name2=value2] ...
- 클라이언트가 서버에 요청을 보낼때, Domain, PAth, Secure 필터들이 현재 요청하려는 사이트에 들어맞으면서 아직 파기되지 않은
쿠키들을 함께 보낸다. 모든 쿠키는 Cookie 헤더에 한데 이어 붙여 보낸다.

##### 11.6.7 Version 1 RFC 2965 쿠키
- Version1 표준은 Set-Cookie2와 Cookie2헤더를 가지고 있으며, Version 0 시스템과도 호환된다.
- 아직 모든 브라우저나 서버가 완전히 지원하지는 않는다.

##### 11.6.8 쿠키와 세션 추적
- 쿠키는 웹 사이트에 수차례 트랜잭션을 만들어내는 사용자를 추적하는 데 사용한다.

##### 11.6.9 쿠키와 캐싱
- 쿠키 트랜잭션과 관련된 문서를 캐싱하는것은 주의해야 한다.
- 이전 사용자의 쿠키가 다른 사용자에게 할당돼버리거나, 다른이에게 개인정보가 노출되는 상황이 일어날 수도 있다.
- 캐시되지 말아야할 문서가 있다면 Cache-Control: no-cache"Set-Cookie"를 기술해서 명확하게 표시한다.
- Set-Cookie 헤더를 캐시하는것은 주의해야 한다.
- Cookie 헤더를 가지고 있는 요청을 주의해야 한다.

##### 11.6.10 쿠키, 보안 그리고 개인정보
- 쿠키를 사용하지 않도록 비활성화 시키거나, 로그 분석과 같은 달느 방법으로 대체하는 것도 가능하므로, 
그 자체가 보안상 엄청나게 위험한 것은 아니다.  

### 12장 기본 인증
- 서버는 사용자가 누구인지 식별할 수 있어야 한다.
- 서버가 사용자가 누군지 알면, 그 사용자가 어떤 작업이나 리소스에 접근할 수 있는지 결정할 수 있다.

#### 12.1 인증
- 인증은 당신이 누구인지 증명하는 것이다.
- 완벽한 인증이란 없다. 비밀번호는 탈취 될 수 있고, 신분증은 도둑맞거나 위조될 수 있다.

##### 12.1.1 HTTP의 인증요구/응답 프레임워크
- HTTP는 사용자 인증을 하는데 사용하는 자체 인증요구/응답 프레임워크를 제공한다.
- 웹 애플리케이션이 HTTP 요청 메시지를 받으면, 서버는 요청 처리를 하는 대신 현재 사용자가 누구인지 알 수 있게 개인 정보를 요구하는 
'인증 요구'로 응답할 ㅅ ㅜ있다.

##### 12.1.2 인증 프로토콜과 헤더
- HTTP는 필요에 따라 고쳐 쓸 수 있는 제어 헤더를 통해, 다른 인증 프로토콜에 맞추어 확장할 수 있는 프레임워크를 제공한다.
- HTTP는 기본 인증과 다이제스트 인증이라는 두 가지 공식적인 인증 프로토콜이 있다.
- 서버가 사용자에게 인증요구를 보낼 때, 서버는 401 Unauthorized 응답과 함께 WWW-Authenticate 헤더를 기술해서 어디서 어떻게 인증할지 설명한다.
- 클라이언트가 서버로 인증하려면, 인코딩된 비밀번호와 그 외 인증 파라메터들을 Authorization 헤더에 담아서 요청을 다시 보낸다.
- 인증이 완료되면, 서버는 정상적인 상태 코드를 반환하며 추가적인 인증 알고리즘에 대한 정보를 Authentication-Info 헤더에 기술할 수도 있다.

##### 12.1.3 보안 영역
- 웹 서버는 기물문서를 보안영역(realm) 그룹으로 나눈다. 보안 영역은 저마다 다른 사용자 권한을 요구한다.
 
#### 12.2 기본 인증
- 기본 인증은 가장 잘 알려진 HTTP 인증 규약이다.
- 거의 모든 주요 클라이언트와 서버에 기본 인증이 구현되어 있다.
- 웹 서버는 클라이언트의 요청을 거부하고 인증을 요구할 수 있다.

##### 12.2.1 기본 인증의 예
- 기본 인증 프로토콜은 Authentication-Info 헤더를 사용하지 않는다는 점을 기억하자.

##### 12.2.2 Base-64 사용자 이름/비밀번호 인코딩
- HTTP 기본 인증은 사용자 이름과 비밀번호를 콜론으로 이어서 합치고, base-64 인코딩 메서드를 사용해 인코딩 한다.

##### 12.2.3 프락시 인증
- 중개 프락시 서버를 통해 인증할 수도 있다.
- 프락시 서버에서 접근 정책을 중앙 관리 할 수 있기 때문에, 회사 리소스 전체에 대해 통합적인 접근 제어를 하기 위해서 프락시 서버를 사용하면 좋다.
- 프락시 인증은 웹 서버의 인증과 헤더와 상태 코드만 다르고 절차는 같다. 

#### 12.3 기본 인증의 보안 결함
- 기본 인증은 단순하고 편리하지만 안심할 수는 없다.
- 기본 인증은 악의적이지 않은 누군가가 의도치 않게 리소스에 접근하는 것을 막는데 사용하거나, SSL 같은 암호기술과 혼용한다.

`보안 결함`
1. 기본 인증은 사용자 이름과 비밀번호를 쉽게 디코딩할 수 있는 형식으로 네트워크에 전송한다.
2. 보안 비밀번호가 디코딩하기에 더 복잡한 방식으로 인코딩되어 있더라도, 그것을 그대로 원서버에 보내서 인증에 성공하고 서버에 접근할 수 있다.
3. 메세지의 인증 헤더를 건드리지는 않지만, 그 외 다른부분을 수정해서 트랜잭션의 본래 의도를 바꿔버리는 프락시나 중개자가
중간에 개입하는 경우, 기본 인증은 정상적인 동작을 보장하지 않는다.
4. 기본 인증은 가짜 서버의 위장에 취약하다.

### 13장 다이제스트 인증
- 기본 인증은 편리하고 유연하지만 전혀 안전하지 않다.
- 사용자 이름과 비밀번호를 평문으로 보내고, 메시지를 위조하지 못하게 보호하려면 어떠한 시도도 하지않는다.

#### 13.1 다이제스트 인증의 개선점
- 다이제스트 인증은 기본 인증의 가장 심각한 결함을 수정한 또 다른 HTTP 인증 프로토콜이다.

`특징`
1. 비밀번호를 절대로 평문으로 전송하지 않는다.
2. 인증 체결을 가로채서 재현하려는 악의적인 사람들을 차단한다.
3. 구현하기에 따라서, 메시지 내용 위조를 막는 것도 가능하다.
4. 그외 몇몇 잘 알려진 형태의 공격을 막는다.

> 다이제스트 인증이 가장 안전한 프로토콜은 아니다. 안전한 HTTP 트랜잭션을 위한 많은 요구사항을 만족하지는 못한다.

##### 13.1.1 비밀번호를 안전하게 지키기 위해 요약 사용하기
- 클라이언트는 비밀번호르 보내는 대신, 비밀번호를 비가약적으로 뒤섞은 지문 혹은 요약을 보낸다.
- 서버는 클라이언트가 보낸 요약이 비밀번호에 알맞게 대응하는지 검사할 수 있다.

##### 13.1.2 단방향 요약
- 요약은 정보 본문의 압축이다.
- 요약은 단반향 함수로 동작하고, 일반적으로 입력가능한 무한 가지의 모든 입력값들을 유한한 범위의 압축으로 변환한다.
- 요약 함수는 보통 암호 체크섬 으로 불리며, 단방향 해시 함수이거나 지문 함수이다.

##### 13.1.3 재전송 방지를 위한 난스 사용
- 단뱡항 요약은 비밀번호를 그대로 전송해야 할 필요성에서 우리를 해방시켜 준다.
- 하지만 그 자체만으로는 우리를 위험에서 지켜줒 ㅣ못한다.
- 비밀번호를 모른다고 해도 요약을 개로채서 서버로 몇번으로 재전송 할 수 있다.
- 이런 재전송 공격을 방지하기 위해 서버는 클라이언트에게 난스 라고 불리는 특별하고, 자주 바뀌는 증표를 건네준다.
- 난스를 비밀번호에 섞으면 난스가 바뀔 때마다 요약도 바뀌게 만들어 준다.

> 다이제스트 인증은 난스를 사용할 것을 요구한다. 난스는 WWW-Authenticate 인증 요구에 담겨 서버에서 클라이언트로 넘겨진다.

##### 13.1.4 다이제스트 인증 핸드셰이크
1. 서버는 난스 값을 계산한다.
2. 서버는 난스를 WWW-Authenticate 인증요구 메시지에 담아, 서버가 지원하는 알고리즘 목록과 함께 클라이언트에게 전송한다.
3. 클라이언트는 알고리즘을 선택하고 비밀번호와 그 외 데이터에 대한 요약을 계산한다.
4. 클라이언트는 Authorization 메시지에 요약을 담아 서버에게 돌려준다.
5. 서버는 요약, 알고리즘, 그외 보조 데이터들을 받고 클라이언트가 했던 그대로 요약을 계산한뒤, 요약이 서로 같은지 확인한다.

#### 13.2 요약 계산
- 다이제스트 인증의 핵심은 공개된 정보, 비밀 정보, 시한부 난스 값을 조합한 단방향 요약이다.

##### 13.2.1 요약 알고리즘 입력 데이터
- 요약은 다음 세 요소로부터 계산된다.

1. 단방향 해시함수 H(d) 와, 요약함수 KD(s,d). s = 비밀, d = 데이터 를 의미한다.
2. 비밀번호 등 보안 정보를 담고 있는 데이터 덩어리. A1 이라 칭한다.
3. 요청 메시지의 비밀이 아닌 속성을 담고 있는 데이터 덩어리. A2 라 칭한다.

> A1, A2 두 조각의 데이터는 요약을 생성하기 위해 H와 KD에 의해 처리된다.

##### 13.2.2 H(d), KD(s,d) 알고리즘
- 다이제스트 인증은 여러 요약 알고리즘을 선택할 수 있도록 지원한다.
- RFC 2617 에서 제안된 두 알고리즘은 MD5와 MD5-sess 이며, 만약 알고리즘이 정해지지 않았다면 MD5가 기본값이다.

##### 13.2.3 보안 관련 데이터 A1
- A1은 사용자 이름, 비밀번호, 보호 영역, 난스와 같은 비밀 보호 정보로 이루어져 있다.
- 메시지 자체가 아닌 비밀 정보와만 관련되어 있다.

##### 13.2.4 메시지 관련 데이터 A2
- A2로 불리는 데이터 덩어리는 URL, 요청 메서드, 메시지 엔티티 본문과 같은 메시지 자체의 정보를 나타낸다.
- A2는 메서드, 리소스, 메시지의 위조를 방지하기 위해 사용된다.

##### 13.2.5 요약 알고리즘 전반
- RFC 2617은 주어진 H, KD, A1, A2로 요약을 계산하는 두가지 방법을 정의한다.

1. 예전 명세인 RFC-2069와 호환을 염두에 둔것으로, qop옵션이 빠졌을때 사용된다. 비밀 정보와 난스가 붙은 메시지의 데이터의
해시를 이용해 요약을 계산한다.
2.현대적이면서 보다 선호되는 접근법으로 난스 횟수 집계 및 대칭 인증의 지원을 포함한다. 이 접근법은 qop가 auth 일 때와 auth-int
일때 모두 사용된다. 이것은 난스 횟수 qop, c 난스 데이터를 요약에 추가한다.

##### 13.2.6 다이제스트 인증 세션
- WWW-Authenticate 인증 요구에 대한 응답은 보호 공간에 대한 인증 세션을 싲가하게 한다.
- 인증 세은 클라이언트가 보호 공간의 다른 서버로 부터 또 다른 WWW-Authenticate 인증요구를 받을 때까지 지속된다.

##### 13.2.7 사전 인가
- 일반적인 인증에서 각 요처은 트랜잭션이 완료되기 전에 요청/인증요구 사이클을 필요로 한다.
- 만약 클라이언트가 다음 난스를 미리 알고 있다면 요청/인증요구 사이클을 생략할 수 있다.
- 만약 클라잉너트가 요청을 받기 전 Authorization 헤더를 계산할 수 있다면 클라이언트는 요청/인증요구 단계를 거치지 않고
미리 Authorization 헤더를 서버에 제공한다.

> 사전 인가로 인한 성능 개선효과가 존재함

- 다이제스트 인증은 사전 인가를 할 수 있는 몇가지 방법을 제안한다.

1. 서버가 다음 난스를 Authentication-Info 성공 헤더에 담아 미리 보낸다.
2. 짧은 시간동안 같은 나스를 재사용하는 것을 허용한다.
3. 클라이언트와 서버가 동기화 되어 있고 예측 가능한 난스 생성 알고리즘을 사용한다.

##### 13.2.8 난스 선택
- 난스의 내용은 불투명하고 구현 의존적이다.
- RFC 2617은 다음과 같은 가상의 난스 공식을 제안했다.

> BASE64(타임스탬프 H(타임스탬프":" ETag ":" 개인 ))

- 이 방법에서 서버는 난스의 유효 기간을 제한할 수 있다.
- ETag를 포함하면 갱신된 리소스에 대한 재요청을 방지한다.

##### 13.2.9 상호 인증
- RFC 2617은 클라이언트가 서버를 인증할 수 있도록 다이제스트 인증을 확장 했다.
- 이는 서버가 공유된 비밀 정보에 근거한 올바른 응답 요약을 생성할 수 있도록, 클라이언트 난스 값을 제공함으로써 가능해진다.
- 서버는 이 요약을 Authentication-Info 헤더를 통해 클라이언트에 전달한다.
- 이 상호 인증은 RFC 2617로 표준화 되었다.

#### 13.3 보호 수준 향상
- qop 필드는 요약 헤더의 세가지 헤더 WWW-Authenticate, Authorization, Authentication-Info 에 모두 존재할 수 있다.
- qop 필드는 클라이언트와 서버가 어떤 보호 기법을 어느정도 수준으로 사용할 것인지 협상할 수 있게 해준다.

##### 13.3.1 메시지 무결성 보호
- 무결성 보호가 적용되었을 때 계산되는 H는, 메시지의 본문 해시가 아닌 엔티티 본문의 해시이다.
- 송신자에 의해 어떤 전송 인코딩이 적용되기도 전에 먼저 계산되고 그 후 수신자에 의해 제거된다.

##### 13.3.2 다이제스트 인증 헤더
- 기본, 다이제스트 인증 프로토콜 양쪽 모두 WWW-Authenticate 헤더에 담겨 전달되는 인증 요구와, Authorization 헤더에 담겨
전달되는 인가 응답을 포함한다. 다이제스트 인증은 여기에 선택적인 Authentication-Info 헤더를 추가했다. 

#### 13.4 실제 상황에 대한 고려

##### 13.4.1 다중 인증 요구
- 서버는 한 리소스에 대해 여러 인증을 요구할 수 있따.
- 다중 인증 요구에 직면했을 때, 클라이언트는 반드시 자신이 지원할 수 있는 가장 강력한 인증 메커니즘을 선택해야 한다.

##### 13.4.2 오류 처리
- 다이제스트 인증에서, 지시자나 그 값이 적절하지 않거나 요구된 지시자가 빠져 있는 경우 알맞은 응답은 400 응답이다.
- 요청의 요약이 맞지 않으면, 로그인이 실패했음을 기록해 두는 것이 좋다. 반복된 실패는 공격을 시도하고 있음을 의미한다.
- 인증서버는 반드시 'uri' 지시자가 가리키는 리소스가 요청줄에 명시된 리소스와 같음을 확인해야 한다.

##### 13.4.3 보호 공간
- 영역 값은 접근한 서버의 루트 URL과 결합되어, 보호 공간을 정의한다.
- 영역은 서버의 보호된 리소스들을 자신만의 인증 제도와 ㅇ니가 데이터베이스 어느 한쪽 혹은 양쪽 모두를 가진 보호 영역의
집합으로 분할할 수 있도록 해준다.

##### 13.4.4 URI 다시 쓰기
- 프락시는 가리키는 리소스의 변경 없이 구문만 고쳐서 URI를 다시 쓰기도 한다.
- 프락시가 URI를 변경할 수 있는 동시에 다이제스트 인증은 URI값의 무결성 검사를 하므로, 다이제스트 인증이 실패할 수 있다.

##### 13.4.5 캐시
- 공유 캐시가 Authorization 헤더를 포함한 요청과 그에 대한 응답을 받은 경우, Cache-Control 지시자 중 하나가 응답에 존재하지 않는 한
다른 요청에 대해 그 응답을 반환해서는 안된다.

#### 13.5 보안에 대한 고려사항

##### 13.5.1 헤더 부당 변경
- 헤더 부당 변경에 대해 항상 안전한 시스템을 제공하기 위해, 양 종단 암호화나 헤더에 대한 디지털 서명이 필요하다.
- 보호 수준에 대한 정보는 WWW-Authenticate, Authorization 헤더에만 담겨있다.

##### 13.5.2 재전송 공격
- 재전송 공격이란 누군가 어떤 트랜잭션에서 엿들은 인증자격을 다른 트랜잭션을 위해 사용하는것을 말한다.
- 이 문제는 GET 요청에 대한 이슈이긴 하지만, POST PUT 요청에 대한 재전송 공격에 대해서도 항상 잘 동작하는 예방책을 필수적으로 가지고 있어야 한다.

##### 13.5.3 다중 인증 메커니즘
- 서버가 다중 인증 제도를 지원할 때 WWW-Authenticate 헤더를 통해 선택지를 제공한다.
- 클라이언트에게 가장 강력한 인증 메커니즘을 선택해야 할 의무가 있지는 않기 때문에, 결국 인증의 강도는 선택지중 가장 약한 것과 같다고 보아야 한다.

##### 13.5.4 사전 공격
- 사전 공격은 전형적인 비밀번호 추측 공격이다.
- 트랜잭션을 엿들어 난스/응답 쌍에 대해 흔히 구할수 있는 비밀번호 추측 프로그램을 사용하여 찾아내는 공격이다.

##### 13.5.5 악의적인 프락시와 중간자 공격
- 프락시중 하나가 악의적이거나 보안이 허술하다면 클라이언트는 중간자 공격에 취약한 상태가 될 수 있다.
- 신뢰할 수 있는 프락시의 신뢰도에 흠집낼 수 있는 것중 하나는 프락시 자신의 확장 인터페이스 이다.

##### 13.5.6 선택 평문 공격
- 만약 보안이 허술하거나 악의적인 프락시가 트래픽 중간에 끼어든다면 어렵지 않게 클라이언트가 응답 계싼을 하기위한 난스를 제공 할 수 있다.
- 응답을 계싼하기 위해 알려진 키를 사용하는 것은 응답의 암호 해독을 쉽게 한다.
- 이것을 선택 평문 공격이라 불린다.

##### 13.5.7 비밀번호 저장
- 다이제스트 인증 메커니즘은 사용자 응답을 서버 내부에 저장된 것과 비교한다.
- 다이제스트 인증 비밀번호 파일이 유출되면 영역의 모든 문서는 즉각 공격자에게 노출된다.

### 14장 보안 HTTP

#### 14.1 HTTP를 안전하게 만들기
- HTTP의 보안 버전은 효율적이고, 이식성이 좋아야하고, 관리가 쉬워야 하며, 현실 세계의 변화에 대한 적응력이 좋아야 한다.

##### 14.1.1 HTTPS
- HTTPS는 HTTP를 안전하게 만드는 방식 중에서 가장 인기 있는 것이다.
- HTTPS로 접근하고 있는 경우 https:// 스킴을 사용한다.
- HTTPS를 사용할 때, 모든 HTTP요청과 응답 데이터는 네트워크로 보내지기 전에 암호화 된다.
- HTTPS는 HTTP 하부에 전송 레벨 암호 보안 계층을 제공함으로써 동작하는데, 이는 안전 소켓 계층 SSL or TLS를 이용해 구현된다.

#### 14.2 디지털 암호학

##### 14.2.1 비밀 코드의 기술과 과학
- 암호법은 메시지 인코딩과 디코딩에 대한 과장이자 기술이다.

##### 14.2.2 암호(cipher)
- 암호법은 암호라 불리는 비밀 코드에 기반한다.
- 암호란 메시지를 인코딩하는 어떤 특정한 방법과 나중에 그 비밀 메시지를 디코딩하는 방법이다.
- 인코딩되기 전의 원본 메시지는 흔히 평문이라고 불린다.
- 암호가 작용되어 코딩된 메시지는 보통 암호문이라 불린다.

##### 14.2.3 암호 기계
- 암호는 상대적으로 간단한 알고리즘으로 시작했는데, 사람이 직접 인코딩과 디코딩을 해야했기 때문이다.
- 하지만 보다 복잡한 암호로 메시지를 빠르고 정확하게 인코딩하고 디코딩하는 기계를 만들기 시작했다.

#### 14.2.4 키가 있는 암호
- 코드 알고리즘과 기계가 적의 손에 들어갈 수 있기 때문에, 대부분의 기계들에는 암호의 동작방식을 변경할 수 있는 값 설정이 가능한
다이얼이 달려있다.
- 이런 암호 매개변수를 키 라고 부른다.

#### 14.2.5 디지털 암호
- 속도 및 기능에 대한 기계장치의 한계에서 벗어남으로써, 복잡한 인코딩과 디코딩 알고리즘이 가능해졌다.
- 매우 큰 키를 지원하는 것이 가능해져서, 단일 암호 알고리즘으로 키의 값마다 다른 수조 개의 가상 암호 알고리즘을 만들어낼 수 있게 되었다.
- 키가 길수록 인코디으이 많은 조합이 가능해지고 무작위로 추측한 키에 대한 크래킹이 어려워진다.

#### 14.3 대칭키 암호법
- 많은 암호 알고리즘은 대칭키 암호라 불리는데, 인코딩과 디코딩시 사용하는 키가 같기 때문이다.
- 잘 알려진 대칭키 암호 알고리즘은 DES, Triple-DES, RC2, RC4 등이 있다. 

##### 14.3.1 키 길이와 열거 공격
- 대부분의 경우 인코딩 및 디코딩 알고리즘은 공개적으로 알려져 있으므로, 키만이 유일한 비밀이다.
- 좋은 암호 알고리즘은 공격자가 코드를 크래킹하려면 우주에 존재하는 모든 가능한 키값을 시도해보는것 외에 다른 방법이 없게 만든다.
- 무차별로 모든 키값을 대입해보는 공격을 열거공격이라고 한다.

##### 14.3.2 공유키 발급하기
- 대칭키 암호의 단점 중 하나는 방송자와 수신자가 서로 대화하려면 둘 다 공유키를 가져야 한다는 것이다.
- 즉 모든 사용자에 대한 비밀 키를 생성하고 그것을 기억해야한다.

#### 14.4 공개키 암호법
- 한 쌍의 호스트가 하나의 인코딩/디코딩 키를 사용하는 대신, 공개 키 암호방식은 두 개의 비대칭 키를 사용한다.
- 인코딩 키는 모두를 위해 공개되어 있지만, 디코딩 키는 호스트만이 알 고 있다.
- 공개키 암호화 기술은 보안 프로토콜을 전 세계의 모든 컴퓨터 사용자에게 적용할 수 있게 해주었다.

##### 14.4.1 RSA
- 공개키 비대칭 암호의 과제는, 다른 이가 비밀인 개인 키를 계산할 수 없다는 것을 확신시켜 주는 것이다.
- MIT 에서 발명되고 이어서 RSA 데이터 시큐리티에서 상용화된 RSA 알고리즘이다. 

##### 14.4.2 혼성 암호 체계와 세션 키
- 비대칭 공개키 암호 방식은 누구나 공개키만 알면 그 키에 대응되는 공개 서버에 안전하게 메시지를 보낼 수 있다.
- 하지만 공개키 암호 방식의 알고리즘은 계산이 느린 경향이 있다.
- 노드 사이에 안전한 통신을 수립할때는 편리한 공개키 암호를 사용하고, 안전한 통신을 통해 임시의 무작위 대칭 키를 생성하고
교환하여 이후의 나머지 데이터를 암호화할 때는 빠른 대칭 키를 사용하는 방식이 흔히 쓰인다.

#### 14.5 디지털 서명
- 암호 체계는 그 메시지가 위조되지 않았음을 증명하기 위해 메시지에 서명을 하도록 하는데 이용될 수 있다.
- 디지털 서명이라 불리는 기법은 인터넷 보안 인증서에게 중요하다.

##### 14.5.1 서명은 암호 체크섬이다.
- 디지털 서명은 메시지에 붙어있는 특별한 암호 체크섬이다.
- 이점은 다음과 같다.

1. 서명은 메시지를 작성한 저자가 누군지 알려준다. 오직 저자만이 체크섬을 계산할 수 있으며 체크섬은 저자의 개인 서명 처럼 동작한다.
2. 서명은 메시지 위조를 방지한다.

#### 14.6 디지털 인증서
- 디지털 인증서 (certs) 는 신뢰할 수 있는 기관으로 부터 보증받은 사용자 나 회사에 대한 정보를 가지고 있다.

##### 14.6.1 인증서 내부
- 디지털 설명된 정보의 집합이 담겨 있다.
    - 대상의 이름
    - 유효기간
    - 인증서 발급자
    - 인증서 발급자의 디지털 서명
- 추가적으로 서명 알고리즘과 대상의 공개키도 가지고 있다.

##### 14.6.2 X.509 v3 인증서
- 디지털 인증에 대한 전 세계적인 단일 표준은 없다.
- 오늘날 사용되는 대부분의 인증서는 X.509 라 불리는 표준화된 서식에 저장하고 있다.

##### 14.6.3 서버 인증을 위한 인증서 사용
- HTTPS 를 통한 웹 트랜잭션 시작시 브라우저는 접속한 서버에서 인증서를 가져온다.

`서버 인증서가 포함하고 있는 내용`
- 웹 사이트 명과 호스트 명
- 웹 사이트의 공개 키
- 서명 기관의 이름
- 서명 기관의 서명

> 만약 서명 기관이 알 수 없는 곳이라면, 해당 대화상자를 사용자에게 보여준다. 

#### 14.7 HTTPS 의 세부사항
- HTTPS는 HTTP 프로토콜의 대칭, 비대칭 인증서 기반 암호 기법의 강력한 집합을 결합한 것
- 웹 기반 전자상거래의 고속 성장을 이끄는 주력

##### 14.7.1 HTTPS의 개요
- 보안 전송 계층을 통해 전송되는 HTTP
- HTTPS의 보안계층은 SSL, TLS 로 구현되었다.

##### 14.7.2 HTTPS 스킴
- HTTPS 프로토콜의 URL 스킴 접두사는 https 이다.
- 클라이언트는 웹 리소스에 대한 트랜잭션 수행을 요청받으면 URL의 스킴을 검사한다.

##### 14.7.3 보안 전송 셋업
- HTTPS에서의 절차는 SSL 보안 계층 때문에 약간 더 복잡하다.
- 443 포트를 통해 연결하고, 핸드셰이크를 통해 SSL을 초기화 한다.
- 초기화가 완료되면 요청 메시지를 보안 계층을 통해 전송할 수 있다.

##### 14.7.4 SSL 핸드 셰이크
- SSL 핸드셰이크에서는 다음과 같은 일이 일어난다.
1. 프로토콜 버전 번호 교환
2. 양쪽 모두 이해가능한 암호 서낵
3. 양쪽 신원 인정
4. 채널을 암호화 하기 위한 임시 세션키 생성

##### 14.7.5 서버 인증서
- SSL은 서버와 클라이언트간에 상호 인증을 지원한다.
- 클라이언트 인증서는 웹 브라우징에서 흔히 쓰이지 않는다.
- 보안 HTTPS 트랜잭션은 항상 서버 인증서를 요구한다.

##### 14.7.6 사이트 인증서 검사
- 넷 스케이프가 제안한 웹 서버 인증서 검사 알고리즘은 대부분의 웹 브라우저 검사 기법의 기초를 구축했다.
1. 날짜검사
    - 인증서의 유효성을 확인하기 위해, 시작일 및 종료일을 검사한다.
2. 서명자 신뢰도 검사
    - 모든 인증서는 서버를 보증하는 인증기관 (CA) 에 의해 서명되어 있다.
    - 신뢰할만한 CA 로 부터 발급받은 인증서 임을 확인하고, 만약 알려지지 않은 서명기관이라면 경고를 보여준다.
3. 서명 검사
    - 믿을만한 서명기관이라고판단되면, 서명 기관의 공개키를 서명에 적용하여 체크섬을 이용해 인증서의 무결성을 검사한다.
4. 사이트 신원검사
    - 인증서의 도메인 명이 서버의 도메인 명과 동잃나지 검사한다.

##### 14.7.7 가상 호스팅과 인증서
- 가상 호스트로 운영되는 사이트의 보안트래픽을 다루는것은 까다롭다.
- 이런 문제를 피하기 위해 보안 트랜잭션을 수행하는 모든 사용자를 하나의 호스트로 리다이렉트 한다.

#### 14.8 진짜 HTTPS 클라이언트
- 암호 전문가가 아닌이상, 가공되지 않은 SSL 트래픽을 직접 보내지 마라.

##### 14.8.1 OpenSSL
- SSL, TLS 의 가장 인기 있는 오프소스 구현
- http://www.openssl.org

#### 14.9 프락시를 통한 보안 트래픽 터널링
- 많은 회사가 기업 네트워크와 공공 인터넷을 잇는 경계에 보안 프락시를 설치한다.
- 이 프락시는 방화벽 라우터가 HTTP 트래픽 교환을 허락한 유일한 장치이며, 바이러스 검사 및 기타 콘텐츠 제어를 수행한다.
- HTTPS 가 프락시와 잘 동작하기 위한 기법 중 하나는 HTTPS SSL 터널링 프로토콜이다.
- HTTP 는 connect 확장 메서드를 이용해 터널을 만든다.

## 4부 엔터티, 인코딩, 국제화

### 15장 엔터티와 인코딩
- HTTP는 메시지가 올바르게 수송되고, 식별되고, 추출되고, 처리하는것을 보장한다. HTTP 는 다음을 보장한다.
1. 객체는 올바르게 식별되므로 브라우저나 다른 클라이언트는 콘텐츠를 바르게 처리할 수 있다.
2. 객체는 올바르게 압축이 풀릴것이다.
3. 객체는 항상 최신이다.
4. 사용자의 요구를 만족할 것이다.
5. 네트워크 사이를 빠르고 효율적으로 이동할 것이다.
6. 조작되지 않고 온전하게 도착할 것이다.

> 이 모든것을 가능케 하기 위해 HTTP는 콘텐츠를 잘 나르기 위해 잘 라벨링된 엔터티를 사용한다.

#### 15.1 메시지는 컨테이너, 엔티티는 화물
- HTTP 메시지를 인터넷 운송 시스템의 컨테이너라고 생각한다면, HTTP 엔티티는 메시지의 화물이다.
- HTTP/1.1 은 아래의 10가지 주요 헤더 필드를 정의 하였다.
1. Content-Type
    - 엔티티에 의해 전달된 객체의 종류
2. Content-Length
    - 전달되는 메시지의 길이나 크기
3. Content-Language
    - 전달되는 객체와 가장 잘 대응되는 자연어
4. Content-Encoding
    - 객체 데이터에 대해 행해진 변형 (압축)
5. Content-Location
    - 요청 시점을 기준으로, 객체의 또 다른 위치
6. Content-Range
    - 만약 이 엔티티가 부분 엔티티라면, 이 엔티티가 어느 부분에 해당하는지 정의한다.
7. Content-MD5
    - 엔티티 본문의 콘텐츠에 대한 체크섬
8. Last-Modified
    - 서버에서 이 콘텐츠의 최종 수정일
9. Expires
    - 이 엔티티 데이터에 대한 최신 만료기간
10. Allow
    - 이 리소스에 대해 어떤 메서드가 허용되는가
11. ETag
    - 이 인스턴스에 대한 고유 검사기
12. Cache-Control
    - 어떻게 이 문서가 캐시될수 있는가 
    
##### 15.1.1 엔티티 본문
- 엔티티본문은 가공되지 않은 데이터만을 담고 있다.
- 그 외 정보들은 모두 헤더에 담겨있다.
- 엔티티 헤더는 본문에 대해 설명할 필요가 있다. 

#### 15.2 Content-Length: 엔티티의 길이
- Content-Length 헤더는 메시지의 본문 크기를 바트 단위로 나타낸다.
- 이 헤더는 메시지를 청크 인코딩으로 전송하지 않는 한, 본문을 포함한 메시지에서는 필수적이다.
- 메시지 잘림 감지 와 지속 커넥션을 공유하는 메시지를 분할 하고자 할 때 필요하다.

##### 15.2.1 잘림 검출
- 이전 버전의 HTTP 는 커넥션이 닫힌 것을 보고 메시지의 끝을 인지했따.
- Content-Length 가 없다면, 클라이언트는 커넥션이 정상 종료된 것인지 도중에 충돌이 발생한 것인지 알지 못한다.
- 메시지 잘림 판단을 위해 Content-Length 헤더는 필수적이다.
- 메시지 잘림은 캐싱 프락시 서버에서 특히 취약하다.
- 캐싱 프락시 서버는 잘린 메시지를 캐시하시는것을 줄이기 위해 Content-Length 헤더가 없는 본문은 캐싱하지 않는다.

##### 15.2.2 잘못된 Content-Length
- Content-Length 가 잘못된 값을 가진 경우 아에 빠진 것보다 큰 피해를 유발할 수 있다.

##### 15.2.3 Content-Length 와 지속 커넥션
- Content-Length 헤더는 지속 커넥션을 위해 필수이다.
- Content-Length 헤더는 메시지 하나가 어디서 끝나는지 알려준다.
- 지속 커넥션 이기 때문에, 클라이언트가 커넥션이 닫힌 위치를 근거로 메시지의 끝을 인식하는것은 불가능하다.

##### 15.2.4 콘텐츠 인코딩
- 엔티티 본문이 인코딩 되어 있다면, Content-Length 헤더는 인코딩 되지 않은 본문의 길이가 아닌, 인코딩된 본문의 길이를 바이트 단위로 정의한다

##### 15.2.5 엔티티 본문 길이 판별을 위한 규칙
1. 본문을 갖는 것이 허용되지 않는 특정 타입의 HTTP 메시지 에서는 본문 계산을 위한 Content-Length 헤더가 무시 된다.
2. 메시지가 Transfer-Encoding 헤더를 포함하고 있다면, 메시지가 커넥션이 닫혀 먼저 끝나지 않는 한, 엔티티는 **0바이트 청크**라 불리는 특별한 패턴으로 끝나야 한다.
3. 메시지가 Content-Length 헤더를 갖는다면, Transfer-Encoding 헤더가 존재하지 않는 이상 Content-Length 값은 본문의 길이를 담게 된다.
4. 메시지가 multipart/byteranges 미디어 타입을 가지고 있고, 엔티티 길이가 별도 정의된게 없다면 멀티파트 메시지의 각 부분은 각자가 스스로의 크기를 정의한다. 이 미디어 타입은 수신자가 
이것을 해석할 수 있다는 사실을 알기 전 까지는 절대로 보내지 않아야한다.
5. 위 규칙중 어느것에도 해당하지 앟는다면, 엔티티는 커넥션이 닫힐 때 끝난다.
6. HTTP/1.0 애플리케이션과의 호환을 위해, 엔티티 본문을 갖고 있는 HTTP/1.1 요청은 반드시 유효한 Content-Length 헤더도 갖고 있어야 한다.
HTTP/1.1 명세는 요청 본문은 있지만 Content-Length 헤더가 없다면, 메시지 길이 판별 불가시 400 응답, 유효한 길이를 요구하려면 411 응답을 보내라고 조언한다.

#### 15.3 엔티티 요약
- HTTP가 신뢰할만한 프로토콜 위에서 돌아감에도 불구하고 메시지 일부분이 전송중 변형되는 일이 발생한다.
- 엔티티가 최초 생성될 때 데이터에 대한 체크섬을 생성해 해당 체크섬으로 변형을 검사할 수 있다.
- Content-MD5 헤더는 엔티티 본문에 MD5 알고리즘을 적용한 결과를 보내기 위해 사용한다.
- 하지만 메시지 무결성 검사를 위해 Content-MD5는 그다지 자주 전송되지 않는다.
- HTTP 확장들은 IETF 초안으로 다른 요약 알고리즘들을 제안했다. 
- Want-Digest 라는 새로운 헤더를 제안 했다.

#### 15.4 미디어 타입과 차셋
- Content-Type 헤더는 엔티티 본문의 MIME 타입을 기술한다.

| 미디어 타입 | 설명 |
|---|---|
| text/html | HTML 문서 |
| text/plain | 플레인 텍스트 |
| image/* | 이미지 |
| audio/x-wav | wav 음향 |
| model/vrml | VRML 모델 |
| application/vnd.ms-powerpoint | 파워 포인트 |
| multipart/byteranges | 바이트 레인지 |
| message/http | 완전한 HTTP 메시지 |

#### 15.5 콘텐츠 인코딩

##### 15.5.1 인코딩 과정
1. 웹 서버가 원본 Content-Type과 Content-Length 헤더를 수반한 원본 응답 메시지를 생성한다.
2. 콘텐츠 인코딩 서버가 인코딩된 메시지를 생성한뒤 Content-Encoding 헤더를 추가한다.
3. 수신 측은 디코딩 하여 원본을 얻는다.

##### 15.5.2 인코딩 유형
- IANA 를 통해 표준화 된다.

| 콘텐츠 인코딩 값 | 설명 |
| --- | --- |
| gzip | GNU zip 인코딩이 적용됨 |
| compress | 유닉스 파일 압축프로그램이 실행됨 |
| deflate | zlib 포맷으로 압축됨 |
| identity | 어떤 인코딩도 수행되지 않았음을 의미, Content-Encoding 헤더가 없다면 이값으로 간주 |

##### 15.5.3 Accept-Encoding 헤더
- 클라이언트가 자신이 지원하는 인코딩 목록을 요청헤더를 통해 전달한다.
- Accept-Encoding이 없다면, 모든 인코딩을 허용함으로 간주한다.

#### 15.6 전송 인코딩과 청크 인코딩
- 콘텐츠 인코딩은 콘텐츠 포맷과 긴밀한 연관이 있다.

##### 15.6.1 안전한 전송
- 전송 인코딩은 네트워크를 통한 안전한 전송을 위해 존재했다.
- HTTP에서 전송된 메시지의 본문이 문제를 일으킬수 있는 이유중 두가지를 소개한다.

1. 알수없는 크기
    -  몇몇 게이트웨이 와 콘텐츠 인코더는 콘텐츠를 먼저 생성하지 않고서는 메시지 본문의 최종 크기를 판단할 수 없다.
2. 보안
    - 공용 전송 네트워크로 메시지를 보내기 전에 전송 인코딩을 사용해 알아보기 어렵게 뒤섞어버리는 방법
    
##### 15.6.2 Transfer-Encoding 헤더
- 전송 인코딩을 제어하고 서술하기 위해 정의된 헤더는 다음과 같다.

1. Transfer-Encoding
    - 안전한 전송을 위해 어떤 인코딩이 적용되었는지 서술한다.
2. TE
    - 어떤 확장된 전송 인코딩을 사용할 수 있는지 서버에게 알려준다.
    
##### 15.6.3 청크 인코딩
- 청키 인코딩은 메시지를 일정 크기의 청크 여럿으로 쪼개어, 순차적으로 보낸다.
- 이를 이용하면 전체 크기를 알 필요가 없어진다.
- 청크 인코딩은 전송 인코딩의 한 형태임을 유의하라.
- 지속 커넥션을 사용한다면, 크기가 0인 청크로 본문이 끝났음을 알린다.

##### 15.6.4 콘텐츠와 전송 인코딩의 조합
- 콘텐츠 인코딩과 전송 인코딩은 동시에 사용될 수 있다.

##### 15.6.5 전송 인코딩 규칙
1. 전송 인코딩 집합은 반드시 chunked 를 포함해야 한다. 예외는 메시지가 커넥션의 종료로 끝나는 경우 뿐이다.
2. 청크 전송 인코딩이 사용되었다면, 메시지 본문에 적용된 마지막 전송 인코딩이 존재해야한다.
3. 청크 전송 인코딩은 반드시 메시지 본문에 한 번 이상 적용되어야 한다.

> 이 규칙은 수신자가 메시지 전송 길이를 알아낼 수 있게 해준다.
> 어떤 HTTP/1.1 애플리케이션이더라도 최소한 청크 인코딩은 지원해야 한다.

#### 15.7 시간에 따라 바뀌는 인스턴스
- 웹 객체는 정적이지 않다. 같은 URL은 시간에 따라 다른 버전의 객체를 가리킬 수 있다.
- HTTP 프로토콜은 어떤 특정 종류의 요청이나 응답을 다루는 방법들을 정의하는데, 이것은 인스턴스 좆ㄱ조작이라 불리며 객체 인스턴스에 작용한다.
- 대표적인 두가지는 범위 요청과 델타 인코딩이다.

#### 15.8 검사기와 신선도

##### 15.8.1 신선도
- 서버는 Expires, Cache-Control 헤더를 통해 캐시된 콘텐츠가 얼마동안 유효한지에 대한 정보를 준다.

##### 15.8.2 조건부 요청과 검사기
- 캐시된 문서가 유효하지 않은 경우 서버로 부터 유효한 문서를 요청하는데, 해당 문서가 수정되지 않았음에도 요청을 하게 되면
- 불필요한 리소스 낭비가 된다.
- 이를 해결하기 위해 HTTP는 리소스가 변경된 경우에만 갱신 요청을 하는 조건부 요청 기능을 제공한다.
- If~ 로 시작하는 헤더로 부터 구현된다. 대표적인 헤더는 If-Modified-Since 헤더 이다.
- 검사기를 통해 변경을 감지하는데, 약한 검사기와 강한 검사기 두가지로 나뉜다.
- 약한 검사기는 변경 시각을 기준으로, 강한 검사기는 ETag 를 활용한 문서 버저닝을 통해 검사한다. 

#### 15.9 범위 요청
- 범위 요청을 이용하면 HTTP 클라이언트는 받다가 실패한 엔티티를 일부 혹은 범위로 요청함으로써 다운로드 중단시점부터 재개할 수 있다.
- Range~ 헤더를 이용해 요청하면, 서버는 Content-Type: multipart/byte-ranges 헤더와 함께 하나의 엔티티로 응답한다.
- 모든 서버가 범위 요청을 받을수 있는 것은 아니지만, 많은 경우 가능하다.

#### 15.10 델타 인코딩
- 델타 인코딩은 객체 전체가 아닌 변경된 부분에 대해서만 통신하여 전송량을 최적화하는 HTTP 프로토콜의 확장이다.
- 클라이언트가 현재 가지고 있는 버전에 대한 유일한 식별자 를 If-None-Match 헤더에 담아 변경되었다면 최신 버전의 문서를 받아온다.
- 이 때 A-IM 헤더를 보내 델타 인코딩을 처리할 수 있음을 알린다.
- Accept-Instance-Manipulation